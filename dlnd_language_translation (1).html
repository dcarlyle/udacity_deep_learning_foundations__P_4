<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<title>dlnd_language_translation</title><script src="https://unpkg.com/jupyter-js-widgets@2.0.*/dist/embed.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    color: #000 !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.2.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.2.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.2.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.2.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.2.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.2.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=1);
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2);
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=3);
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1);
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1);
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
@media (max-width: 991px) {
  #ipython_notebook {
    margin-left: 10px;
  }
}
[dir="rtl"] #ipython_notebook {
  float: right !important;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#login_widget {
  float: right;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  text-align: center;
  vertical-align: middle;
  display: inline;
  opacity: 0;
  z-index: 2;
  width: 12ex;
  margin-right: -12ex;
}
.alternate_upload .btn-upload {
  height: 22px;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
[dir="rtl"] #tabs li {
  float: right;
}
ul#tabs {
  margin-bottom: 4px;
}
[dir="rtl"] ul#tabs {
  margin-right: 0px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons {
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-right {
  padding-top: 1px;
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-left {
  float: right !important;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: baseline;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
#tree-selector {
  padding-right: 0px;
}
[dir="rtl"] #tree-selector a {
  float: right;
}
#button-select-all {
  min-width: 50px;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
[dir="rtl"] #new-menu {
  text-align: right;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
[dir="rtl"] #running .col-sm-8 {
  float: right !important;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul {
  list-style: disc;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ul ul {
  list-style: square;
  margin: 0em 2em;
}
.rendered_html ul ul ul {
  list-style: circle;
  margin: 0em 2em;
}
.rendered_html ol {
  list-style: decimal;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
  margin: 0em 2em;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  background-color: #fff;
  color: #000;
  font-size: 100%;
  padding: 0px;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: 1px solid black;
  border-collapse: collapse;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  border: 1px solid black;
  border-collapse: collapse;
  margin: 1em 2em;
}
.rendered_html td,
.rendered_html th {
  text-align: left;
  vertical-align: middle;
  padding: 4px;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget {
  float: right !important;
  float: right;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  margin-top: 6px;
}
span.save_widget span.filename {
  height: 1em;
  line-height: 1em;
  padding: 3px;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  display: none;
}
.command-shortcut:before {
  content: "(command)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>
<style type="text/css">
    
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}

@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Language-Translation">Language Translation<a class="anchor-link" href="#Language-Translation">&#182;</a></h1><p>In this project, you’re going to take a peek into the realm of neural network machine translation.  You’ll be training a sequence to sequence model on a dataset of English and French sentences that can translate new sentences from English to French.</p>
<h2 id="Get-the-Data">Get the Data<a class="anchor-link" href="#Get-the-Data">&#182;</a></h2><p>Since translating the whole language of English to French will take lots of time to train, we have provided you with a small portion of the English corpus.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[59]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>

<span class="n">source_path</span> <span class="o">=</span> <span class="s1">&#39;data/small_vocab_en&#39;</span>
<span class="n">target_path</span> <span class="o">=</span> <span class="s1">&#39;data/small_vocab_fr&#39;</span>
<span class="n">source_text</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">source_path</span><span class="p">)</span>
<span class="n">target_text</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">target_path</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Explore-the-Data">Explore the Data<a class="anchor-link" href="#Explore-the-Data">&#182;</a></h2><p>Play around with view_sentence_range to view different parts of the data.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[60]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">view_sentence_range</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Dataset Stats&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Roughly the number of unique words: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">({</span><span class="n">word</span><span class="p">:</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">()})))</span>

<span class="n">sentences</span> <span class="o">=</span> <span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">word_counts</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of sentences: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Average number of words in a sentence: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">word_counts</span><span class="p">)))</span>

<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;English sentences </span><span class="si">{}</span><span class="s1"> to </span><span class="si">{}</span><span class="s1">:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">view_sentence_range</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)[</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]]))</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;French sentences </span><span class="si">{}</span><span class="s1"> to </span><span class="si">{}</span><span class="s1">:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">view_sentence_range</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">target_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)[</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]]))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Dataset Stats
Roughly the number of unique words: 227
Number of sentences: 137861
Average number of words in a sentence: 13.225277634719028

English sentences 0 to 10:
new jersey is sometimes quiet during autumn , and it is snowy in april .
the united states is usually chilly during july , and it is usually freezing in november .
california is usually quiet during march , and it is usually hot in june .
the united states is sometimes mild during june , and it is cold in september .
your least liked fruit is the grape , but my least liked is the apple .
his favorite fruit is the orange , but my favorite is the grape .
paris is relaxing during december , but it is usually chilly in july .
new jersey is busy during spring , and it is never hot in march .
our least liked fruit is the lemon , but my least liked is the grape .
the united states is sometimes busy during january , and it is sometimes warm in november .

French sentences 0 to 10:
new jersey est parfois calme pendant l&#39; automne , et il est neigeux en avril .
les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .
california est généralement calme en mars , et il est généralement chaud en juin .
les états-unis est parfois légère en juin , et il fait froid en septembre .
votre moins aimé fruit est le raisin , mais mon moins aimé est la pomme .
son fruit préféré est l&#39;orange , mais mon préféré est le raisin .
paris est relaxant en décembre , mais il est généralement froid en juillet .
new jersey est occupé au printemps , et il est jamais chaude en mars .
notre fruit est moins aimé le citron , mais mon moins aimé est le raisin .
les états-unis est parfois occupé en janvier , et il est parfois chaud en novembre .
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Implement-Preprocessing-Function">Implement Preprocessing Function<a class="anchor-link" href="#Implement-Preprocessing-Function">&#182;</a></h2><h3 id="Text-to-Word-Ids">Text to Word Ids<a class="anchor-link" href="#Text-to-Word-Ids">&#182;</a></h3><p>As you did with other RNNs, you must turn the text into a number so the computer can understand it. In the function <code>text_to_ids()</code>, you'll turn <code>source_text</code> and <code>target_text</code> from words to ids.  However, you need to add the <code>&lt;EOS&gt;</code> word id at the end of each sentence from <code>target_text</code>.  This will help the neural network predict when the sentence should end.</p>
<p>You can get the <code>&lt;EOS&gt;</code> word id by doing:</p>
<div class="highlight"><pre><span></span><span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;EOS&gt;&#39;</span><span class="p">]</span>
</pre></div>
<p>You can get other word ids using <code>source_vocab_to_int</code> and <code>target_vocab_to_int</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[61]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># ref:  http://localhost:8889/notebooks/sentiment-rnn/Sentiment_RNN_Solution.ipynb</span>

<span class="k">def</span> <span class="nf">text_to_ids_subroutine</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">vocab2ids</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert source text to proper word ids, if target is True we add an end of sentence marker EOS</span>
<span class="sd">    :param text: String that contains all the source text.</span>
<span class="sd">    :param vocab2ids: Dictionary to go from the source words to an id</span>
<span class="sd">    :return: A lists (source_id_text)</span>
<span class="sd">    &quot;&quot;&quot;</span>


    <span class="n">id_text</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># sentences, a list of sentences </span>

    <span class="k">for</span> <span class="n">sentences</span> <span class="ow">in</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">):</span>

        <span class="n">id_sentence</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># list of word id integers in one sentence, e.g. 1, 2, 3</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentences</span><span class="o">.</span><span class="n">split</span><span class="p">():</span>
            <span class="n">id_sentence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vocab2ids</span><span class="p">[</span><span class="n">word</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">target</span><span class="p">:</span>
            <span class="n">id_sentence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vocab2ids</span><span class="p">[</span><span class="s1">&#39;&lt;EOS&gt;&#39;</span><span class="p">])</span> <span class="c1"># finish with the EOS token</span>
        <span class="n">id_text</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">id_sentence</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">id_text</span>

<span class="k">def</span> <span class="nf">text_to_ids</span><span class="p">(</span><span class="n">source_text</span><span class="p">,</span> <span class="n">target_text</span><span class="p">,</span> <span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert source and target text to proper word ids</span>
<span class="sd">    :param source_text: String that contains all the source text.</span>
<span class="sd">    :param target_text: String that contains all the target text.</span>
<span class="sd">    :param source_vocab_to_int: Dictionary to go from the source words to an id</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :return: A tuple of lists (source_id_text, target_id_text)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>

    <span class="c1">#let&#39;s add &lt;EOS&gt; for end of sentence to each sentence</span>
<span class="c1">#    source_ids = text_to_ids_subroutine(source_text, source_vocab_to_int)</span>
    
    <span class="c1"># Now let us repeat for the target</span>
<span class="c1">#    target_ids = text_to_ids_subroutine(target_text, target_vocab_to_int, True)</span>
    
    
    <span class="c1"># &#39;.&#39;   id = 31</span>
    <span class="c1"># &#39;and&#39; is 4</span>
    <span class="c1"># &#39;,&#39;   is 4</span>
    
    <span class="c1"># better approach as advised by my code reviewing tutor...  :)</span>
    <span class="n">target_ids</span> <span class="o">=</span> <span class="p">[[</span><span class="n">target_vocab_to_int</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">s</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span> <span class="o">+</span> <span class="p">[</span><span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;EOS&gt;&#39;</span><span class="p">]]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">target_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)]</span>
    <span class="n">source_ids</span> <span class="o">=</span> <span class="p">[[</span><span class="n">source_vocab_to_int</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">s</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)]</span>
    
    <span class="k">return</span> <span class="n">source_ids</span><span class="p">,</span> <span class="n">target_ids</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_text_to_ids</span><span class="p">(</span><span class="n">text_to_ids</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Preprocess-all-the-data-and-save-it">Preprocess all the data and save it<a class="anchor-link" href="#Preprocess-all-the-data-and-save-it">&#182;</a></h3><p>Running the code cell below will preprocess all the data and save it to file.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[62]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">helper</span><span class="o">.</span><span class="n">preprocess_and_save_data</span><span class="p">(</span><span class="n">source_path</span><span class="p">,</span> <span class="n">target_path</span><span class="p">,</span> <span class="n">text_to_ids</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Check-Point">Check Point<a class="anchor-link" href="#Check-Point">&#182;</a></h1><p>This is your first checkpoint. If you ever decide to come back to this notebook or have to restart the notebook, you can start from here. The preprocessed data has been saved to disk.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[63]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">helper</span>

<span class="p">(</span><span class="n">source_int_text</span><span class="p">,</span> <span class="n">target_int_text</span><span class="p">),</span> <span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">),</span> <span class="n">_</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Check-the-Version-of-TensorFlow-and-Access-to-GPU">Check the Version of TensorFlow and Access to GPU<a class="anchor-link" href="#Check-the-Version-of-TensorFlow-and-Access-to-GPU">&#182;</a></h3><p>This will check to make sure you have the correct version of TensorFlow and access to a GPU</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[64]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">distutils.version</span> <span class="k">import</span> <span class="n">LooseVersion</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="c1"># Check TensorFlow Version</span>
<span class="k">assert</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span> <span class="ow">in</span> <span class="p">[</span><span class="n">LooseVersion</span><span class="p">(</span><span class="s1">&#39;1.0.0&#39;</span><span class="p">),</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="s1">&#39;1.0.1&#39;</span><span class="p">)],</span> <span class="s1">&#39;This project requires TensorFlow version 1.0  You are using </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;TensorFlow Version: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">))</span>

<span class="c1"># Check for a GPU</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">gpu_device_name</span><span class="p">():</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;No GPU found. Please use a GPU to train your neural network.&#39;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Default GPU Device: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">gpu_device_name</span><span class="p">()))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>TensorFlow Version: 1.0.0
Default GPU Device: /gpu:0
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Build-the-Neural-Network">Build the Neural Network<a class="anchor-link" href="#Build-the-Neural-Network">&#182;</a></h2><p>You'll build the components necessary to build a Sequence-to-Sequence model by implementing the following functions below:</p>
<ul>
<li><code>model_inputs</code></li>
<li><code>process_decoding_input</code></li>
<li><code>encoding_layer</code></li>
<li><code>decoding_layer_train</code></li>
<li><code>decoding_layer_infer</code></li>
<li><code>decoding_layer</code></li>
<li><code>seq2seq_model</code></li>
</ul>
<h3 id="Input">Input<a class="anchor-link" href="#Input">&#182;</a></h3><p>Implement the <code>model_inputs()</code> function to create TF Placeholders for the Neural Network. It should create the following placeholders:</p>
<ul>
<li>Input text placeholder named "input" using the TF Placeholder name parameter with rank 2.</li>
<li>Targets placeholder with rank 2.</li>
<li>Learning rate placeholder with rank 0.</li>
<li>Keep probability placeholder named "keep_prob" using the TF Placeholder name parameter with rank 0.</li>
</ul>
<p>Return the placeholders in the following the tuple (Input, Targets, Learing Rate, Keep Probability)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[65]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">model_inputs</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create TF Placeholders for input, targets, and learning rate.</span>
<span class="sd">    :return: Tuple (input, targets, learning rate, keep probability)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">input_data</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;input&#39;</span><span class="p">)</span>
    <span class="n">targets</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;targets&#39;</span><span class="p">)</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span><span class="p">)</span>
    <span class="n">kp</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;keep_prob&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">input_data</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">kp</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_model_inputs</span><span class="p">(</span><span class="n">model_inputs</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Process-Decoding-Input">Process Decoding Input<a class="anchor-link" href="#Process-Decoding-Input">&#182;</a></h3><p>Implement <code>process_decoding_input</code> using TensorFlow to remove the last word id from each batch in <code>target_data</code> and concat the GO ID to the beginning of each batch.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[66]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">process_decoding_input</span><span class="p">(</span><span class="n">target_data</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Preprocess target data for dencoding</span>
<span class="sd">    :param target_data: Target Placehoder</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :param batch_size: Batch Size</span>
<span class="sd">    :return: Preprocessed target data</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>

    <span class="c1"># Process the input we&#39;ll feed to the decoder</span>
    <span class="n">ending</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">strided_slice</span><span class="p">(</span><span class="n">target_data</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    
    <span class="c1"># in seq2seq/sequence_to_sequence_implementation.ipynb they use &lt;s&gt; for the special word for process decoding input</span>
    <span class="c1"># we add GO  to indicate targets training the batch is starting.</span>
    <span class="n">dec_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">fill</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;GO&gt;&#39;</span><span class="p">]),</span> <span class="n">ending</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
    
    <span class="c1">############</span>
    <span class="c1"># TESTING #</span>
    <span class="c1">##########</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    # sequence_length sholud be max length of a sentence, for this unit it is the shape of the tensforflow placeholder</span>
<span class="sd">    #print(help(target_data))</span>
<span class="sd">    sequence_length = int((target_data.shape)[1])</span>
<span class="sd">    demonstration_outputs = np.reshape(range(batch_size * sequence_length), (batch_size, sequence_length))</span>
<span class="sd">    sess = tf.InteractiveSession()</span>
<span class="sd">    print(&quot;Targets&quot;)</span>
<span class="sd">    print(demonstration_outputs[:2])</span>
<span class="sd">    print(&quot;\n&quot;)</span>
<span class="sd">    print(&quot;Processed Decoding Input&quot;)</span>
<span class="sd">    print(sess.run(dec_input, {target_data: demonstration_outputs})[:2])</span>
<span class="sd">    &#39;&#39;&#39;</span>
  
    <span class="k">return</span> <span class="n">dec_input</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_process_decoding_input</span><span class="p">(</span><span class="n">process_decoding_input</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Encoding">Encoding<a class="anchor-link" href="#Encoding">&#182;</a></h3><p>Implement <code>encoding_layer()</code> to create a Encoder RNN layer using <a href="https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn"><code>tf.nn.dynamic_rnn()</code></a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[67]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">encoding_layer</span><span class="p">(</span><span class="n">rnn_inputs</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create encoding layer</span>
<span class="sd">    :param rnn_inputs: Inputs for the RNN</span>
<span class="sd">    :param rnn_size: RNN Size</span>
<span class="sd">    :param num_layers: Number of layers</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :return: RNN state</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    
    <span class="c1"># Encoder embedding</span>
    <span class="c1"># Embed the input data using tf.contrib.layers.embed_sequence</span>
    <span class="c1">#enc_embed_input = tf.contrib.layers.embed_sequence(input_data, source_vocab_size, encoding_embedding_size)</span>
    
    <span class="c1"># Pass the embedded input into a stack of RNNs. Save the RNN state and ignore the output.</span>
    <span class="c1"># &lt;---- GRUs are easier to understand and less complex than LSTM, </span>
    <span class="c1"># but unit test fails with them</span>
    <span class="c1"># ref: http://web.stanford.edu/class/cs20si/lectures/slides_11.pdf</span>
    <span class="c1"># ref: https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/GRUCell</span>
    <span class="c1">#cell = tf.contrib.rnn.GRUCell(rnn_size)</span>
    <span class="c1">#cell = tf.contrib.rnn.core_rnn_cell.GRUCell(rnn_size)</span>
    <span class="n">cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">BasicLSTMCell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">)</span>
    
    <span class="c1"># add a drop out wrapper</span>
    <span class="n">cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">output_keep_prob</span><span class="o">=</span><span class="n">keep_prob</span><span class="p">)</span>
    
    <span class="c1"># add cell with drop out wrapper to the stack of RNN Cells</span>
    <span class="n">enc_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">MultiRNNCell</span><span class="p">([</span><span class="n">cell</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_layers</span><span class="p">)</span>
    
    
    <span class="c1">#enc_cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.BasicLSTMCell(rnn_size)] * num_layers)</span>
    
    <span class="c1"># output is a pair (output and state), we only want state</span>
    <span class="n">output</span><span class="p">,</span> <span class="n">enc_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span><span class="n">enc_cell</span><span class="p">,</span> <span class="n">rnn_inputs</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    
    <span class="c1"># adding in a dropout_keep_probability</span>
    <span class="c1">#output = tf.nn.dropout(output, keep_prob)  #&lt;---- not being used....!</span>

    <span class="k">return</span> <span class="n">enc_state</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_encoding_layer</span><span class="p">(</span><span class="n">encoding_layer</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Decoding---Training">Decoding - Training<a class="anchor-link" href="#Decoding---Training">&#182;</a></h3><p>Create training logits using <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/simple_decoder_fn_train"><code>tf.contrib.seq2seq.simple_decoder_fn_train()</code></a> and <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_rnn_decoder"><code>tf.contrib.seq2seq.dynamic_rnn_decoder()</code></a>.  Apply the <code>output_fn</code> to the <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_rnn_decoder"><code>tf.contrib.seq2seq.dynamic_rnn_decoder()</code></a> outputs.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[68]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">decoding_layer_train</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">dec_cell</span><span class="p">,</span> <span class="n">dec_embed_input</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">,</span> <span class="n">decoding_scope</span><span class="p">,</span>
                         <span class="n">output_fn</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a decoding layer for training</span>
<span class="sd">    :param encoder_state: Encoder State</span>
<span class="sd">    :param dec_cell: Decoder RNN Cell</span>
<span class="sd">    :param dec_embed_input: Decoder embedded input</span>
<span class="sd">    :param sequence_length: Sequence Length</span>
<span class="sd">    :param decoding_scope: TenorFlow Variable Scope for decoding</span>
<span class="sd">    :param output_fn: Function to apply the output layer</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :return: Train Logits</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    
    <span class="c1"># Training Decoder</span>
    <span class="n">train_decoder_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">simple_decoder_fn_train</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">)</span>
    <span class="n">train_pred</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">dynamic_rnn_decoder</span><span class="p">(</span>
        <span class="n">dec_cell</span><span class="p">,</span> <span class="n">train_decoder_fn</span><span class="p">,</span> <span class="n">dec_embed_input</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">,</span> <span class="n">scope</span><span class="o">=</span><span class="n">decoding_scope</span><span class="p">)</span>
    
    <span class="c1"># Apply output function</span>
    <span class="n">train_logits</span> <span class="o">=</span>  <span class="n">output_fn</span><span class="p">(</span><span class="n">train_pred</span><span class="p">)</span>
    
    <span class="c1">#apply drop out again</span>
    <span class="c1"># IMPROVEMENT NOTE from tutor ----</span>
    <span class="c1"># ut dropout layer should be within the model, </span>
    <span class="c1"># not at the output, to provide improvement. Here this is like you removed words, and/or swap some.</span>
<span class="c1">#    train_logits = tf.nn.dropout(train_logits, keep_prob)</span>
    
    <span class="k">return</span> <span class="n">train_logits</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_decoding_layer_train</span><span class="p">(</span><span class="n">decoding_layer_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Decoding---Inference">Decoding - Inference<a class="anchor-link" href="#Decoding---Inference">&#182;</a></h3><p>Create inference logits using <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/simple_decoder_fn_inference"><code>tf.contrib.seq2seq.simple_decoder_fn_inference()</code></a> and <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_rnn_decoder"><code>tf.contrib.seq2seq.dynamic_rnn_decoder()</code></a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[69]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">decoding_layer_infer</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">dec_cell</span><span class="p">,</span> <span class="n">dec_embeddings</span><span class="p">,</span> <span class="n">start_of_sequence_id</span><span class="p">,</span> <span class="n">end_of_sequence_id</span><span class="p">,</span>
                         <span class="n">maximum_length</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">decoding_scope</span><span class="p">,</span> <span class="n">output_fn</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a decoding layer for inference</span>
<span class="sd">    :param encoder_state: Encoder state</span>
<span class="sd">    :param dec_cell: Decoder RNN Cell</span>
<span class="sd">    :param dec_embeddings: Decoder embeddings</span>
<span class="sd">    :param start_of_sequence_id: GO ID</span>
<span class="sd">    :param end_of_sequence_id: EOS Id</span>
<span class="sd">    :param maximum_length: The maximum allowed time steps to decode</span>
<span class="sd">    :param vocab_size: Size of vocabulary</span>
<span class="sd">    :param decoding_scope: TensorFlow Variable Scope for decoding</span>
<span class="sd">    :param output_fn: Function to apply the output layer</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :return: Inference Logits</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="c1"># Inference Decoder</span>
    <span class="c1">#infer_decoder_fn = tf.contrib.seq2seq.simple_decoder_fn_inference(</span>
    <span class="c1">#    output_fn, encoder_state, dec_embeddings, target_letter_to_int[&#39;&lt;GO&gt;&#39;], target_letter_to_int[&#39;&lt;\GO&gt;&#39;], </span>
    <span class="c1">#    maximum_sequence_length - 1, vocab_size)</span>
    
    <span class="n">infer_decoder_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">simple_decoder_fn_inference</span><span class="p">(</span>
        <span class="n">output_fn</span><span class="p">,</span> <span class="n">encoder_state</span><span class="p">,</span> <span class="n">dec_embeddings</span><span class="p">,</span> <span class="n">start_of_sequence_id</span><span class="p">,</span> <span class="n">end_of_sequence_id</span><span class="p">,</span> 
        <span class="n">maximum_length</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>
    
    <span class="n">inference_logits</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">dynamic_rnn_decoder</span><span class="p">(</span><span class="n">dec_cell</span><span class="p">,</span> <span class="n">infer_decoder_fn</span><span class="p">,</span> <span class="n">scope</span><span class="o">=</span><span class="n">decoding_scope</span><span class="p">)</span>
    
    <span class="c1"># apply drop out</span>
    <span class="c1"># IMPROVEMENT NOTE from tutor ----</span>
    <span class="c1"># owever as the name of the function say, this one is only for the inference, </span>
    <span class="c1"># this mean that you shouldn&#39;t use a dropout layer here. </span>
    <span class="c1"># The dropout should only be used for the training, otherwise you will loss information.</span>
    <span class="c1"># Even if adding dropout can be seen as a bagging.</span>
    <span class="c1"># Here is a good explanation of the dropout : https://www.quora.com/How-does-the-dropout-method-work-in-deep-learning</span>
<span class="c1">#    inference_logits = tf.nn.dropout(inference_logits, keep_prob)</span>
    
    <span class="k">return</span> <span class="n">inference_logits</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_decoding_layer_infer</span><span class="p">(</span><span class="n">decoding_layer_infer</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-Decoding-Layer">Build the Decoding Layer<a class="anchor-link" href="#Build-the-Decoding-Layer">&#182;</a></h3><p>Implement <code>decoding_layer()</code> to create a Decoder RNN layer.</p>
<ul>
<li>Create RNN cell for decoding using <code>rnn_size</code> and <code>num_layers</code>.</li>
<li>Create the output fuction using <a href="https://docs.python.org/3/tutorial/controlflow.html#lambda-expressions"><code>lambda</code></a> to transform it's input, logits, to class logits.</li>
<li>Use the your <code>decoding_layer_train(encoder_state, dec_cell, dec_embed_input, sequence_length, decoding_scope, output_fn, keep_prob)</code> function to get the training logits.</li>
<li>Use your <code>decoding_layer_infer(encoder_state, dec_cell, dec_embeddings, start_of_sequence_id, end_of_sequence_id, maximum_length, vocab_size, decoding_scope, output_fn, keep_prob)</code> function to get the inference logits.</li>
</ul>
<p>Note: You'll need to use <a href="https://www.tensorflow.org/api_docs/python/tf/variable_scope">tf.variable_scope</a> to share variables between training and inference.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[70]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">decoding_layer</span><span class="p">(</span><span class="n">dec_embed_input</span><span class="p">,</span> <span class="n">dec_embeddings</span><span class="p">,</span> <span class="n">encoder_state</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">,</span>
                   <span class="n">num_layers</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create decoding layer</span>
<span class="sd">    :param dec_embed_input: Decoder embedded input</span>
<span class="sd">    :param dec_embeddings: Decoder embeddings</span>
<span class="sd">    :param encoder_state: The encoded state</span>
<span class="sd">    :param vocab_size: Size of vocabulary</span>
<span class="sd">    :param sequence_length: Sequence Length</span>
<span class="sd">    :param rnn_size: RNN Size</span>
<span class="sd">    :param num_layers: Number of layers</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :return: Tuple of (Training Logits, Inference Logits)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="c1">#Implement decoding_layer() to create a Decoder RNN layer.</span>
    <span class="c1"># 1. Create RNN cell for decoding using rnn_size and num_layers.</span>
    <span class="n">cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">BasicLSTMCell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">)</span>
    
    <span class="c1"># add a drop out wrapper</span>
    <span class="n">cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">output_keep_prob</span><span class="o">=</span><span class="n">keep_prob</span><span class="p">)</span>
    
    <span class="c1"># add cell with drop out wrapper to the stack of RNN Cells</span>
    <span class="n">dec_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">MultiRNNCell</span><span class="p">([</span><span class="n">cell</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_layers</span><span class="p">)</span>
    
    <span class="c1"># 2. Create the output fuction using lambda to transform it&#39;s input, logits, to class logits.</span>
    <span class="c1"># Build the output layer in the decoding scope, so the weight and bias can be shared between </span>
    <span class="c1"># the training and inference decoders.</span>
    <span class="c1"># Output Layer</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s2">&quot;decoding&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">decoding_scope</span><span class="p">:</span>
        
        <span class="n">output_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">fully_connected</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">scope</span><span class="o">=</span><span class="n">decoding_scope</span><span class="p">)</span>
    
    <span class="c1"># 3. Use the your decoding_layer_train() function to get the training logits.</span>
        <span class="n">training_logits</span> <span class="o">=</span> <span class="n">decoding_layer_train</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">dec_cell</span><span class="p">,</span> <span class="n">dec_embed_input</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">,</span> 
                                           <span class="n">decoding_scope</span><span class="p">,</span> <span class="n">output_fn</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>    
        
        
    <span class="c1"># 4. Use your decoding_layer_infer() function to get the inference logits.</span>
    <span class="c1"># reuse the scope (decoding_scope.reuse_variables())</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s2">&quot;decoding&quot;</span><span class="p">,</span> <span class="n">reuse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">decoding_scope</span><span class="p">:</span>
        
        <span class="n">inference_logits</span> <span class="o">=</span> <span class="n">decoding_layer_infer</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">dec_cell</span><span class="p">,</span> <span class="n">dec_embeddings</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;GO&gt;&#39;</span><span class="p">],</span> 
                                            <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;EOS&gt;&#39;</span><span class="p">],</span> <span class="n">sequence_length</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> 
                                            <span class="n">decoding_scope</span><span class="p">,</span> <span class="n">output_fn</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span> 

    
    <span class="k">return</span> <span class="n">training_logits</span><span class="p">,</span> <span class="n">inference_logits</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_decoding_layer</span><span class="p">(</span><span class="n">decoding_layer</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-Neural-Network">Build the Neural Network<a class="anchor-link" href="#Build-the-Neural-Network">&#182;</a></h3><p>Apply the functions you implemented above to:</p>
<ul>
<li>Apply embedding to the input data for the encoder.</li>
<li>Encode the input using your <code>encoding_layer(rnn_inputs, rnn_size, num_layers, keep_prob)</code>.</li>
<li>Process target data using your <code>process_decoding_input(target_data, target_vocab_to_int, batch_size)</code> function.</li>
<li>Apply embedding to the target data for the decoder.</li>
<li>Decode the encoded input using your <code>decoding_layer(dec_embed_input, dec_embeddings, encoder_state, vocab_size, sequence_length, rnn_size, num_layers, target_vocab_to_int, keep_prob)</code>.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[71]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">seq2seq_model</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">target_data</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">,</span> <span class="n">source_vocab_size</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span>
                  <span class="n">enc_embedding_size</span><span class="p">,</span> <span class="n">dec_embedding_size</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Build the Sequence-to-Sequence part of the neural network</span>
<span class="sd">    :param input_data: Input placeholder</span>
<span class="sd">    :param target_data: Target placeholder</span>
<span class="sd">    :param keep_prob: Dropout keep probability placeholder</span>
<span class="sd">    :param batch_size: Batch Size</span>
<span class="sd">    :param sequence_length: Sequence Length</span>
<span class="sd">    :param source_vocab_size: Source vocabulary size</span>
<span class="sd">    :param target_vocab_size: Target vocabulary size</span>
<span class="sd">    :param enc_embedding_size: Decoder embedding size</span>
<span class="sd">    :param dec_embedding_size: Encoder embedding size</span>
<span class="sd">    :param rnn_size: RNN Size</span>
<span class="sd">    :param num_layers: Number of layers</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :return: Tuple of (Training Logits, Inference Logits)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    
    <span class="c1"># 1. - Apply embedding to the input data for the encoder.</span>
    <span class="n">enc_embed_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">embed_sequence</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">source_vocab_size</span><span class="p">,</span> <span class="n">enc_embedding_size</span><span class="p">)</span>
    
    <span class="c1"># 2. - create an Encoder RNN layer  - Encode the input using your `encoding_layer()`.</span>
    <span class="n">encoder_state</span> <span class="o">=</span> <span class="n">encoding_layer</span><span class="p">(</span><span class="n">enc_embed_input</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
    
    <span class="c1"># 3. - Process target data using your `process_decoding_input()` function.</span>
    <span class="n">dec_input</span> <span class="o">=</span> <span class="n">process_decoding_input</span><span class="p">(</span><span class="n">target_data</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
    
    <span class="c1"># 4. - Apply embedding to the target data for the decoder.</span>
    <span class="c1"># Embed the decoding input</span>
    <span class="c1"># Decoder Embedding</span>
    
    <span class="c1"># IMPROVEMENT NOTE from tutor ----</span>
    <span class="c1"># For the tf.random_uniform, I would suggest to add a range of value for the initialization, as -1 to 1</span>
    <span class="c1"># https://cs224d.stanford.edu/lectures/CS224d-Lecture7.pdf</span>
    <span class="n">dec_embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">([</span><span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">dec_embedding_size</span><span class="p">],</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>
    <span class="c1">#dec_embeddings = tf.Variable(tf.random_normal([target_vocab_size, dec_embedding_size],  stddev = 0.05))</span>
    
    
    <span class="n">dec_embed_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">embedding_lookup</span><span class="p">(</span><span class="n">dec_embeddings</span><span class="p">,</span> <span class="n">dec_input</span><span class="p">)</span>
    
    <span class="c1"># 5. - Decode the encoded input using your `decoding_layer()`.</span>
    <span class="n">training_logits</span><span class="p">,</span> <span class="n">inference_logits</span> <span class="o">=</span> <span class="n">decoding_layer</span><span class="p">(</span><span class="n">dec_embed_input</span><span class="p">,</span> <span class="n">dec_embeddings</span><span class="p">,</span> 
                                                       <span class="n">encoder_state</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span> 
                                                       <span class="n">sequence_length</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">,</span> 
                                                       <span class="n">num_layers</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>

    
    <span class="k">return</span> <span class="n">training_logits</span><span class="p">,</span> <span class="n">inference_logits</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_seq2seq_model</span><span class="p">(</span><span class="n">seq2seq_model</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Neural-Network-Training">Neural Network Training<a class="anchor-link" href="#Neural-Network-Training">&#182;</a></h2><h3 id="Hyperparameters">Hyperparameters<a class="anchor-link" href="#Hyperparameters">&#182;</a></h3><p>Tune the following parameters:</p>
<ul>
<li>Set <code>epochs</code> to the number of epochs.</li>
<li>Set <code>batch_size</code> to the batch size.</li>
<li>Set <code>rnn_size</code> to the size of the RNNs.</li>
<li>Set <code>num_layers</code> to the number of layers.</li>
<li>Set <code>encoding_embedding_size</code> to the size of the embedding for the encoder.</li>
<li>Set <code>decoding_embedding_size</code> to the size of the embedding for the decoder.</li>
<li>Set <code>learning_rate</code> to the learning rate.</li>
<li>Set <code>keep_probability</code> to the Dropout keep probability</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[75]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># A few notes from tutor added...to assist me getting even more out of the implementation  :)</span>

<span class="c1"># Don&#39;t forget: the values of hyper parameters should be power of 2. Tensorflow optimizes our computation if we do so.</span>

<span class="c1"># epochs = [5-15] : with more layers you should increase the number of epochs, </span>
<span class="c1"># the key is to choose a number such that the loss on validation set stops decreasing further.</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">4</span> <span class="c1">#3</span>
<span class="c1"># Batch Size</span>
<span class="c1"># batch_size = [256, 1024] : mainly depend on where you will run the code, and it&#39;s power</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">256</span> <span class="c1">#512 #minibatch, bigger batch is reducing the loss and accuracy</span>
<span class="c1"># RNN Size</span>
<span class="c1"># rnn_size = [128, 512] : High mean, the model will learn more complex structure</span>
<span class="n">rnn_size</span> <span class="o">=</span> <span class="mi">256</span> <span class="c1">#512 </span>
<span class="c1"># Number of Layers</span>
<span class="c1"># num_layers = [2, 4] : More you have more your complex your model will be</span>
<span class="n">num_layers</span> <span class="o">=</span> <span class="mi">2</span> <span class="c1">#3</span>
<span class="c1"># Embedding Size</span>
<span class="c1"># embedding_size = [128, 256] : Can represent the number of unique words we can deal with.</span>
<span class="c1"># according to cs224d standford lecture the embedding size for a small dataset it should be around 25 to 1000</span>
<span class="c1"># IMPROVEMENT NOTE from tutor ----</span>
<span class="c1"># Good ! but your embedding_size is way too large. (I set them to 1000)</span>
<span class="c1"># we have a vocab of 277 words... so.... I Guess let us go for 277</span>
<span class="n">encoding_embedding_size</span> <span class="o">=</span> <span class="mi">256</span> <span class="c1">#...... larger seems to improve train accuracy</span>
<span class="n">decoding_embedding_size</span> <span class="o">=</span> <span class="mi">256</span> 
<span class="c1"># Learning Rate</span>
<span class="c1"># learning_rate = [0.001, 0.01] : low to learn form the large variability of the dataset</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="c1"># Dropout Keep Probability</span>
<span class="c1"># keep_probability = [0.6, 0.9] : Depend where you put dropout layer, </span>
<span class="c1"># but shouldn&#39;t be too low due to the small size of our dataset</span>
<span class="n">keep_probability</span> <span class="o">=</span> <span class="mf">0.8</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-Graph">Build the Graph<a class="anchor-link" href="#Build-the-Graph">&#182;</a></h3><p>Build the graph using the neural network you implemented.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[76]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">save_path</span> <span class="o">=</span> <span class="s1">&#39;checkpoints/dev&#39;</span>
<span class="p">(</span><span class="n">source_int_text</span><span class="p">,</span> <span class="n">target_int_text</span><span class="p">),</span> <span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">),</span> <span class="n">_</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
<span class="n">max_source_sentence_length</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">source_int_text</span><span class="p">])</span>

<span class="n">train_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">train_graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
    <span class="n">input_data</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">keep_prob</span> <span class="o">=</span> <span class="n">model_inputs</span><span class="p">()</span>
    <span class="n">sequence_length</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder_with_default</span><span class="p">(</span><span class="n">max_source_sentence_length</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;sequence_length&#39;</span><span class="p">)</span>
    <span class="n">input_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>
    
    <span class="n">train_logits</span><span class="p">,</span> <span class="n">inference_logits</span> <span class="o">=</span> <span class="n">seq2seq_model</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">reverse</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">targets</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">target_vocab_to_int</span><span class="p">),</span>
        <span class="n">encoding_embedding_size</span><span class="p">,</span> <span class="n">decoding_embedding_size</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">)</span>

    <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">inference_logits</span><span class="p">,</span> <span class="s1">&#39;logits&#39;</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s2">&quot;optimization&quot;</span><span class="p">):</span>
        <span class="c1"># Loss function</span>
        <span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">sequence_loss</span><span class="p">(</span>
            <span class="n">train_logits</span><span class="p">,</span>
            <span class="n">targets</span><span class="p">,</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">input_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">sequence_length</span><span class="p">]))</span>

        <span class="c1"># Optimizer</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>

        <span class="c1"># Gradient Clipping</span>
        <span class="n">gradients</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">compute_gradients</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
        <span class="n">capped_gradients</span> <span class="o">=</span> <span class="p">[(</span><span class="n">tf</span><span class="o">.</span><span class="n">clip_by_value</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">),</span> <span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">grad</span><span class="p">,</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">gradients</span> <span class="k">if</span> <span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">]</span>
        <span class="n">train_op</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="n">capped_gradients</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Train">Train<a class="anchor-link" href="#Train">&#182;</a></h3><p>Train the neural network on the preprocessed data. If you have a hard time getting a good loss, check the forms to see if anyone is having the same problem.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[77]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="k">def</span> <span class="nf">get_accuracy</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">logits</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate accuracy</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">max_seq</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">max_seq</span> <span class="o">-</span> <span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
            <span class="n">target</span><span class="p">,</span>
            <span class="p">[(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="n">max_seq</span> <span class="o">-</span> <span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])],</span>
            <span class="s1">&#39;constant&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">max_seq</span> <span class="o">-</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
            <span class="n">logits</span><span class="p">,</span>
            <span class="p">[(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="n">max_seq</span> <span class="o">-</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">)],</span>
            <span class="s1">&#39;constant&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>

<span class="n">train_source</span> <span class="o">=</span> <span class="n">source_int_text</span><span class="p">[</span><span class="n">batch_size</span><span class="p">:]</span>
<span class="n">train_target</span> <span class="o">=</span> <span class="n">target_int_text</span><span class="p">[</span><span class="n">batch_size</span><span class="p">:]</span>

<span class="n">valid_source</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">pad_sentence_batch</span><span class="p">(</span><span class="n">source_int_text</span><span class="p">[:</span><span class="n">batch_size</span><span class="p">])</span>
<span class="n">valid_target</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">pad_sentence_batch</span><span class="p">(</span><span class="n">target_int_text</span><span class="p">[:</span><span class="n">batch_size</span><span class="p">])</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">train_graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>

    <span class="k">for</span> <span class="n">epoch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">batch_i</span><span class="p">,</span> <span class="p">(</span><span class="n">source_batch</span><span class="p">,</span> <span class="n">target_batch</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
                <span class="n">helper</span><span class="o">.</span><span class="n">batch_data</span><span class="p">(</span><span class="n">train_source</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)):</span>
            <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            
            <span class="n">_</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                <span class="p">[</span><span class="n">train_op</span><span class="p">,</span> <span class="n">cost</span><span class="p">],</span>
                <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">source_batch</span><span class="p">,</span>
                 <span class="n">targets</span><span class="p">:</span> <span class="n">target_batch</span><span class="p">,</span>
                 <span class="n">lr</span><span class="p">:</span> <span class="n">learning_rate</span><span class="p">,</span>
                 <span class="n">sequence_length</span><span class="p">:</span> <span class="n">target_batch</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                 <span class="n">keep_prob</span><span class="p">:</span> <span class="n">keep_probability</span><span class="p">})</span>
            
            <span class="n">batch_train_logits</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                <span class="n">inference_logits</span><span class="p">,</span>
                <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">source_batch</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>
            <span class="n">batch_valid_logits</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                <span class="n">inference_logits</span><span class="p">,</span>
                <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">valid_source</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>
                
            <span class="n">train_acc</span> <span class="o">=</span> <span class="n">get_accuracy</span><span class="p">(</span><span class="n">target_batch</span><span class="p">,</span> <span class="n">batch_train_logits</span><span class="p">)</span>
            <span class="n">valid_acc</span> <span class="o">=</span> <span class="n">get_accuracy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">valid_target</span><span class="p">),</span> <span class="n">batch_valid_logits</span><span class="p">)</span>
            <span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">{:&gt;3}</span><span class="s1"> Batch </span><span class="si">{:&gt;4}</span><span class="s1">/</span><span class="si">{}</span><span class="s1"> - Train Accuracy: </span><span class="si">{:&gt;6.3f}</span><span class="s1">, Validation Accuracy: </span><span class="si">{:&gt;6.3f}</span><span class="s1">, Loss: </span><span class="si">{:&gt;6.3f}</span><span class="s1">&#39;</span>
                  <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch_i</span><span class="p">,</span> <span class="n">batch_i</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">source_int_text</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">train_acc</span><span class="p">,</span> <span class="n">valid_acc</span><span class="p">,</span> <span class="n">loss</span><span class="p">))</span>

    <span class="c1"># Save Model</span>
    <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>
    <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">save_path</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Model Trained and Saved&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch   0 Batch    0/538 - Train Accuracy:  0.200, Validation Accuracy:  0.289, Loss:  5.888
Epoch   0 Batch    1/538 - Train Accuracy:  0.261, Validation Accuracy:  0.346, Loss:  5.724
Epoch   0 Batch    2/538 - Train Accuracy:  0.280, Validation Accuracy:  0.339, Loss:  5.478
Epoch   0 Batch    3/538 - Train Accuracy:  0.249, Validation Accuracy:  0.334, Loss:  5.159
Epoch   0 Batch    4/538 - Train Accuracy:  0.248, Validation Accuracy:  0.328, Loss:  4.631
Epoch   0 Batch    5/538 - Train Accuracy:  0.286, Validation Accuracy:  0.336, Loss:  4.152
Epoch   0 Batch    6/538 - Train Accuracy:  0.302, Validation Accuracy:  0.346, Loss:  3.948
Epoch   0 Batch    7/538 - Train Accuracy:  0.304, Validation Accuracy:  0.368, Loss:  3.819
Epoch   0 Batch    8/538 - Train Accuracy:  0.288, Validation Accuracy:  0.352, Loss:  3.683
Epoch   0 Batch    9/538 - Train Accuracy:  0.315, Validation Accuracy:  0.371, Loss:  3.572
Epoch   0 Batch   10/538 - Train Accuracy:  0.299, Validation Accuracy:  0.378, Loss:  3.515
Epoch   0 Batch   11/538 - Train Accuracy:  0.307, Validation Accuracy:  0.369, Loss:  3.355
Epoch   0 Batch   12/538 - Train Accuracy:  0.257, Validation Accuracy:  0.328, Loss:  3.341
Epoch   0 Batch   13/538 - Train Accuracy:  0.272, Validation Accuracy:  0.303, Loss:  3.010
Epoch   0 Batch   14/538 - Train Accuracy:  0.298, Validation Accuracy:  0.359, Loss:  3.140
Epoch   0 Batch   15/538 - Train Accuracy:  0.361, Validation Accuracy:  0.395, Loss:  2.929
Epoch   0 Batch   16/538 - Train Accuracy:  0.339, Validation Accuracy:  0.384, Loss:  2.899
Epoch   0 Batch   17/538 - Train Accuracy:  0.321, Validation Accuracy:  0.387, Loss:  2.966
Epoch   0 Batch   18/538 - Train Accuracy:  0.338, Validation Accuracy:  0.403, Loss:  2.983
Epoch   0 Batch   19/538 - Train Accuracy:  0.335, Validation Accuracy:  0.407, Loss:  2.944
Epoch   0 Batch   20/538 - Train Accuracy:  0.378, Validation Accuracy:  0.421, Loss:  2.788
Epoch   0 Batch   21/538 - Train Accuracy:  0.313, Validation Accuracy:  0.422, Loss:  2.993
Epoch   0 Batch   22/538 - Train Accuracy:  0.356, Validation Accuracy:  0.418, Loss:  2.793
Epoch   0 Batch   23/538 - Train Accuracy:  0.373, Validation Accuracy:  0.429, Loss:  2.757
Epoch   0 Batch   24/538 - Train Accuracy:  0.384, Validation Accuracy:  0.428, Loss:  2.702
Epoch   0 Batch   25/538 - Train Accuracy:  0.366, Validation Accuracy:  0.434, Loss:  2.727
Epoch   0 Batch   26/538 - Train Accuracy:  0.358, Validation Accuracy:  0.425, Loss:  2.699
Epoch   0 Batch   27/538 - Train Accuracy:  0.366, Validation Accuracy:  0.425, Loss:  2.642
Epoch   0 Batch   28/538 - Train Accuracy:  0.422, Validation Accuracy:  0.425, Loss:  2.394
Epoch   0 Batch   29/538 - Train Accuracy:  0.374, Validation Accuracy:  0.425, Loss:  2.533
Epoch   0 Batch   30/538 - Train Accuracy:  0.350, Validation Accuracy:  0.425, Loss:  2.594
Epoch   0 Batch   31/538 - Train Accuracy:  0.387, Validation Accuracy:  0.426, Loss:  2.449
Epoch   0 Batch   32/538 - Train Accuracy:  0.371, Validation Accuracy:  0.433, Loss:  2.483
Epoch   0 Batch   33/538 - Train Accuracy:  0.373, Validation Accuracy:  0.414, Loss:  2.427
Epoch   0 Batch   34/538 - Train Accuracy:  0.348, Validation Accuracy:  0.407, Loss:  2.474
Epoch   0 Batch   35/538 - Train Accuracy:  0.360, Validation Accuracy:  0.433, Loss:  2.445
Epoch   0 Batch   36/538 - Train Accuracy:  0.380, Validation Accuracy:  0.430, Loss:  2.322
Epoch   0 Batch   37/538 - Train Accuracy:  0.355, Validation Accuracy:  0.422, Loss:  2.363
Epoch   0 Batch   38/538 - Train Accuracy:  0.340, Validation Accuracy:  0.421, Loss:  2.383
Epoch   0 Batch   39/538 - Train Accuracy:  0.340, Validation Accuracy:  0.420, Loss:  2.363
Epoch   0 Batch   40/538 - Train Accuracy:  0.400, Validation Accuracy:  0.418, Loss:  2.104
Epoch   0 Batch   41/538 - Train Accuracy:  0.363, Validation Accuracy:  0.435, Loss:  2.281
Epoch   0 Batch   42/538 - Train Accuracy:  0.341, Validation Accuracy:  0.414, Loss:  2.221
Epoch   0 Batch   43/538 - Train Accuracy:  0.339, Validation Accuracy:  0.414, Loss:  2.250
Epoch   0 Batch   44/538 - Train Accuracy:  0.340, Validation Accuracy:  0.425, Loss:  2.236
Epoch   0 Batch   45/538 - Train Accuracy:  0.376, Validation Accuracy:  0.420, Loss:  2.086
Epoch   0 Batch   46/538 - Train Accuracy:  0.344, Validation Accuracy:  0.420, Loss:  2.148
Epoch   0 Batch   47/538 - Train Accuracy:  0.395, Validation Accuracy:  0.425, Loss:  2.044
Epoch   0 Batch   48/538 - Train Accuracy:  0.389, Validation Accuracy:  0.418, Loss:  2.000
Epoch   0 Batch   49/538 - Train Accuracy:  0.338, Validation Accuracy:  0.420, Loss:  2.122
Epoch   0 Batch   50/538 - Train Accuracy:  0.342, Validation Accuracy:  0.416, Loss:  2.022
Epoch   0 Batch   51/538 - Train Accuracy:  0.312, Validation Accuracy:  0.429, Loss:  2.162
Epoch   0 Batch   52/538 - Train Accuracy:  0.354, Validation Accuracy:  0.412, Loss:  2.001
Epoch   0 Batch   53/538 - Train Accuracy:  0.395, Validation Accuracy:  0.416, Loss:  1.814
Epoch   0 Batch   54/538 - Train Accuracy:  0.366, Validation Accuracy:  0.428, Loss:  1.933
Epoch   0 Batch   55/538 - Train Accuracy:  0.359, Validation Accuracy:  0.429, Loss:  1.953
Epoch   0 Batch   56/538 - Train Accuracy:  0.375, Validation Accuracy:  0.421, Loss:  1.859
Epoch   0 Batch   57/538 - Train Accuracy:  0.335, Validation Accuracy:  0.421, Loss:  1.934
Epoch   0 Batch   58/538 - Train Accuracy:  0.326, Validation Accuracy:  0.423, Loss:  1.899
Epoch   0 Batch   59/538 - Train Accuracy:  0.349, Validation Accuracy:  0.423, Loss:  1.866
Epoch   0 Batch   60/538 - Train Accuracy:  0.345, Validation Accuracy:  0.421, Loss:  1.826
Epoch   0 Batch   61/538 - Train Accuracy:  0.355, Validation Accuracy:  0.430, Loss:  1.792
Epoch   0 Batch   62/538 - Train Accuracy:  0.382, Validation Accuracy:  0.432, Loss:  1.739
Epoch   0 Batch   63/538 - Train Accuracy:  0.397, Validation Accuracy:  0.422, Loss:  1.696
Epoch   0 Batch   64/538 - Train Accuracy:  0.386, Validation Accuracy:  0.427, Loss:  1.706
Epoch   0 Batch   65/538 - Train Accuracy:  0.340, Validation Accuracy:  0.423, Loss:  1.774
Epoch   0 Batch   66/538 - Train Accuracy:  0.382, Validation Accuracy:  0.427, Loss:  1.653
Epoch   0 Batch   67/538 - Train Accuracy:  0.354, Validation Accuracy:  0.419, Loss:  1.699
Epoch   0 Batch   68/538 - Train Accuracy:  0.391, Validation Accuracy:  0.430, Loss:  1.572
Epoch   0 Batch   69/538 - Train Accuracy:  0.355, Validation Accuracy:  0.432, Loss:  1.667
Epoch   0 Batch   70/538 - Train Accuracy:  0.380, Validation Accuracy:  0.429, Loss:  1.588
Epoch   0 Batch   71/538 - Train Accuracy:  0.368, Validation Accuracy:  0.423, Loss:  1.636
Epoch   0 Batch   72/538 - Train Accuracy:  0.384, Validation Accuracy:  0.419, Loss:  1.552
Epoch   0 Batch   73/538 - Train Accuracy:  0.348, Validation Accuracy:  0.418, Loss:  1.621
Epoch   0 Batch   74/538 - Train Accuracy:  0.378, Validation Accuracy:  0.433, Loss:  1.538
Epoch   0 Batch   75/538 - Train Accuracy:  0.396, Validation Accuracy:  0.430, Loss:  1.530
Epoch   0 Batch   76/538 - Train Accuracy:  0.358, Validation Accuracy:  0.435, Loss:  1.595
Epoch   0 Batch   77/538 - Train Accuracy:  0.372, Validation Accuracy:  0.450, Loss:  1.552
Epoch   0 Batch   78/538 - Train Accuracy:  0.413, Validation Accuracy:  0.451, Loss:  1.507
Epoch   0 Batch   79/538 - Train Accuracy:  0.401, Validation Accuracy:  0.452, Loss:  1.432
Epoch   0 Batch   80/538 - Train Accuracy:  0.370, Validation Accuracy:  0.442, Loss:  1.530
Epoch   0 Batch   81/538 - Train Accuracy:  0.389, Validation Accuracy:  0.455, Loss:  1.505
Epoch   0 Batch   82/538 - Train Accuracy:  0.394, Validation Accuracy:  0.460, Loss:  1.461
Epoch   0 Batch   83/538 - Train Accuracy:  0.400, Validation Accuracy:  0.461, Loss:  1.481
Epoch   0 Batch   84/538 - Train Accuracy:  0.421, Validation Accuracy:  0.465, Loss:  1.412
Epoch   0 Batch   85/538 - Train Accuracy:  0.452, Validation Accuracy:  0.470, Loss:  1.328
Epoch   0 Batch   86/538 - Train Accuracy:  0.411, Validation Accuracy:  0.462, Loss:  1.453
Epoch   0 Batch   87/538 - Train Accuracy:  0.401, Validation Accuracy:  0.459, Loss:  1.413
Epoch   0 Batch   88/538 - Train Accuracy:  0.415, Validation Accuracy:  0.456, Loss:  1.416
Epoch   0 Batch   89/538 - Train Accuracy:  0.410, Validation Accuracy:  0.455, Loss:  1.400
Epoch   0 Batch   90/538 - Train Accuracy:  0.414, Validation Accuracy:  0.449, Loss:  1.353
Epoch   0 Batch   91/538 - Train Accuracy:  0.363, Validation Accuracy:  0.438, Loss:  1.391
Epoch   0 Batch   92/538 - Train Accuracy:  0.375, Validation Accuracy:  0.435, Loss:  1.375
Epoch   0 Batch   93/538 - Train Accuracy:  0.352, Validation Accuracy:  0.434, Loss:  1.348
Epoch   0 Batch   94/538 - Train Accuracy:  0.370, Validation Accuracy:  0.435, Loss:  1.369
Epoch   0 Batch   95/538 - Train Accuracy:  0.454, Validation Accuracy:  0.458, Loss:  1.233
Epoch   0 Batch   96/538 - Train Accuracy:  0.439, Validation Accuracy:  0.460, Loss:  1.236
Epoch   0 Batch   97/538 - Train Accuracy:  0.392, Validation Accuracy:  0.460, Loss:  1.311
Epoch   0 Batch   98/538 - Train Accuracy:  0.431, Validation Accuracy:  0.461, Loss:  1.227
Epoch   0 Batch   99/538 - Train Accuracy:  0.394, Validation Accuracy:  0.457, Loss:  1.315
Epoch   0 Batch  100/538 - Train Accuracy:  0.404, Validation Accuracy:  0.460, Loss:  1.263
Epoch   0 Batch  101/538 - Train Accuracy:  0.418, Validation Accuracy:  0.474, Loss:  1.280
Epoch   0 Batch  102/538 - Train Accuracy:  0.421, Validation Accuracy:  0.471, Loss:  1.302
Epoch   0 Batch  103/538 - Train Accuracy:  0.412, Validation Accuracy:  0.461, Loss:  1.261
Epoch   0 Batch  104/538 - Train Accuracy:  0.419, Validation Accuracy:  0.452, Loss:  1.223
Epoch   0 Batch  105/538 - Train Accuracy:  0.422, Validation Accuracy:  0.462, Loss:  1.190
Epoch   0 Batch  106/538 - Train Accuracy:  0.412, Validation Accuracy:  0.478, Loss:  1.228
Epoch   0 Batch  107/538 - Train Accuracy:  0.414, Validation Accuracy:  0.487, Loss:  1.256
Epoch   0 Batch  108/538 - Train Accuracy:  0.437, Validation Accuracy:  0.488, Loss:  1.238
Epoch   0 Batch  109/538 - Train Accuracy:  0.431, Validation Accuracy:  0.479, Loss:  1.204
Epoch   0 Batch  110/538 - Train Accuracy:  0.403, Validation Accuracy:  0.467, Loss:  1.239
Epoch   0 Batch  111/538 - Train Accuracy:  0.451, Validation Accuracy:  0.478, Loss:  1.161
Epoch   0 Batch  112/538 - Train Accuracy:  0.415, Validation Accuracy:  0.489, Loss:  1.212
Epoch   0 Batch  113/538 - Train Accuracy:  0.426, Validation Accuracy:  0.479, Loss:  1.224
Epoch   0 Batch  114/538 - Train Accuracy:  0.463, Validation Accuracy:  0.485, Loss:  1.136
Epoch   0 Batch  115/538 - Train Accuracy:  0.444, Validation Accuracy:  0.499, Loss:  1.159
Epoch   0 Batch  116/538 - Train Accuracy:  0.451, Validation Accuracy:  0.487, Loss:  1.185
Epoch   0 Batch  117/538 - Train Accuracy:  0.458, Validation Accuracy:  0.483, Loss:  1.128
Epoch   0 Batch  118/538 - Train Accuracy:  0.469, Validation Accuracy:  0.477, Loss:  1.104
Epoch   0 Batch  119/538 - Train Accuracy:  0.450, Validation Accuracy:  0.478, Loss:  1.084
Epoch   0 Batch  120/538 - Train Accuracy:  0.439, Validation Accuracy:  0.480, Loss:  1.118
Epoch   0 Batch  121/538 - Train Accuracy:  0.458, Validation Accuracy:  0.504, Loss:  1.066
Epoch   0 Batch  122/538 - Train Accuracy:  0.456, Validation Accuracy:  0.498, Loss:  1.073
Epoch   0 Batch  123/538 - Train Accuracy:  0.478, Validation Accuracy:  0.496, Loss:  1.062
Epoch   0 Batch  124/538 - Train Accuracy:  0.486, Validation Accuracy:  0.500, Loss:  1.020
Epoch   0 Batch  125/538 - Train Accuracy:  0.474, Validation Accuracy:  0.509, Loss:  1.067
Epoch   0 Batch  126/538 - Train Accuracy:  0.480, Validation Accuracy:  0.504, Loss:  1.048
Epoch   0 Batch  127/538 - Train Accuracy:  0.428, Validation Accuracy:  0.499, Loss:  1.125
Epoch   0 Batch  128/538 - Train Accuracy:  0.457, Validation Accuracy:  0.496, Loss:  1.058
Epoch   0 Batch  129/538 - Train Accuracy:  0.459, Validation Accuracy:  0.491, Loss:  1.029
Epoch   0 Batch  130/538 - Train Accuracy:  0.462, Validation Accuracy:  0.482, Loss:  1.036
Epoch   0 Batch  131/538 - Train Accuracy:  0.427, Validation Accuracy:  0.489, Loss:  1.071
Epoch   0 Batch  132/538 - Train Accuracy:  0.445, Validation Accuracy:  0.485, Loss:  1.009
Epoch   0 Batch  133/538 - Train Accuracy:  0.454, Validation Accuracy:  0.484, Loss:  0.976
Epoch   0 Batch  134/538 - Train Accuracy:  0.430, Validation Accuracy:  0.481, Loss:  1.096
Epoch   0 Batch  135/538 - Train Accuracy:  0.456, Validation Accuracy:  0.485, Loss:  1.042
Epoch   0 Batch  136/538 - Train Accuracy:  0.452, Validation Accuracy:  0.490, Loss:  1.021
Epoch   0 Batch  137/538 - Train Accuracy:  0.438, Validation Accuracy:  0.488, Loss:  1.025
Epoch   0 Batch  138/538 - Train Accuracy:  0.485, Validation Accuracy:  0.521, Loss:  1.017
Epoch   0 Batch  139/538 - Train Accuracy:  0.440, Validation Accuracy:  0.507, Loss:  1.080
Epoch   0 Batch  140/538 - Train Accuracy:  0.422, Validation Accuracy:  0.512, Loss:  1.099
Epoch   0 Batch  141/538 - Train Accuracy:  0.448, Validation Accuracy:  0.511, Loss:  1.071
Epoch   0 Batch  142/538 - Train Accuracy:  0.497, Validation Accuracy:  0.501, Loss:  0.971
Epoch   0 Batch  143/538 - Train Accuracy:  0.458, Validation Accuracy:  0.500, Loss:  1.030
Epoch   0 Batch  144/538 - Train Accuracy:  0.463, Validation Accuracy:  0.506, Loss:  1.029
Epoch   0 Batch  145/538 - Train Accuracy:  0.468, Validation Accuracy:  0.517, Loss:  1.022
Epoch   0 Batch  146/538 - Train Accuracy:  0.470, Validation Accuracy:  0.504, Loss:  0.943
Epoch   0 Batch  147/538 - Train Accuracy:  0.480, Validation Accuracy:  0.510, Loss:  0.970
Epoch   0 Batch  148/538 - Train Accuracy:  0.445, Validation Accuracy:  0.515, Loss:  1.055
Epoch   0 Batch  149/538 - Train Accuracy:  0.455, Validation Accuracy:  0.520, Loss:  0.983
Epoch   0 Batch  150/538 - Train Accuracy:  0.471, Validation Accuracy:  0.511, Loss:  0.983
Epoch   0 Batch  151/538 - Train Accuracy:  0.478, Validation Accuracy:  0.522, Loss:  0.956
Epoch   0 Batch  152/538 - Train Accuracy:  0.462, Validation Accuracy:  0.516, Loss:  0.932
Epoch   0 Batch  153/538 - Train Accuracy:  0.471, Validation Accuracy:  0.526, Loss:  0.998
Epoch   0 Batch  154/538 - Train Accuracy:  0.470, Validation Accuracy:  0.524, Loss:  0.935
Epoch   0 Batch  155/538 - Train Accuracy:  0.523, Validation Accuracy:  0.521, Loss:  0.944
Epoch   0 Batch  156/538 - Train Accuracy:  0.466, Validation Accuracy:  0.507, Loss:  0.965
Epoch   0 Batch  157/538 - Train Accuracy:  0.476, Validation Accuracy:  0.518, Loss:  0.913
Epoch   0 Batch  158/538 - Train Accuracy:  0.484, Validation Accuracy:  0.522, Loss:  0.974
Epoch   0 Batch  159/538 - Train Accuracy:  0.463, Validation Accuracy:  0.525, Loss:  0.975
Epoch   0 Batch  160/538 - Train Accuracy:  0.470, Validation Accuracy:  0.516, Loss:  0.912
Epoch   0 Batch  161/538 - Train Accuracy:  0.461, Validation Accuracy:  0.522, Loss:  0.957
Epoch   0 Batch  162/538 - Train Accuracy:  0.507, Validation Accuracy:  0.524, Loss:  0.914
Epoch   0 Batch  163/538 - Train Accuracy:  0.483, Validation Accuracy:  0.523, Loss:  0.949
Epoch   0 Batch  164/538 - Train Accuracy:  0.467, Validation Accuracy:  0.512, Loss:  0.955
Epoch   0 Batch  165/538 - Train Accuracy:  0.497, Validation Accuracy:  0.510, Loss:  0.861
Epoch   0 Batch  166/538 - Train Accuracy:  0.475, Validation Accuracy:  0.518, Loss:  0.917
Epoch   0 Batch  167/538 - Train Accuracy:  0.502, Validation Accuracy:  0.499, Loss:  0.882
Epoch   0 Batch  168/538 - Train Accuracy:  0.449, Validation Accuracy:  0.496, Loss:  0.960
Epoch   0 Batch  169/538 - Train Accuracy:  0.458, Validation Accuracy:  0.497, Loss:  0.903
Epoch   0 Batch  170/538 - Train Accuracy:  0.475, Validation Accuracy:  0.497, Loss:  0.884
Epoch   0 Batch  171/538 - Train Accuracy:  0.440, Validation Accuracy:  0.495, Loss:  0.930
Epoch   0 Batch  172/538 - Train Accuracy:  0.486, Validation Accuracy:  0.499, Loss:  0.870
Epoch   0 Batch  173/538 - Train Accuracy:  0.484, Validation Accuracy:  0.499, Loss:  0.860
Epoch   0 Batch  174/538 - Train Accuracy:  0.449, Validation Accuracy:  0.499, Loss:  0.921
Epoch   0 Batch  175/538 - Train Accuracy:  0.443, Validation Accuracy:  0.511, Loss:  0.920
Epoch   0 Batch  176/538 - Train Accuracy:  0.495, Validation Accuracy:  0.531, Loss:  0.924
Epoch   0 Batch  177/538 - Train Accuracy:  0.514, Validation Accuracy:  0.528, Loss:  0.882
Epoch   0 Batch  178/538 - Train Accuracy:  0.521, Validation Accuracy:  0.534, Loss:  0.841
Epoch   0 Batch  179/538 - Train Accuracy:  0.496, Validation Accuracy:  0.545, Loss:  0.895
Epoch   0 Batch  180/538 - Train Accuracy:  0.541, Validation Accuracy:  0.550, Loss:  0.862
Epoch   0 Batch  181/538 - Train Accuracy:  0.464, Validation Accuracy:  0.537, Loss:  0.917
Epoch   0 Batch  182/538 - Train Accuracy:  0.462, Validation Accuracy:  0.526, Loss:  0.892
Epoch   0 Batch  183/538 - Train Accuracy:  0.505, Validation Accuracy:  0.532, Loss:  0.824
Epoch   0 Batch  184/538 - Train Accuracy:  0.507, Validation Accuracy:  0.549, Loss:  0.823
Epoch   0 Batch  185/538 - Train Accuracy:  0.492, Validation Accuracy:  0.542, Loss:  0.860
Epoch   0 Batch  186/538 - Train Accuracy:  0.492, Validation Accuracy:  0.537, Loss:  0.845
Epoch   0 Batch  187/538 - Train Accuracy:  0.534, Validation Accuracy:  0.536, Loss:  0.805
Epoch   0 Batch  188/538 - Train Accuracy:  0.500, Validation Accuracy:  0.546, Loss:  0.863
Epoch   0 Batch  189/538 - Train Accuracy:  0.504, Validation Accuracy:  0.528, Loss:  0.865
Epoch   0 Batch  190/538 - Train Accuracy:  0.505, Validation Accuracy:  0.534, Loss:  0.872
Epoch   0 Batch  191/538 - Train Accuracy:  0.533, Validation Accuracy:  0.534, Loss:  0.817
Epoch   0 Batch  192/538 - Train Accuracy:  0.528, Validation Accuracy:  0.545, Loss:  0.820
Epoch   0 Batch  193/538 - Train Accuracy:  0.536, Validation Accuracy:  0.538, Loss:  0.810
Epoch   0 Batch  194/538 - Train Accuracy:  0.499, Validation Accuracy:  0.545, Loss:  0.867
Epoch   0 Batch  195/538 - Train Accuracy:  0.520, Validation Accuracy:  0.552, Loss:  0.810
Epoch   0 Batch  196/538 - Train Accuracy:  0.528, Validation Accuracy:  0.553, Loss:  0.815
Epoch   0 Batch  197/538 - Train Accuracy:  0.539, Validation Accuracy:  0.549, Loss:  0.802
Epoch   0 Batch  198/538 - Train Accuracy:  0.552, Validation Accuracy:  0.552, Loss:  0.807
Epoch   0 Batch  199/538 - Train Accuracy:  0.497, Validation Accuracy:  0.551, Loss:  0.845
Epoch   0 Batch  200/538 - Train Accuracy:  0.525, Validation Accuracy:  0.556, Loss:  0.810
Epoch   0 Batch  201/538 - Train Accuracy:  0.533, Validation Accuracy:  0.547, Loss:  0.794
Epoch   0 Batch  202/538 - Train Accuracy:  0.487, Validation Accuracy:  0.547, Loss:  0.851
Epoch   0 Batch  203/538 - Train Accuracy:  0.507, Validation Accuracy:  0.539, Loss:  0.855
Epoch   0 Batch  204/538 - Train Accuracy:  0.491, Validation Accuracy:  0.548, Loss:  0.823
Epoch   0 Batch  205/538 - Train Accuracy:  0.521, Validation Accuracy:  0.552, Loss:  0.786
Epoch   0 Batch  206/538 - Train Accuracy:  0.503, Validation Accuracy:  0.550, Loss:  0.838
Epoch   0 Batch  207/538 - Train Accuracy:  0.519, Validation Accuracy:  0.551, Loss:  0.774
Epoch   0 Batch  208/538 - Train Accuracy:  0.496, Validation Accuracy:  0.557, Loss:  0.819
Epoch   0 Batch  209/538 - Train Accuracy:  0.509, Validation Accuracy:  0.566, Loss:  0.811
Epoch   0 Batch  210/538 - Train Accuracy:  0.531, Validation Accuracy:  0.555, Loss:  0.783
Epoch   0 Batch  211/538 - Train Accuracy:  0.499, Validation Accuracy:  0.539, Loss:  0.827
Epoch   0 Batch  212/538 - Train Accuracy:  0.544, Validation Accuracy:  0.542, Loss:  0.796
Epoch   0 Batch  213/538 - Train Accuracy:  0.509, Validation Accuracy:  0.534, Loss:  0.781
Epoch   0 Batch  214/538 - Train Accuracy:  0.516, Validation Accuracy:  0.539, Loss:  0.784
Epoch   0 Batch  215/538 - Train Accuracy:  0.515, Validation Accuracy:  0.553, Loss:  0.801
Epoch   0 Batch  216/538 - Train Accuracy:  0.496, Validation Accuracy:  0.551, Loss:  0.814
Epoch   0 Batch  217/538 - Train Accuracy:  0.567, Validation Accuracy:  0.552, Loss:  0.758
Epoch   0 Batch  218/538 - Train Accuracy:  0.522, Validation Accuracy:  0.556, Loss:  0.787
Epoch   0 Batch  219/538 - Train Accuracy:  0.506, Validation Accuracy:  0.538, Loss:  0.830
Epoch   0 Batch  220/538 - Train Accuracy:  0.519, Validation Accuracy:  0.554, Loss:  0.772
Epoch   0 Batch  221/538 - Train Accuracy:  0.562, Validation Accuracy:  0.557, Loss:  0.746
Epoch   0 Batch  222/538 - Train Accuracy:  0.532, Validation Accuracy:  0.546, Loss:  0.748
Epoch   0 Batch  223/538 - Train Accuracy:  0.510, Validation Accuracy:  0.538, Loss:  0.804
Epoch   0 Batch  224/538 - Train Accuracy:  0.516, Validation Accuracy:  0.561, Loss:  0.805
Epoch   0 Batch  225/538 - Train Accuracy:  0.556, Validation Accuracy:  0.550, Loss:  0.759
Epoch   0 Batch  226/538 - Train Accuracy:  0.542, Validation Accuracy:  0.543, Loss:  0.742
Epoch   0 Batch  227/538 - Train Accuracy:  0.548, Validation Accuracy:  0.552, Loss:  0.731
Epoch   0 Batch  228/538 - Train Accuracy:  0.523, Validation Accuracy:  0.559, Loss:  0.737
Epoch   0 Batch  229/538 - Train Accuracy:  0.531, Validation Accuracy:  0.559, Loss:  0.758
Epoch   0 Batch  230/538 - Train Accuracy:  0.498, Validation Accuracy:  0.546, Loss:  0.770
Epoch   0 Batch  231/538 - Train Accuracy:  0.520, Validation Accuracy:  0.549, Loss:  0.761
Epoch   0 Batch  232/538 - Train Accuracy:  0.533, Validation Accuracy:  0.559, Loss:  0.759
Epoch   0 Batch  233/538 - Train Accuracy:  0.572, Validation Accuracy:  0.563, Loss:  0.755
Epoch   0 Batch  234/538 - Train Accuracy:  0.518, Validation Accuracy:  0.559, Loss:  0.772
Epoch   0 Batch  235/538 - Train Accuracy:  0.534, Validation Accuracy:  0.550, Loss:  0.727
Epoch   0 Batch  236/538 - Train Accuracy:  0.528, Validation Accuracy:  0.559, Loss:  0.771
Epoch   0 Batch  237/538 - Train Accuracy:  0.543, Validation Accuracy:  0.563, Loss:  0.729
Epoch   0 Batch  238/538 - Train Accuracy:  0.582, Validation Accuracy:  0.567, Loss:  0.722
Epoch   0 Batch  239/538 - Train Accuracy:  0.539, Validation Accuracy:  0.569, Loss:  0.760
Epoch   0 Batch  240/538 - Train Accuracy:  0.541, Validation Accuracy:  0.563, Loss:  0.767
Epoch   0 Batch  241/538 - Train Accuracy:  0.541, Validation Accuracy:  0.564, Loss:  0.744
Epoch   0 Batch  242/538 - Train Accuracy:  0.566, Validation Accuracy:  0.569, Loss:  0.738
Epoch   0 Batch  243/538 - Train Accuracy:  0.512, Validation Accuracy:  0.565, Loss:  0.778
Epoch   0 Batch  244/538 - Train Accuracy:  0.555, Validation Accuracy:  0.547, Loss:  0.712
Epoch   0 Batch  245/538 - Train Accuracy:  0.525, Validation Accuracy:  0.545, Loss:  0.763
Epoch   0 Batch  246/538 - Train Accuracy:  0.564, Validation Accuracy:  0.554, Loss:  0.696
Epoch   0 Batch  247/538 - Train Accuracy:  0.551, Validation Accuracy:  0.569, Loss:  0.746
Epoch   0 Batch  248/538 - Train Accuracy:  0.555, Validation Accuracy:  0.576, Loss:  0.733
Epoch   0 Batch  249/538 - Train Accuracy:  0.557, Validation Accuracy:  0.574, Loss:  0.700
Epoch   0 Batch  250/538 - Train Accuracy:  0.545, Validation Accuracy:  0.576, Loss:  0.720
Epoch   0 Batch  251/538 - Train Accuracy:  0.543, Validation Accuracy:  0.570, Loss:  0.740
Epoch   0 Batch  252/538 - Train Accuracy:  0.571, Validation Accuracy:  0.577, Loss:  0.681
Epoch   0 Batch  253/538 - Train Accuracy:  0.565, Validation Accuracy:  0.573, Loss:  0.692
Epoch   0 Batch  254/538 - Train Accuracy:  0.561, Validation Accuracy:  0.562, Loss:  0.730
Epoch   0 Batch  255/538 - Train Accuracy:  0.562, Validation Accuracy:  0.565, Loss:  0.720
Epoch   0 Batch  256/538 - Train Accuracy:  0.567, Validation Accuracy:  0.576, Loss:  0.726
Epoch   0 Batch  257/538 - Train Accuracy:  0.595, Validation Accuracy:  0.579, Loss:  0.698
Epoch   0 Batch  258/538 - Train Accuracy:  0.595, Validation Accuracy:  0.578, Loss:  0.693
Epoch   0 Batch  259/538 - Train Accuracy:  0.579, Validation Accuracy:  0.576, Loss:  0.690
Epoch   0 Batch  260/538 - Train Accuracy:  0.555, Validation Accuracy:  0.571, Loss:  0.710
Epoch   0 Batch  261/538 - Train Accuracy:  0.543, Validation Accuracy:  0.568, Loss:  0.733
Epoch   0 Batch  262/538 - Train Accuracy:  0.507, Validation Accuracy:  0.572, Loss:  0.706
Epoch   0 Batch  263/538 - Train Accuracy:  0.557, Validation Accuracy:  0.577, Loss:  0.711
Epoch   0 Batch  264/538 - Train Accuracy:  0.546, Validation Accuracy:  0.573, Loss:  0.717
Epoch   0 Batch  265/538 - Train Accuracy:  0.516, Validation Accuracy:  0.573, Loss:  0.734
Epoch   0 Batch  266/538 - Train Accuracy:  0.566, Validation Accuracy:  0.561, Loss:  0.694
Epoch   0 Batch  267/538 - Train Accuracy:  0.527, Validation Accuracy:  0.563, Loss:  0.703
Epoch   0 Batch  268/538 - Train Accuracy:  0.581, Validation Accuracy:  0.566, Loss:  0.670
Epoch   0 Batch  269/538 - Train Accuracy:  0.546, Validation Accuracy:  0.576, Loss:  0.698
Epoch   0 Batch  270/538 - Train Accuracy:  0.563, Validation Accuracy:  0.575, Loss:  0.706
Epoch   0 Batch  271/538 - Train Accuracy:  0.555, Validation Accuracy:  0.576, Loss:  0.709
Epoch   0 Batch  272/538 - Train Accuracy:  0.538, Validation Accuracy:  0.576, Loss:  0.740
Epoch   0 Batch  273/538 - Train Accuracy:  0.559, Validation Accuracy:  0.576, Loss:  0.709
Epoch   0 Batch  274/538 - Train Accuracy:  0.537, Validation Accuracy:  0.579, Loss:  0.741
Epoch   0 Batch  275/538 - Train Accuracy:  0.562, Validation Accuracy:  0.581, Loss:  0.723
Epoch   0 Batch  276/538 - Train Accuracy:  0.581, Validation Accuracy:  0.582, Loss:  0.709
Epoch   0 Batch  277/538 - Train Accuracy:  0.569, Validation Accuracy:  0.583, Loss:  0.697
Epoch   0 Batch  278/538 - Train Accuracy:  0.563, Validation Accuracy:  0.583, Loss:  0.703
Epoch   0 Batch  279/538 - Train Accuracy:  0.579, Validation Accuracy:  0.579, Loss:  0.682
Epoch   0 Batch  280/538 - Train Accuracy:  0.604, Validation Accuracy:  0.578, Loss:  0.656
Epoch   0 Batch  281/538 - Train Accuracy:  0.567, Validation Accuracy:  0.579, Loss:  0.710
Epoch   0 Batch  282/538 - Train Accuracy:  0.593, Validation Accuracy:  0.585, Loss:  0.675
Epoch   0 Batch  283/538 - Train Accuracy:  0.584, Validation Accuracy:  0.597, Loss:  0.685
Epoch   0 Batch  284/538 - Train Accuracy:  0.606, Validation Accuracy:  0.599, Loss:  0.688
Epoch   0 Batch  285/538 - Train Accuracy:  0.602, Validation Accuracy:  0.602, Loss:  0.644
Epoch   0 Batch  286/538 - Train Accuracy:  0.571, Validation Accuracy:  0.594, Loss:  0.687
Epoch   0 Batch  287/538 - Train Accuracy:  0.609, Validation Accuracy:  0.594, Loss:  0.657
Epoch   0 Batch  288/538 - Train Accuracy:  0.563, Validation Accuracy:  0.588, Loss:  0.693
Epoch   0 Batch  289/538 - Train Accuracy:  0.605, Validation Accuracy:  0.580, Loss:  0.628
Epoch   0 Batch  290/538 - Train Accuracy:  0.547, Validation Accuracy:  0.580, Loss:  0.683
Epoch   0 Batch  291/538 - Train Accuracy:  0.587, Validation Accuracy:  0.578, Loss:  0.660
Epoch   0 Batch  292/538 - Train Accuracy:  0.604, Validation Accuracy:  0.579, Loss:  0.644
Epoch   0 Batch  293/538 - Train Accuracy:  0.586, Validation Accuracy:  0.585, Loss:  0.650
Epoch   0 Batch  294/538 - Train Accuracy:  0.565, Validation Accuracy:  0.593, Loss:  0.708
Epoch   0 Batch  295/538 - Train Accuracy:  0.613, Validation Accuracy:  0.597, Loss:  0.626
Epoch   0 Batch  296/538 - Train Accuracy:  0.591, Validation Accuracy:  0.605, Loss:  0.664
Epoch   0 Batch  297/538 - Train Accuracy:  0.561, Validation Accuracy:  0.597, Loss:  0.692
Epoch   0 Batch  298/538 - Train Accuracy:  0.591, Validation Accuracy:  0.606, Loss:  0.656
Epoch   0 Batch  299/538 - Train Accuracy:  0.592, Validation Accuracy:  0.596, Loss:  0.659
Epoch   0 Batch  300/538 - Train Accuracy:  0.607, Validation Accuracy:  0.595, Loss:  0.659
Epoch   0 Batch  301/538 - Train Accuracy:  0.582, Validation Accuracy:  0.590, Loss:  0.678
Epoch   0 Batch  302/538 - Train Accuracy:  0.624, Validation Accuracy:  0.586, Loss:  0.643
Epoch   0 Batch  303/538 - Train Accuracy:  0.635, Validation Accuracy:  0.586, Loss:  0.639
Epoch   0 Batch  304/538 - Train Accuracy:  0.577, Validation Accuracy:  0.590, Loss:  0.676
Epoch   0 Batch  305/538 - Train Accuracy:  0.595, Validation Accuracy:  0.599, Loss:  0.640
Epoch   0 Batch  306/538 - Train Accuracy:  0.600, Validation Accuracy:  0.603, Loss:  0.659
Epoch   0 Batch  307/538 - Train Accuracy:  0.598, Validation Accuracy:  0.602, Loss:  0.664
Epoch   0 Batch  308/538 - Train Accuracy:  0.597, Validation Accuracy:  0.602, Loss:  0.643
Epoch   0 Batch  309/538 - Train Accuracy:  0.579, Validation Accuracy:  0.602, Loss:  0.662
Epoch   0 Batch  310/538 - Train Accuracy:  0.587, Validation Accuracy:  0.594, Loss:  0.656
Epoch   0 Batch  311/538 - Train Accuracy:  0.602, Validation Accuracy:  0.607, Loss:  0.644
Epoch   0 Batch  312/538 - Train Accuracy:  0.640, Validation Accuracy:  0.611, Loss:  0.598
Epoch   0 Batch  313/538 - Train Accuracy:  0.589, Validation Accuracy:  0.612, Loss:  0.688
Epoch   0 Batch  314/538 - Train Accuracy:  0.602, Validation Accuracy:  0.616, Loss:  0.661
Epoch   0 Batch  315/538 - Train Accuracy:  0.586, Validation Accuracy:  0.613, Loss:  0.645
Epoch   0 Batch  316/538 - Train Accuracy:  0.602, Validation Accuracy:  0.614, Loss:  0.637
Epoch   0 Batch  317/538 - Train Accuracy:  0.605, Validation Accuracy:  0.609, Loss:  0.650
Epoch   0 Batch  318/538 - Train Accuracy:  0.588, Validation Accuracy:  0.603, Loss:  0.646
Epoch   0 Batch  319/538 - Train Accuracy:  0.604, Validation Accuracy:  0.609, Loss:  0.638
Epoch   0 Batch  320/538 - Train Accuracy:  0.611, Validation Accuracy:  0.613, Loss:  0.638
Epoch   0 Batch  321/538 - Train Accuracy:  0.609, Validation Accuracy:  0.614, Loss:  0.622
Epoch   0 Batch  322/538 - Train Accuracy:  0.613, Validation Accuracy:  0.613, Loss:  0.626
Epoch   0 Batch  323/538 - Train Accuracy:  0.607, Validation Accuracy:  0.616, Loss:  0.623
Epoch   0 Batch  324/538 - Train Accuracy:  0.578, Validation Accuracy:  0.621, Loss:  0.672
Epoch   0 Batch  325/538 - Train Accuracy:  0.598, Validation Accuracy:  0.617, Loss:  0.629
Epoch   0 Batch  326/538 - Train Accuracy:  0.589, Validation Accuracy:  0.616, Loss:  0.648
Epoch   0 Batch  327/538 - Train Accuracy:  0.572, Validation Accuracy:  0.602, Loss:  0.686
Epoch   0 Batch  328/538 - Train Accuracy:  0.599, Validation Accuracy:  0.604, Loss:  0.677
Epoch   0 Batch  329/538 - Train Accuracy:  0.608, Validation Accuracy:  0.609, Loss:  0.669
Epoch   0 Batch  330/538 - Train Accuracy:  0.611, Validation Accuracy:  0.607, Loss:  0.641
Epoch   0 Batch  331/538 - Train Accuracy:  0.584, Validation Accuracy:  0.604, Loss:  0.655
Epoch   0 Batch  332/538 - Train Accuracy:  0.547, Validation Accuracy:  0.572, Loss:  0.678
Epoch   0 Batch  333/538 - Train Accuracy:  0.581, Validation Accuracy:  0.585, Loss:  0.652
Epoch   0 Batch  334/538 - Train Accuracy:  0.624, Validation Accuracy:  0.600, Loss:  0.604
Epoch   0 Batch  335/538 - Train Accuracy:  0.594, Validation Accuracy:  0.601, Loss:  0.643
Epoch   0 Batch  336/538 - Train Accuracy:  0.597, Validation Accuracy:  0.600, Loss:  0.642
Epoch   0 Batch  337/538 - Train Accuracy:  0.595, Validation Accuracy:  0.597, Loss:  0.629
Epoch   0 Batch  338/538 - Train Accuracy:  0.583, Validation Accuracy:  0.612, Loss:  0.646
Epoch   0 Batch  339/538 - Train Accuracy:  0.606, Validation Accuracy:  0.607, Loss:  0.621
Epoch   0 Batch  340/538 - Train Accuracy:  0.578, Validation Accuracy:  0.613, Loss:  0.669
Epoch   0 Batch  341/538 - Train Accuracy:  0.584, Validation Accuracy:  0.607, Loss:  0.646
Epoch   0 Batch  342/538 - Train Accuracy:  0.596, Validation Accuracy:  0.593, Loss:  0.624
Epoch   0 Batch  343/538 - Train Accuracy:  0.579, Validation Accuracy:  0.595, Loss:  0.664
Epoch   0 Batch  344/538 - Train Accuracy:  0.582, Validation Accuracy:  0.600, Loss:  0.647
Epoch   0 Batch  345/538 - Train Accuracy:  0.617, Validation Accuracy:  0.603, Loss:  0.627
Epoch   0 Batch  346/538 - Train Accuracy:  0.585, Validation Accuracy:  0.594, Loss:  0.631
Epoch   0 Batch  347/538 - Train Accuracy:  0.585, Validation Accuracy:  0.590, Loss:  0.637
Epoch   0 Batch  348/538 - Train Accuracy:  0.601, Validation Accuracy:  0.594, Loss:  0.603
Epoch   0 Batch  349/538 - Train Accuracy:  0.560, Validation Accuracy:  0.601, Loss:  0.635
Epoch   0 Batch  350/538 - Train Accuracy:  0.611, Validation Accuracy:  0.609, Loss:  0.627
Epoch   0 Batch  351/538 - Train Accuracy:  0.583, Validation Accuracy:  0.610, Loss:  0.654
Epoch   0 Batch  352/538 - Train Accuracy:  0.634, Validation Accuracy:  0.614, Loss:  0.626
Epoch   0 Batch  353/538 - Train Accuracy:  0.603, Validation Accuracy:  0.616, Loss:  0.657
Epoch   0 Batch  354/538 - Train Accuracy:  0.582, Validation Accuracy:  0.616, Loss:  0.648
Epoch   0 Batch  355/538 - Train Accuracy:  0.597, Validation Accuracy:  0.616, Loss:  0.641
Epoch   0 Batch  356/538 - Train Accuracy:  0.618, Validation Accuracy:  0.619, Loss:  0.582
Epoch   0 Batch  357/538 - Train Accuracy:  0.618, Validation Accuracy:  0.619, Loss:  0.617
Epoch   0 Batch  358/538 - Train Accuracy:  0.598, Validation Accuracy:  0.616, Loss:  0.627
Epoch   0 Batch  359/538 - Train Accuracy:  0.607, Validation Accuracy:  0.613, Loss:  0.620
Epoch   0 Batch  360/538 - Train Accuracy:  0.606, Validation Accuracy:  0.609, Loss:  0.631
Epoch   0 Batch  361/538 - Train Accuracy:  0.596, Validation Accuracy:  0.602, Loss:  0.606
Epoch   0 Batch  362/538 - Train Accuracy:  0.605, Validation Accuracy:  0.609, Loss:  0.599
Epoch   0 Batch  363/538 - Train Accuracy:  0.616, Validation Accuracy:  0.612, Loss:  0.591
Epoch   0 Batch  364/538 - Train Accuracy:  0.575, Validation Accuracy:  0.613, Loss:  0.652
Epoch   0 Batch  365/538 - Train Accuracy:  0.618, Validation Accuracy:  0.613, Loss:  0.604
Epoch   0 Batch  366/538 - Train Accuracy:  0.615, Validation Accuracy:  0.614, Loss:  0.622
Epoch   0 Batch  367/538 - Train Accuracy:  0.621, Validation Accuracy:  0.614, Loss:  0.604
Epoch   0 Batch  368/538 - Train Accuracy:  0.669, Validation Accuracy:  0.614, Loss:  0.556
Epoch   0 Batch  369/538 - Train Accuracy:  0.613, Validation Accuracy:  0.614, Loss:  0.615
Epoch   0 Batch  370/538 - Train Accuracy:  0.603, Validation Accuracy:  0.614, Loss:  0.637
Epoch   0 Batch  371/538 - Train Accuracy:  0.612, Validation Accuracy:  0.615, Loss:  0.593
Epoch   0 Batch  372/538 - Train Accuracy:  0.612, Validation Accuracy:  0.617, Loss:  0.610
Epoch   0 Batch  373/538 - Train Accuracy:  0.593, Validation Accuracy:  0.616, Loss:  0.602
Epoch   0 Batch  374/538 - Train Accuracy:  0.591, Validation Accuracy:  0.618, Loss:  0.622
Epoch   0 Batch  375/538 - Train Accuracy:  0.622, Validation Accuracy:  0.621, Loss:  0.573
Epoch   0 Batch  376/538 - Train Accuracy:  0.602, Validation Accuracy:  0.618, Loss:  0.614
Epoch   0 Batch  377/538 - Train Accuracy:  0.602, Validation Accuracy:  0.621, Loss:  0.608
Epoch   0 Batch  378/538 - Train Accuracy:  0.627, Validation Accuracy:  0.620, Loss:  0.575
Epoch   0 Batch  379/538 - Train Accuracy:  0.626, Validation Accuracy:  0.620, Loss:  0.578
Epoch   0 Batch  380/538 - Train Accuracy:  0.588, Validation Accuracy:  0.620, Loss:  0.604
Epoch   0 Batch  381/538 - Train Accuracy:  0.611, Validation Accuracy:  0.623, Loss:  0.567
Epoch   0 Batch  382/538 - Train Accuracy:  0.608, Validation Accuracy:  0.623, Loss:  0.617
Epoch   0 Batch  383/538 - Train Accuracy:  0.611, Validation Accuracy:  0.622, Loss:  0.609
Epoch   0 Batch  384/538 - Train Accuracy:  0.647, Validation Accuracy:  0.622, Loss:  0.580
Epoch   0 Batch  385/538 - Train Accuracy:  0.632, Validation Accuracy:  0.621, Loss:  0.579
Epoch   0 Batch  386/538 - Train Accuracy:  0.611, Validation Accuracy:  0.623, Loss:  0.611
Epoch   0 Batch  387/538 - Train Accuracy:  0.609, Validation Accuracy:  0.621, Loss:  0.600
Epoch   0 Batch  388/538 - Train Accuracy:  0.616, Validation Accuracy:  0.624, Loss:  0.591
Epoch   0 Batch  389/538 - Train Accuracy:  0.595, Validation Accuracy:  0.624, Loss:  0.616
Epoch   0 Batch  390/538 - Train Accuracy:  0.636, Validation Accuracy:  0.625, Loss:  0.584
Epoch   0 Batch  391/538 - Train Accuracy:  0.621, Validation Accuracy:  0.629, Loss:  0.579
Epoch   0 Batch  392/538 - Train Accuracy:  0.622, Validation Accuracy:  0.626, Loss:  0.587
Epoch   0 Batch  393/538 - Train Accuracy:  0.625, Validation Accuracy:  0.620, Loss:  0.570
Epoch   0 Batch  394/538 - Train Accuracy:  0.569, Validation Accuracy:  0.625, Loss:  0.618
Epoch   0 Batch  395/538 - Train Accuracy:  0.584, Validation Accuracy:  0.627, Loss:  0.605
Epoch   0 Batch  396/538 - Train Accuracy:  0.593, Validation Accuracy:  0.623, Loss:  0.596
Epoch   0 Batch  397/538 - Train Accuracy:  0.605, Validation Accuracy:  0.615, Loss:  0.601
Epoch   0 Batch  398/538 - Train Accuracy:  0.603, Validation Accuracy:  0.621, Loss:  0.602
Epoch   0 Batch  399/538 - Train Accuracy:  0.596, Validation Accuracy:  0.624, Loss:  0.616
Epoch   0 Batch  400/538 - Train Accuracy:  0.604, Validation Accuracy:  0.620, Loss:  0.577
Epoch   0 Batch  401/538 - Train Accuracy:  0.607, Validation Accuracy:  0.624, Loss:  0.604
Epoch   0 Batch  402/538 - Train Accuracy:  0.616, Validation Accuracy:  0.628, Loss:  0.583
Epoch   0 Batch  403/538 - Train Accuracy:  0.614, Validation Accuracy:  0.631, Loss:  0.598
Epoch   0 Batch  404/538 - Train Accuracy:  0.634, Validation Accuracy:  0.634, Loss:  0.573
Epoch   0 Batch  405/538 - Train Accuracy:  0.618, Validation Accuracy:  0.636, Loss:  0.568
Epoch   0 Batch  406/538 - Train Accuracy:  0.626, Validation Accuracy:  0.639, Loss:  0.562
Epoch   0 Batch  407/538 - Train Accuracy:  0.643, Validation Accuracy:  0.633, Loss:  0.592
Epoch   0 Batch  408/538 - Train Accuracy:  0.591, Validation Accuracy:  0.632, Loss:  0.614
Epoch   0 Batch  409/538 - Train Accuracy:  0.615, Validation Accuracy:  0.631, Loss:  0.615
Epoch   0 Batch  410/538 - Train Accuracy:  0.622, Validation Accuracy:  0.632, Loss:  0.589
Epoch   0 Batch  411/538 - Train Accuracy:  0.625, Validation Accuracy:  0.630, Loss:  0.556
Epoch   0 Batch  412/538 - Train Accuracy:  0.639, Validation Accuracy:  0.630, Loss:  0.557
Epoch   0 Batch  413/538 - Train Accuracy:  0.623, Validation Accuracy:  0.629, Loss:  0.582
Epoch   0 Batch  414/538 - Train Accuracy:  0.607, Validation Accuracy:  0.631, Loss:  0.593
Epoch   0 Batch  415/538 - Train Accuracy:  0.586, Validation Accuracy:  0.623, Loss:  0.598
Epoch   0 Batch  416/538 - Train Accuracy:  0.652, Validation Accuracy:  0.627, Loss:  0.554
Epoch   0 Batch  417/538 - Train Accuracy:  0.629, Validation Accuracy:  0.634, Loss:  0.575
Epoch   0 Batch  418/538 - Train Accuracy:  0.603, Validation Accuracy:  0.630, Loss:  0.596
Epoch   0 Batch  419/538 - Train Accuracy:  0.628, Validation Accuracy:  0.636, Loss:  0.561
Epoch   0 Batch  420/538 - Train Accuracy:  0.634, Validation Accuracy:  0.630, Loss:  0.572
Epoch   0 Batch  421/538 - Train Accuracy:  0.632, Validation Accuracy:  0.628, Loss:  0.545
Epoch   0 Batch  422/538 - Train Accuracy:  0.637, Validation Accuracy:  0.631, Loss:  0.576
Epoch   0 Batch  423/538 - Train Accuracy:  0.629, Validation Accuracy:  0.635, Loss:  0.585
Epoch   0 Batch  424/538 - Train Accuracy:  0.623, Validation Accuracy:  0.638, Loss:  0.567
Epoch   0 Batch  425/538 - Train Accuracy:  0.629, Validation Accuracy:  0.632, Loss:  0.566
Epoch   0 Batch  426/538 - Train Accuracy:  0.653, Validation Accuracy:  0.638, Loss:  0.557
Epoch   0 Batch  427/538 - Train Accuracy:  0.608, Validation Accuracy:  0.636, Loss:  0.585
Epoch   0 Batch  428/538 - Train Accuracy:  0.649, Validation Accuracy:  0.642, Loss:  0.549
Epoch   0 Batch  429/538 - Train Accuracy:  0.642, Validation Accuracy:  0.643, Loss:  0.556
Epoch   0 Batch  430/538 - Train Accuracy:  0.642, Validation Accuracy:  0.635, Loss:  0.569
Epoch   0 Batch  431/538 - Train Accuracy:  0.623, Validation Accuracy:  0.633, Loss:  0.561
Epoch   0 Batch  432/538 - Train Accuracy:  0.683, Validation Accuracy:  0.628, Loss:  0.525
Epoch   0 Batch  433/538 - Train Accuracy:  0.614, Validation Accuracy:  0.640, Loss:  0.584
Epoch   0 Batch  434/538 - Train Accuracy:  0.609, Validation Accuracy:  0.643, Loss:  0.573
Epoch   0 Batch  435/538 - Train Accuracy:  0.608, Validation Accuracy:  0.636, Loss:  0.562
Epoch   0 Batch  436/538 - Train Accuracy:  0.619, Validation Accuracy:  0.648, Loss:  0.576
Epoch   0 Batch  437/538 - Train Accuracy:  0.628, Validation Accuracy:  0.649, Loss:  0.567
Epoch   0 Batch  438/538 - Train Accuracy:  0.642, Validation Accuracy:  0.640, Loss:  0.554
Epoch   0 Batch  439/538 - Train Accuracy:  0.651, Validation Accuracy:  0.633, Loss:  0.553
Epoch   0 Batch  440/538 - Train Accuracy:  0.647, Validation Accuracy:  0.647, Loss:  0.579
Epoch   0 Batch  441/538 - Train Accuracy:  0.598, Validation Accuracy:  0.642, Loss:  0.569
Epoch   0 Batch  442/538 - Train Accuracy:  0.652, Validation Accuracy:  0.640, Loss:  0.504
Epoch   0 Batch  443/538 - Train Accuracy:  0.662, Validation Accuracy:  0.639, Loss:  0.538
Epoch   0 Batch  444/538 - Train Accuracy:  0.676, Validation Accuracy:  0.640, Loss:  0.525
Epoch   0 Batch  445/538 - Train Accuracy:  0.655, Validation Accuracy:  0.653, Loss:  0.542
Epoch   0 Batch  446/538 - Train Accuracy:  0.665, Validation Accuracy:  0.648, Loss:  0.522
Epoch   0 Batch  447/538 - Train Accuracy:  0.612, Validation Accuracy:  0.642, Loss:  0.558
Epoch   0 Batch  448/538 - Train Accuracy:  0.639, Validation Accuracy:  0.633, Loss:  0.518
Epoch   0 Batch  449/538 - Train Accuracy:  0.643, Validation Accuracy:  0.648, Loss:  0.566
Epoch   0 Batch  450/538 - Train Accuracy:  0.653, Validation Accuracy:  0.649, Loss:  0.552
Epoch   0 Batch  451/538 - Train Accuracy:  0.626, Validation Accuracy:  0.644, Loss:  0.548
Epoch   0 Batch  452/538 - Train Accuracy:  0.641, Validation Accuracy:  0.645, Loss:  0.529
Epoch   0 Batch  453/538 - Train Accuracy:  0.623, Validation Accuracy:  0.642, Loss:  0.561
Epoch   0 Batch  454/538 - Train Accuracy:  0.650, Validation Accuracy:  0.635, Loss:  0.531
Epoch   0 Batch  455/538 - Train Accuracy:  0.664, Validation Accuracy:  0.639, Loss:  0.493
Epoch   0 Batch  456/538 - Train Accuracy:  0.694, Validation Accuracy:  0.627, Loss:  0.470
Epoch   0 Batch  457/538 - Train Accuracy:  0.634, Validation Accuracy:  0.642, Loss:  0.556
Epoch   0 Batch  458/538 - Train Accuracy:  0.632, Validation Accuracy:  0.645, Loss:  0.520
Epoch   0 Batch  459/538 - Train Accuracy:  0.648, Validation Accuracy:  0.632, Loss:  0.540
Epoch   0 Batch  460/538 - Train Accuracy:  0.619, Validation Accuracy:  0.631, Loss:  0.517
Epoch   0 Batch  461/538 - Train Accuracy:  0.608, Validation Accuracy:  0.644, Loss:  0.572
Epoch   0 Batch  462/538 - Train Accuracy:  0.654, Validation Accuracy:  0.639, Loss:  0.531
Epoch   0 Batch  463/538 - Train Accuracy:  0.621, Validation Accuracy:  0.632, Loss:  0.548
Epoch   0 Batch  464/538 - Train Accuracy:  0.637, Validation Accuracy:  0.636, Loss:  0.544
Epoch   0 Batch  465/538 - Train Accuracy:  0.607, Validation Accuracy:  0.638, Loss:  0.556
Epoch   0 Batch  466/538 - Train Accuracy:  0.601, Validation Accuracy:  0.625, Loss:  0.546
Epoch   0 Batch  467/538 - Train Accuracy:  0.631, Validation Accuracy:  0.648, Loss:  0.542
Epoch   0 Batch  468/538 - Train Accuracy:  0.653, Validation Accuracy:  0.645, Loss:  0.550
Epoch   0 Batch  469/538 - Train Accuracy:  0.627, Validation Accuracy:  0.641, Loss:  0.541
Epoch   0 Batch  470/538 - Train Accuracy:  0.652, Validation Accuracy:  0.647, Loss:  0.516
Epoch   0 Batch  471/538 - Train Accuracy:  0.641, Validation Accuracy:  0.654, Loss:  0.523
Epoch   0 Batch  472/538 - Train Accuracy:  0.645, Validation Accuracy:  0.645, Loss:  0.511
Epoch   0 Batch  473/538 - Train Accuracy:  0.619, Validation Accuracy:  0.638, Loss:  0.541
Epoch   0 Batch  474/538 - Train Accuracy:  0.651, Validation Accuracy:  0.638, Loss:  0.499
Epoch   0 Batch  475/538 - Train Accuracy:  0.637, Validation Accuracy:  0.642, Loss:  0.513
Epoch   0 Batch  476/538 - Train Accuracy:  0.619, Validation Accuracy:  0.643, Loss:  0.532
Epoch   0 Batch  477/538 - Train Accuracy:  0.652, Validation Accuracy:  0.646, Loss:  0.525
Epoch   0 Batch  478/538 - Train Accuracy:  0.686, Validation Accuracy:  0.646, Loss:  0.497
Epoch   0 Batch  479/538 - Train Accuracy:  0.671, Validation Accuracy:  0.639, Loss:  0.499
Epoch   0 Batch  480/538 - Train Accuracy:  0.646, Validation Accuracy:  0.648, Loss:  0.507
Epoch   0 Batch  481/538 - Train Accuracy:  0.661, Validation Accuracy:  0.635, Loss:  0.498
Epoch   0 Batch  482/538 - Train Accuracy:  0.663, Validation Accuracy:  0.634, Loss:  0.468
Epoch   0 Batch  483/538 - Train Accuracy:  0.629, Validation Accuracy:  0.638, Loss:  0.529
Epoch   0 Batch  484/538 - Train Accuracy:  0.668, Validation Accuracy:  0.625, Loss:  0.505
Epoch   0 Batch  485/538 - Train Accuracy:  0.649, Validation Accuracy:  0.629, Loss:  0.504
Epoch   0 Batch  486/538 - Train Accuracy:  0.659, Validation Accuracy:  0.641, Loss:  0.494
Epoch   0 Batch  487/538 - Train Accuracy:  0.640, Validation Accuracy:  0.635, Loss:  0.489
Epoch   0 Batch  488/538 - Train Accuracy:  0.649, Validation Accuracy:  0.645, Loss:  0.509
Epoch   0 Batch  489/538 - Train Accuracy:  0.633, Validation Accuracy:  0.648, Loss:  0.534
Epoch   0 Batch  490/538 - Train Accuracy:  0.645, Validation Accuracy:  0.647, Loss:  0.505
Epoch   0 Batch  491/538 - Train Accuracy:  0.625, Validation Accuracy:  0.639, Loss:  0.537
Epoch   0 Batch  492/538 - Train Accuracy:  0.645, Validation Accuracy:  0.642, Loss:  0.520
Epoch   0 Batch  493/538 - Train Accuracy:  0.639, Validation Accuracy:  0.652, Loss:  0.495
Epoch   0 Batch  494/538 - Train Accuracy:  0.644, Validation Accuracy:  0.660, Loss:  0.515
Epoch   0 Batch  495/538 - Train Accuracy:  0.642, Validation Accuracy:  0.654, Loss:  0.521
Epoch   0 Batch  496/538 - Train Accuracy:  0.634, Validation Accuracy:  0.644, Loss:  0.505
Epoch   0 Batch  497/538 - Train Accuracy:  0.662, Validation Accuracy:  0.631, Loss:  0.488
Epoch   0 Batch  498/538 - Train Accuracy:  0.626, Validation Accuracy:  0.650, Loss:  0.504
Epoch   0 Batch  499/538 - Train Accuracy:  0.661, Validation Accuracy:  0.650, Loss:  0.482
Epoch   0 Batch  500/538 - Train Accuracy:  0.678, Validation Accuracy:  0.657, Loss:  0.462
Epoch   0 Batch  501/538 - Train Accuracy:  0.656, Validation Accuracy:  0.644, Loss:  0.495
Epoch   0 Batch  502/538 - Train Accuracy:  0.654, Validation Accuracy:  0.653, Loss:  0.501
Epoch   0 Batch  503/538 - Train Accuracy:  0.666, Validation Accuracy:  0.646, Loss:  0.484
Epoch   0 Batch  504/538 - Train Accuracy:  0.630, Validation Accuracy:  0.647, Loss:  0.493
Epoch   0 Batch  505/538 - Train Accuracy:  0.634, Validation Accuracy:  0.649, Loss:  0.494
Epoch   0 Batch  506/538 - Train Accuracy:  0.648, Validation Accuracy:  0.651, Loss:  0.492
Epoch   0 Batch  507/538 - Train Accuracy:  0.620, Validation Accuracy:  0.655, Loss:  0.510
Epoch   0 Batch  508/538 - Train Accuracy:  0.660, Validation Accuracy:  0.652, Loss:  0.491
Epoch   0 Batch  509/538 - Train Accuracy:  0.624, Validation Accuracy:  0.661, Loss:  0.510
Epoch   0 Batch  510/538 - Train Accuracy:  0.662, Validation Accuracy:  0.651, Loss:  0.490
Epoch   0 Batch  511/538 - Train Accuracy:  0.670, Validation Accuracy:  0.649, Loss:  0.478
Epoch   0 Batch  512/538 - Train Accuracy:  0.664, Validation Accuracy:  0.649, Loss:  0.474
Epoch   0 Batch  513/538 - Train Accuracy:  0.642, Validation Accuracy:  0.649, Loss:  0.498
Epoch   0 Batch  514/538 - Train Accuracy:  0.626, Validation Accuracy:  0.660, Loss:  0.501
Epoch   0 Batch  515/538 - Train Accuracy:  0.647, Validation Accuracy:  0.645, Loss:  0.484
Epoch   0 Batch  516/538 - Train Accuracy:  0.631, Validation Accuracy:  0.657, Loss:  0.493
Epoch   0 Batch  517/538 - Train Accuracy:  0.663, Validation Accuracy:  0.663, Loss:  0.469
Epoch   0 Batch  518/538 - Train Accuracy:  0.626, Validation Accuracy:  0.641, Loss:  0.504
Epoch   0 Batch  519/538 - Train Accuracy:  0.644, Validation Accuracy:  0.645, Loss:  0.470
Epoch   0 Batch  520/538 - Train Accuracy:  0.635, Validation Accuracy:  0.644, Loss:  0.495
Epoch   0 Batch  521/538 - Train Accuracy:  0.646, Validation Accuracy:  0.654, Loss:  0.508
Epoch   0 Batch  522/538 - Train Accuracy:  0.614, Validation Accuracy:  0.643, Loss:  0.493
Epoch   0 Batch  523/538 - Train Accuracy:  0.633, Validation Accuracy:  0.660, Loss:  0.493
Epoch   0 Batch  524/538 - Train Accuracy:  0.632, Validation Accuracy:  0.652, Loss:  0.511
Epoch   0 Batch  525/538 - Train Accuracy:  0.680, Validation Accuracy:  0.673, Loss:  0.470
Epoch   0 Batch  526/538 - Train Accuracy:  0.671, Validation Accuracy:  0.674, Loss:  0.464
Epoch   0 Batch  527/538 - Train Accuracy:  0.664, Validation Accuracy:  0.665, Loss:  0.486
Epoch   0 Batch  528/538 - Train Accuracy:  0.643, Validation Accuracy:  0.668, Loss:  0.511
Epoch   0 Batch  529/538 - Train Accuracy:  0.651, Validation Accuracy:  0.663, Loss:  0.471
Epoch   0 Batch  530/538 - Train Accuracy:  0.664, Validation Accuracy:  0.672, Loss:  0.499
Epoch   0 Batch  531/538 - Train Accuracy:  0.664, Validation Accuracy:  0.661, Loss:  0.490
Epoch   0 Batch  532/538 - Train Accuracy:  0.660, Validation Accuracy:  0.663, Loss:  0.481
Epoch   0 Batch  533/538 - Train Accuracy:  0.705, Validation Accuracy:  0.659, Loss:  0.479
Epoch   0 Batch  534/538 - Train Accuracy:  0.680, Validation Accuracy:  0.661, Loss:  0.453
Epoch   0 Batch  535/538 - Train Accuracy:  0.644, Validation Accuracy:  0.657, Loss:  0.463
Epoch   0 Batch  536/538 - Train Accuracy:  0.679, Validation Accuracy:  0.653, Loss:  0.475
Epoch   1 Batch    0/538 - Train Accuracy:  0.650, Validation Accuracy:  0.668, Loss:  0.478
Epoch   1 Batch    1/538 - Train Accuracy:  0.659, Validation Accuracy:  0.664, Loss:  0.478
Epoch   1 Batch    2/538 - Train Accuracy:  0.646, Validation Accuracy:  0.666, Loss:  0.489
Epoch   1 Batch    3/538 - Train Accuracy:  0.668, Validation Accuracy:  0.676, Loss:  0.480
Epoch   1 Batch    4/538 - Train Accuracy:  0.673, Validation Accuracy:  0.669, Loss:  0.469
Epoch   1 Batch    5/538 - Train Accuracy:  0.651, Validation Accuracy:  0.656, Loss:  0.475
Epoch   1 Batch    6/538 - Train Accuracy:  0.666, Validation Accuracy:  0.668, Loss:  0.459
Epoch   1 Batch    7/538 - Train Accuracy:  0.687, Validation Accuracy:  0.671, Loss:  0.468
Epoch   1 Batch    8/538 - Train Accuracy:  0.671, Validation Accuracy:  0.667, Loss:  0.463
Epoch   1 Batch    9/538 - Train Accuracy:  0.665, Validation Accuracy:  0.672, Loss:  0.471
Epoch   1 Batch   10/538 - Train Accuracy:  0.626, Validation Accuracy:  0.657, Loss:  0.492
Epoch   1 Batch   11/538 - Train Accuracy:  0.650, Validation Accuracy:  0.663, Loss:  0.471
Epoch   1 Batch   12/538 - Train Accuracy:  0.635, Validation Accuracy:  0.656, Loss:  0.480
Epoch   1 Batch   13/538 - Train Accuracy:  0.685, Validation Accuracy:  0.668, Loss:  0.447
Epoch   1 Batch   14/538 - Train Accuracy:  0.664, Validation Accuracy:  0.652, Loss:  0.462
Epoch   1 Batch   15/538 - Train Accuracy:  0.695, Validation Accuracy:  0.664, Loss:  0.445
Epoch   1 Batch   16/538 - Train Accuracy:  0.670, Validation Accuracy:  0.673, Loss:  0.438
Epoch   1 Batch   17/538 - Train Accuracy:  0.660, Validation Accuracy:  0.654, Loss:  0.464
Epoch   1 Batch   18/538 - Train Accuracy:  0.646, Validation Accuracy:  0.671, Loss:  0.486
Epoch   1 Batch   19/538 - Train Accuracy:  0.642, Validation Accuracy:  0.673, Loss:  0.481
Epoch   1 Batch   20/538 - Train Accuracy:  0.677, Validation Accuracy:  0.677, Loss:  0.466
Epoch   1 Batch   21/538 - Train Accuracy:  0.657, Validation Accuracy:  0.677, Loss:  0.482
Epoch   1 Batch   22/538 - Train Accuracy:  0.668, Validation Accuracy:  0.679, Loss:  0.473
Epoch   1 Batch   23/538 - Train Accuracy:  0.673, Validation Accuracy:  0.677, Loss:  0.475
Epoch   1 Batch   24/538 - Train Accuracy:  0.650, Validation Accuracy:  0.676, Loss:  0.450
Epoch   1 Batch   25/538 - Train Accuracy:  0.684, Validation Accuracy:  0.682, Loss:  0.460
Epoch   1 Batch   26/538 - Train Accuracy:  0.651, Validation Accuracy:  0.673, Loss:  0.477
Epoch   1 Batch   27/538 - Train Accuracy:  0.687, Validation Accuracy:  0.684, Loss:  0.453
Epoch   1 Batch   28/538 - Train Accuracy:  0.678, Validation Accuracy:  0.682, Loss:  0.415
Epoch   1 Batch   29/538 - Train Accuracy:  0.676, Validation Accuracy:  0.686, Loss:  0.435
Epoch   1 Batch   30/538 - Train Accuracy:  0.675, Validation Accuracy:  0.673, Loss:  0.470
Epoch   1 Batch   31/538 - Train Accuracy:  0.658, Validation Accuracy:  0.681, Loss:  0.426
Epoch   1 Batch   32/538 - Train Accuracy:  0.650, Validation Accuracy:  0.669, Loss:  0.429
Epoch   1 Batch   33/538 - Train Accuracy:  0.684, Validation Accuracy:  0.680, Loss:  0.448
Epoch   1 Batch   34/538 - Train Accuracy:  0.673, Validation Accuracy:  0.683, Loss:  0.456
Epoch   1 Batch   35/538 - Train Accuracy:  0.671, Validation Accuracy:  0.676, Loss:  0.444
Epoch   1 Batch   36/538 - Train Accuracy:  0.680, Validation Accuracy:  0.684, Loss:  0.437
Epoch   1 Batch   37/538 - Train Accuracy:  0.670, Validation Accuracy:  0.686, Loss:  0.446
Epoch   1 Batch   38/538 - Train Accuracy:  0.651, Validation Accuracy:  0.664, Loss:  0.447
Epoch   1 Batch   39/538 - Train Accuracy:  0.675, Validation Accuracy:  0.670, Loss:  0.449
Epoch   1 Batch   40/538 - Train Accuracy:  0.703, Validation Accuracy:  0.675, Loss:  0.389
Epoch   1 Batch   41/538 - Train Accuracy:  0.653, Validation Accuracy:  0.679, Loss:  0.447
Epoch   1 Batch   42/538 - Train Accuracy:  0.694, Validation Accuracy:  0.675, Loss:  0.440
Epoch   1 Batch   43/538 - Train Accuracy:  0.674, Validation Accuracy:  0.684, Loss:  0.452
Epoch   1 Batch   44/538 - Train Accuracy:  0.654, Validation Accuracy:  0.665, Loss:  0.458
Epoch   1 Batch   45/538 - Train Accuracy:  0.692, Validation Accuracy:  0.691, Loss:  0.427
Epoch   1 Batch   46/538 - Train Accuracy:  0.683, Validation Accuracy:  0.673, Loss:  0.428
Epoch   1 Batch   47/538 - Train Accuracy:  0.686, Validation Accuracy:  0.676, Loss:  0.437
Epoch   1 Batch   48/538 - Train Accuracy:  0.689, Validation Accuracy:  0.678, Loss:  0.400
Epoch   1 Batch   49/538 - Train Accuracy:  0.651, Validation Accuracy:  0.686, Loss:  0.463
Epoch   1 Batch   50/538 - Train Accuracy:  0.685, Validation Accuracy:  0.680, Loss:  0.444
Epoch   1 Batch   51/538 - Train Accuracy:  0.642, Validation Accuracy:  0.677, Loss:  0.483
Epoch   1 Batch   52/538 - Train Accuracy:  0.684, Validation Accuracy:  0.675, Loss:  0.449
Epoch   1 Batch   53/538 - Train Accuracy:  0.694, Validation Accuracy:  0.684, Loss:  0.405
Epoch   1 Batch   54/538 - Train Accuracy:  0.679, Validation Accuracy:  0.685, Loss:  0.431
Epoch   1 Batch   55/538 - Train Accuracy:  0.665, Validation Accuracy:  0.691, Loss:  0.439
Epoch   1 Batch   56/538 - Train Accuracy:  0.671, Validation Accuracy:  0.665, Loss:  0.415
Epoch   1 Batch   57/538 - Train Accuracy:  0.637, Validation Accuracy:  0.686, Loss:  0.467
Epoch   1 Batch   58/538 - Train Accuracy:  0.647, Validation Accuracy:  0.682, Loss:  0.450
Epoch   1 Batch   59/538 - Train Accuracy:  0.682, Validation Accuracy:  0.683, Loss:  0.442
Epoch   1 Batch   60/538 - Train Accuracy:  0.675, Validation Accuracy:  0.689, Loss:  0.428
Epoch   1 Batch   61/538 - Train Accuracy:  0.672, Validation Accuracy:  0.690, Loss:  0.422
Epoch   1 Batch   62/538 - Train Accuracy:  0.708, Validation Accuracy:  0.686, Loss:  0.412
Epoch   1 Batch   63/538 - Train Accuracy:  0.724, Validation Accuracy:  0.691, Loss:  0.393
Epoch   1 Batch   64/538 - Train Accuracy:  0.705, Validation Accuracy:  0.692, Loss:  0.403
Epoch   1 Batch   65/538 - Train Accuracy:  0.668, Validation Accuracy:  0.679, Loss:  0.431
Epoch   1 Batch   66/538 - Train Accuracy:  0.704, Validation Accuracy:  0.680, Loss:  0.397
Epoch   1 Batch   67/538 - Train Accuracy:  0.696, Validation Accuracy:  0.678, Loss:  0.414
Epoch   1 Batch   68/538 - Train Accuracy:  0.689, Validation Accuracy:  0.675, Loss:  0.400
Epoch   1 Batch   69/538 - Train Accuracy:  0.701, Validation Accuracy:  0.683, Loss:  0.425
Epoch   1 Batch   70/538 - Train Accuracy:  0.694, Validation Accuracy:  0.691, Loss:  0.410
Epoch   1 Batch   71/538 - Train Accuracy:  0.651, Validation Accuracy:  0.679, Loss:  0.429
Epoch   1 Batch   72/538 - Train Accuracy:  0.719, Validation Accuracy:  0.695, Loss:  0.425
Epoch   1 Batch   73/538 - Train Accuracy:  0.682, Validation Accuracy:  0.691, Loss:  0.428
Epoch   1 Batch   74/538 - Train Accuracy:  0.706, Validation Accuracy:  0.691, Loss:  0.395
Epoch   1 Batch   75/538 - Train Accuracy:  0.707, Validation Accuracy:  0.688, Loss:  0.397
Epoch   1 Batch   76/538 - Train Accuracy:  0.694, Validation Accuracy:  0.692, Loss:  0.425
Epoch   1 Batch   77/538 - Train Accuracy:  0.692, Validation Accuracy:  0.695, Loss:  0.412
Epoch   1 Batch   78/538 - Train Accuracy:  0.702, Validation Accuracy:  0.699, Loss:  0.409
Epoch   1 Batch   79/538 - Train Accuracy:  0.703, Validation Accuracy:  0.699, Loss:  0.398
Epoch   1 Batch   80/538 - Train Accuracy:  0.680, Validation Accuracy:  0.687, Loss:  0.431
Epoch   1 Batch   81/538 - Train Accuracy:  0.694, Validation Accuracy:  0.705, Loss:  0.423
Epoch   1 Batch   82/538 - Train Accuracy:  0.678, Validation Accuracy:  0.696, Loss:  0.421
Epoch   1 Batch   83/538 - Train Accuracy:  0.702, Validation Accuracy:  0.690, Loss:  0.420
Epoch   1 Batch   84/538 - Train Accuracy:  0.676, Validation Accuracy:  0.690, Loss:  0.416
Epoch   1 Batch   85/538 - Train Accuracy:  0.726, Validation Accuracy:  0.688, Loss:  0.383
Epoch   1 Batch   86/538 - Train Accuracy:  0.713, Validation Accuracy:  0.690, Loss:  0.422
Epoch   1 Batch   87/538 - Train Accuracy:  0.703, Validation Accuracy:  0.699, Loss:  0.406
Epoch   1 Batch   88/538 - Train Accuracy:  0.728, Validation Accuracy:  0.699, Loss:  0.404
Epoch   1 Batch   89/538 - Train Accuracy:  0.694, Validation Accuracy:  0.702, Loss:  0.405
Epoch   1 Batch   90/538 - Train Accuracy:  0.700, Validation Accuracy:  0.701, Loss:  0.416
Epoch   1 Batch   91/538 - Train Accuracy:  0.709, Validation Accuracy:  0.693, Loss:  0.405
Epoch   1 Batch   92/538 - Train Accuracy:  0.682, Validation Accuracy:  0.679, Loss:  0.420
Epoch   1 Batch   93/538 - Train Accuracy:  0.683, Validation Accuracy:  0.681, Loss:  0.417
Epoch   1 Batch   94/538 - Train Accuracy:  0.711, Validation Accuracy:  0.689, Loss:  0.400
Epoch   1 Batch   95/538 - Train Accuracy:  0.729, Validation Accuracy:  0.705, Loss:  0.369
Epoch   1 Batch   96/538 - Train Accuracy:  0.732, Validation Accuracy:  0.705, Loss:  0.377
Epoch   1 Batch   97/538 - Train Accuracy:  0.717, Validation Accuracy:  0.709, Loss:  0.397
Epoch   1 Batch   98/538 - Train Accuracy:  0.736, Validation Accuracy:  0.702, Loss:  0.384
Epoch   1 Batch   99/538 - Train Accuracy:  0.691, Validation Accuracy:  0.704, Loss:  0.397
Epoch   1 Batch  100/538 - Train Accuracy:  0.710, Validation Accuracy:  0.706, Loss:  0.391
Epoch   1 Batch  101/538 - Train Accuracy:  0.697, Validation Accuracy:  0.702, Loss:  0.410
Epoch   1 Batch  102/538 - Train Accuracy:  0.699, Validation Accuracy:  0.708, Loss:  0.401
Epoch   1 Batch  103/538 - Train Accuracy:  0.707, Validation Accuracy:  0.712, Loss:  0.386
Epoch   1 Batch  104/538 - Train Accuracy:  0.712, Validation Accuracy:  0.687, Loss:  0.378
Epoch   1 Batch  105/538 - Train Accuracy:  0.694, Validation Accuracy:  0.706, Loss:  0.381
Epoch   1 Batch  106/538 - Train Accuracy:  0.706, Validation Accuracy:  0.706, Loss:  0.382
Epoch   1 Batch  107/538 - Train Accuracy:  0.694, Validation Accuracy:  0.706, Loss:  0.409
Epoch   1 Batch  108/538 - Train Accuracy:  0.707, Validation Accuracy:  0.703, Loss:  0.398
Epoch   1 Batch  109/538 - Train Accuracy:  0.738, Validation Accuracy:  0.707, Loss:  0.383
Epoch   1 Batch  110/538 - Train Accuracy:  0.697, Validation Accuracy:  0.705, Loss:  0.395
Epoch   1 Batch  111/538 - Train Accuracy:  0.717, Validation Accuracy:  0.704, Loss:  0.374
Epoch   1 Batch  112/538 - Train Accuracy:  0.717, Validation Accuracy:  0.709, Loss:  0.390
Epoch   1 Batch  113/538 - Train Accuracy:  0.698, Validation Accuracy:  0.707, Loss:  0.394
Epoch   1 Batch  114/538 - Train Accuracy:  0.717, Validation Accuracy:  0.703, Loss:  0.368
Epoch   1 Batch  115/538 - Train Accuracy:  0.724, Validation Accuracy:  0.702, Loss:  0.397
Epoch   1 Batch  116/538 - Train Accuracy:  0.709, Validation Accuracy:  0.713, Loss:  0.383
Epoch   1 Batch  117/538 - Train Accuracy:  0.727, Validation Accuracy:  0.697, Loss:  0.372
Epoch   1 Batch  118/538 - Train Accuracy:  0.737, Validation Accuracy:  0.719, Loss:  0.355
Epoch   1 Batch  119/538 - Train Accuracy:  0.751, Validation Accuracy:  0.724, Loss:  0.355
Epoch   1 Batch  120/538 - Train Accuracy:  0.719, Validation Accuracy:  0.719, Loss:  0.363
Epoch   1 Batch  121/538 - Train Accuracy:  0.714, Validation Accuracy:  0.719, Loss:  0.367
Epoch   1 Batch  122/538 - Train Accuracy:  0.721, Validation Accuracy:  0.724, Loss:  0.363
Epoch   1 Batch  123/538 - Train Accuracy:  0.738, Validation Accuracy:  0.732, Loss:  0.346
Epoch   1 Batch  124/538 - Train Accuracy:  0.731, Validation Accuracy:  0.722, Loss:  0.349
Epoch   1 Batch  125/538 - Train Accuracy:  0.733, Validation Accuracy:  0.729, Loss:  0.362
Epoch   1 Batch  126/538 - Train Accuracy:  0.746, Validation Accuracy:  0.726, Loss:  0.347
Epoch   1 Batch  127/538 - Train Accuracy:  0.714, Validation Accuracy:  0.725, Loss:  0.394
Epoch   1 Batch  128/538 - Train Accuracy:  0.747, Validation Accuracy:  0.724, Loss:  0.366
Epoch   1 Batch  129/538 - Train Accuracy:  0.709, Validation Accuracy:  0.722, Loss:  0.352
Epoch   1 Batch  130/538 - Train Accuracy:  0.731, Validation Accuracy:  0.722, Loss:  0.352
Epoch   1 Batch  131/538 - Train Accuracy:  0.732, Validation Accuracy:  0.721, Loss:  0.366
Epoch   1 Batch  132/538 - Train Accuracy:  0.706, Validation Accuracy:  0.716, Loss:  0.361
Epoch   1 Batch  133/538 - Train Accuracy:  0.726, Validation Accuracy:  0.718, Loss:  0.353
Epoch   1 Batch  134/538 - Train Accuracy:  0.701, Validation Accuracy:  0.719, Loss:  0.386
Epoch   1 Batch  135/538 - Train Accuracy:  0.713, Validation Accuracy:  0.714, Loss:  0.368
Epoch   1 Batch  136/538 - Train Accuracy:  0.722, Validation Accuracy:  0.710, Loss:  0.364
Epoch   1 Batch  137/538 - Train Accuracy:  0.694, Validation Accuracy:  0.713, Loss:  0.366
Epoch   1 Batch  138/538 - Train Accuracy:  0.721, Validation Accuracy:  0.710, Loss:  0.359
Epoch   1 Batch  139/538 - Train Accuracy:  0.713, Validation Accuracy:  0.723, Loss:  0.393
Epoch   1 Batch  140/538 - Train Accuracy:  0.695, Validation Accuracy:  0.719, Loss:  0.382
Epoch   1 Batch  141/538 - Train Accuracy:  0.739, Validation Accuracy:  0.718, Loss:  0.370
Epoch   1 Batch  142/538 - Train Accuracy:  0.754, Validation Accuracy:  0.720, Loss:  0.355
Epoch   1 Batch  143/538 - Train Accuracy:  0.731, Validation Accuracy:  0.723, Loss:  0.375
Epoch   1 Batch  144/538 - Train Accuracy:  0.722, Validation Accuracy:  0.724, Loss:  0.386
Epoch   1 Batch  145/538 - Train Accuracy:  0.712, Validation Accuracy:  0.726, Loss:  0.371
Epoch   1 Batch  146/538 - Train Accuracy:  0.721, Validation Accuracy:  0.715, Loss:  0.349
Epoch   1 Batch  147/538 - Train Accuracy:  0.741, Validation Accuracy:  0.715, Loss:  0.336
Epoch   1 Batch  148/538 - Train Accuracy:  0.712, Validation Accuracy:  0.727, Loss:  0.374
Epoch   1 Batch  149/538 - Train Accuracy:  0.733, Validation Accuracy:  0.721, Loss:  0.345
Epoch   1 Batch  150/538 - Train Accuracy:  0.720, Validation Accuracy:  0.732, Loss:  0.361
Epoch   1 Batch  151/538 - Train Accuracy:  0.722, Validation Accuracy:  0.711, Loss:  0.352
Epoch   1 Batch  152/538 - Train Accuracy:  0.748, Validation Accuracy:  0.712, Loss:  0.338
Epoch   1 Batch  153/538 - Train Accuracy:  0.692, Validation Accuracy:  0.713, Loss:  0.362
Epoch   1 Batch  154/538 - Train Accuracy:  0.721, Validation Accuracy:  0.708, Loss:  0.342
Epoch   1 Batch  155/538 - Train Accuracy:  0.727, Validation Accuracy:  0.711, Loss:  0.356
Epoch   1 Batch  156/538 - Train Accuracy:  0.726, Validation Accuracy:  0.723, Loss:  0.345
Epoch   1 Batch  157/538 - Train Accuracy:  0.743, Validation Accuracy:  0.719, Loss:  0.326
Epoch   1 Batch  158/538 - Train Accuracy:  0.737, Validation Accuracy:  0.723, Loss:  0.373
Epoch   1 Batch  159/538 - Train Accuracy:  0.734, Validation Accuracy:  0.721, Loss:  0.358
Epoch   1 Batch  160/538 - Train Accuracy:  0.695, Validation Accuracy:  0.716, Loss:  0.348
Epoch   1 Batch  161/538 - Train Accuracy:  0.714, Validation Accuracy:  0.724, Loss:  0.358
Epoch   1 Batch  162/538 - Train Accuracy:  0.740, Validation Accuracy:  0.722, Loss:  0.326
Epoch   1 Batch  163/538 - Train Accuracy:  0.738, Validation Accuracy:  0.729, Loss:  0.360
Epoch   1 Batch  164/538 - Train Accuracy:  0.727, Validation Accuracy:  0.730, Loss:  0.364
Epoch   1 Batch  165/538 - Train Accuracy:  0.753, Validation Accuracy:  0.736, Loss:  0.317
Epoch   1 Batch  166/538 - Train Accuracy:  0.760, Validation Accuracy:  0.738, Loss:  0.330
Epoch   1 Batch  167/538 - Train Accuracy:  0.739, Validation Accuracy:  0.723, Loss:  0.337
Epoch   1 Batch  168/538 - Train Accuracy:  0.711, Validation Accuracy:  0.737, Loss:  0.377
Epoch   1 Batch  169/538 - Train Accuracy:  0.730, Validation Accuracy:  0.713, Loss:  0.332
Epoch   1 Batch  170/538 - Train Accuracy:  0.721, Validation Accuracy:  0.738, Loss:  0.350
Epoch   1 Batch  171/538 - Train Accuracy:  0.729, Validation Accuracy:  0.726, Loss:  0.349
Epoch   1 Batch  172/538 - Train Accuracy:  0.752, Validation Accuracy:  0.718, Loss:  0.330
Epoch   1 Batch  173/538 - Train Accuracy:  0.746, Validation Accuracy:  0.721, Loss:  0.316
Epoch   1 Batch  174/538 - Train Accuracy:  0.731, Validation Accuracy:  0.731, Loss:  0.344
Epoch   1 Batch  175/538 - Train Accuracy:  0.734, Validation Accuracy:  0.726, Loss:  0.337
Epoch   1 Batch  176/538 - Train Accuracy:  0.715, Validation Accuracy:  0.733, Loss:  0.351
Epoch   1 Batch  177/538 - Train Accuracy:  0.751, Validation Accuracy:  0.734, Loss:  0.325
Epoch   1 Batch  178/538 - Train Accuracy:  0.742, Validation Accuracy:  0.732, Loss:  0.315
Epoch   1 Batch  179/538 - Train Accuracy:  0.728, Validation Accuracy:  0.725, Loss:  0.332
Epoch   1 Batch  180/538 - Train Accuracy:  0.760, Validation Accuracy:  0.734, Loss:  0.321
Epoch   1 Batch  181/538 - Train Accuracy:  0.707, Validation Accuracy:  0.750, Loss:  0.347
Epoch   1 Batch  182/538 - Train Accuracy:  0.746, Validation Accuracy:  0.741, Loss:  0.331
Epoch   1 Batch  183/538 - Train Accuracy:  0.773, Validation Accuracy:  0.735, Loss:  0.300
Epoch   1 Batch  184/538 - Train Accuracy:  0.746, Validation Accuracy:  0.729, Loss:  0.309
Epoch   1 Batch  185/538 - Train Accuracy:  0.757, Validation Accuracy:  0.735, Loss:  0.308
Epoch   1 Batch  186/538 - Train Accuracy:  0.757, Validation Accuracy:  0.742, Loss:  0.323
Epoch   1 Batch  187/538 - Train Accuracy:  0.751, Validation Accuracy:  0.750, Loss:  0.309
Epoch   1 Batch  188/538 - Train Accuracy:  0.739, Validation Accuracy:  0.740, Loss:  0.331
Epoch   1 Batch  189/538 - Train Accuracy:  0.742, Validation Accuracy:  0.737, Loss:  0.328
Epoch   1 Batch  190/538 - Train Accuracy:  0.737, Validation Accuracy:  0.729, Loss:  0.341
Epoch   1 Batch  191/538 - Train Accuracy:  0.742, Validation Accuracy:  0.750, Loss:  0.315
Epoch   1 Batch  192/538 - Train Accuracy:  0.735, Validation Accuracy:  0.724, Loss:  0.314
Epoch   1 Batch  193/538 - Train Accuracy:  0.743, Validation Accuracy:  0.730, Loss:  0.314
Epoch   1 Batch  194/538 - Train Accuracy:  0.729, Validation Accuracy:  0.741, Loss:  0.337
Epoch   1 Batch  195/538 - Train Accuracy:  0.750, Validation Accuracy:  0.738, Loss:  0.311
Epoch   1 Batch  196/538 - Train Accuracy:  0.731, Validation Accuracy:  0.724, Loss:  0.312
Epoch   1 Batch  197/538 - Train Accuracy:  0.744, Validation Accuracy:  0.743, Loss:  0.311
Epoch   1 Batch  198/538 - Train Accuracy:  0.746, Validation Accuracy:  0.735, Loss:  0.317
Epoch   1 Batch  199/538 - Train Accuracy:  0.731, Validation Accuracy:  0.738, Loss:  0.349
Epoch   1 Batch  200/538 - Train Accuracy:  0.766, Validation Accuracy:  0.732, Loss:  0.316
Epoch   1 Batch  201/538 - Train Accuracy:  0.737, Validation Accuracy:  0.744, Loss:  0.308
Epoch   1 Batch  202/538 - Train Accuracy:  0.782, Validation Accuracy:  0.751, Loss:  0.322
Epoch   1 Batch  203/538 - Train Accuracy:  0.724, Validation Accuracy:  0.741, Loss:  0.330
Epoch   1 Batch  204/538 - Train Accuracy:  0.721, Validation Accuracy:  0.749, Loss:  0.322
Epoch   1 Batch  205/538 - Train Accuracy:  0.782, Validation Accuracy:  0.749, Loss:  0.298
Epoch   1 Batch  206/538 - Train Accuracy:  0.704, Validation Accuracy:  0.758, Loss:  0.324
Epoch   1 Batch  207/538 - Train Accuracy:  0.763, Validation Accuracy:  0.759, Loss:  0.298
Epoch   1 Batch  208/538 - Train Accuracy:  0.764, Validation Accuracy:  0.762, Loss:  0.321
Epoch   1 Batch  209/538 - Train Accuracy:  0.786, Validation Accuracy:  0.755, Loss:  0.299
Epoch   1 Batch  210/538 - Train Accuracy:  0.752, Validation Accuracy:  0.753, Loss:  0.306
Epoch   1 Batch  211/538 - Train Accuracy:  0.745, Validation Accuracy:  0.739, Loss:  0.321
Epoch   1 Batch  212/538 - Train Accuracy:  0.746, Validation Accuracy:  0.738, Loss:  0.305
Epoch   1 Batch  213/538 - Train Accuracy:  0.743, Validation Accuracy:  0.742, Loss:  0.298
Epoch   1 Batch  214/538 - Train Accuracy:  0.760, Validation Accuracy:  0.746, Loss:  0.295
Epoch   1 Batch  215/538 - Train Accuracy:  0.741, Validation Accuracy:  0.737, Loss:  0.304
Epoch   1 Batch  216/538 - Train Accuracy:  0.775, Validation Accuracy:  0.734, Loss:  0.318
Epoch   1 Batch  217/538 - Train Accuracy:  0.780, Validation Accuracy:  0.747, Loss:  0.305
Epoch   1 Batch  218/538 - Train Accuracy:  0.738, Validation Accuracy:  0.746, Loss:  0.305
Epoch   1 Batch  219/538 - Train Accuracy:  0.741, Validation Accuracy:  0.735, Loss:  0.319
Epoch   1 Batch  220/538 - Train Accuracy:  0.734, Validation Accuracy:  0.742, Loss:  0.288
Epoch   1 Batch  221/538 - Train Accuracy:  0.767, Validation Accuracy:  0.739, Loss:  0.285
Epoch   1 Batch  222/538 - Train Accuracy:  0.769, Validation Accuracy:  0.746, Loss:  0.284
Epoch   1 Batch  223/538 - Train Accuracy:  0.752, Validation Accuracy:  0.744, Loss:  0.312
Epoch   1 Batch  224/538 - Train Accuracy:  0.743, Validation Accuracy:  0.750, Loss:  0.314
Epoch   1 Batch  225/538 - Train Accuracy:  0.768, Validation Accuracy:  0.750, Loss:  0.293
Epoch   1 Batch  226/538 - Train Accuracy:  0.753, Validation Accuracy:  0.748, Loss:  0.284
Epoch   1 Batch  227/538 - Train Accuracy:  0.768, Validation Accuracy:  0.737, Loss:  0.280
Epoch   1 Batch  228/538 - Train Accuracy:  0.744, Validation Accuracy:  0.742, Loss:  0.284
Epoch   1 Batch  229/538 - Train Accuracy:  0.767, Validation Accuracy:  0.754, Loss:  0.298
Epoch   1 Batch  230/538 - Train Accuracy:  0.782, Validation Accuracy:  0.748, Loss:  0.298
Epoch   1 Batch  231/538 - Train Accuracy:  0.743, Validation Accuracy:  0.755, Loss:  0.287
Epoch   1 Batch  232/538 - Train Accuracy:  0.747, Validation Accuracy:  0.754, Loss:  0.298
Epoch   1 Batch  233/538 - Train Accuracy:  0.779, Validation Accuracy:  0.749, Loss:  0.290
Epoch   1 Batch  234/538 - Train Accuracy:  0.770, Validation Accuracy:  0.749, Loss:  0.301
Epoch   1 Batch  235/538 - Train Accuracy:  0.795, Validation Accuracy:  0.749, Loss:  0.288
Epoch   1 Batch  236/538 - Train Accuracy:  0.754, Validation Accuracy:  0.754, Loss:  0.314
Epoch   1 Batch  237/538 - Train Accuracy:  0.795, Validation Accuracy:  0.752, Loss:  0.280
Epoch   1 Batch  238/538 - Train Accuracy:  0.789, Validation Accuracy:  0.749, Loss:  0.287
Epoch   1 Batch  239/538 - Train Accuracy:  0.775, Validation Accuracy:  0.761, Loss:  0.294
Epoch   1 Batch  240/538 - Train Accuracy:  0.743, Validation Accuracy:  0.750, Loss:  0.286
Epoch   1 Batch  241/538 - Train Accuracy:  0.764, Validation Accuracy:  0.755, Loss:  0.302
Epoch   1 Batch  242/538 - Train Accuracy:  0.760, Validation Accuracy:  0.748, Loss:  0.278
Epoch   1 Batch  243/538 - Train Accuracy:  0.734, Validation Accuracy:  0.743, Loss:  0.314
Epoch   1 Batch  244/538 - Train Accuracy:  0.755, Validation Accuracy:  0.756, Loss:  0.283
Epoch   1 Batch  245/538 - Train Accuracy:  0.749, Validation Accuracy:  0.762, Loss:  0.299
Epoch   1 Batch  246/538 - Train Accuracy:  0.770, Validation Accuracy:  0.756, Loss:  0.268
Epoch   1 Batch  247/538 - Train Accuracy:  0.759, Validation Accuracy:  0.755, Loss:  0.285
Epoch   1 Batch  248/538 - Train Accuracy:  0.785, Validation Accuracy:  0.747, Loss:  0.291
Epoch   1 Batch  249/538 - Train Accuracy:  0.767, Validation Accuracy:  0.757, Loss:  0.270
Epoch   1 Batch  250/538 - Train Accuracy:  0.777, Validation Accuracy:  0.758, Loss:  0.283
Epoch   1 Batch  251/538 - Train Accuracy:  0.786, Validation Accuracy:  0.764, Loss:  0.291
Epoch   1 Batch  252/538 - Train Accuracy:  0.785, Validation Accuracy:  0.753, Loss:  0.273
Epoch   1 Batch  253/538 - Train Accuracy:  0.741, Validation Accuracy:  0.754, Loss:  0.273
Epoch   1 Batch  254/538 - Train Accuracy:  0.758, Validation Accuracy:  0.758, Loss:  0.289
Epoch   1 Batch  255/538 - Train Accuracy:  0.768, Validation Accuracy:  0.762, Loss:  0.278
Epoch   1 Batch  256/538 - Train Accuracy:  0.749, Validation Accuracy:  0.742, Loss:  0.286
Epoch   1 Batch  257/538 - Train Accuracy:  0.779, Validation Accuracy:  0.754, Loss:  0.273
Epoch   1 Batch  258/538 - Train Accuracy:  0.782, Validation Accuracy:  0.748, Loss:  0.273
Epoch   1 Batch  259/538 - Train Accuracy:  0.809, Validation Accuracy:  0.746, Loss:  0.261
Epoch   1 Batch  260/538 - Train Accuracy:  0.751, Validation Accuracy:  0.744, Loss:  0.277
Epoch   1 Batch  261/538 - Train Accuracy:  0.748, Validation Accuracy:  0.745, Loss:  0.284
Epoch   1 Batch  262/538 - Train Accuracy:  0.781, Validation Accuracy:  0.755, Loss:  0.268
Epoch   1 Batch  263/538 - Train Accuracy:  0.758, Validation Accuracy:  0.756, Loss:  0.265
Epoch   1 Batch  264/538 - Train Accuracy:  0.760, Validation Accuracy:  0.763, Loss:  0.275
Epoch   1 Batch  265/538 - Train Accuracy:  0.771, Validation Accuracy:  0.776, Loss:  0.284
Epoch   1 Batch  266/538 - Train Accuracy:  0.766, Validation Accuracy:  0.772, Loss:  0.271
Epoch   1 Batch  267/538 - Train Accuracy:  0.792, Validation Accuracy:  0.767, Loss:  0.268
Epoch   1 Batch  268/538 - Train Accuracy:  0.780, Validation Accuracy:  0.761, Loss:  0.254
Epoch   1 Batch  269/538 - Train Accuracy:  0.758, Validation Accuracy:  0.775, Loss:  0.258
Epoch   1 Batch  270/538 - Train Accuracy:  0.752, Validation Accuracy:  0.762, Loss:  0.261
Epoch   1 Batch  271/538 - Train Accuracy:  0.763, Validation Accuracy:  0.770, Loss:  0.266
Epoch   1 Batch  272/538 - Train Accuracy:  0.761, Validation Accuracy:  0.772, Loss:  0.285
Epoch   1 Batch  273/538 - Train Accuracy:  0.795, Validation Accuracy:  0.777, Loss:  0.268
Epoch   1 Batch  274/538 - Train Accuracy:  0.745, Validation Accuracy:  0.773, Loss:  0.282
Epoch   1 Batch  275/538 - Train Accuracy:  0.756, Validation Accuracy:  0.776, Loss:  0.276
Epoch   1 Batch  276/538 - Train Accuracy:  0.769, Validation Accuracy:  0.774, Loss:  0.269
Epoch   1 Batch  277/538 - Train Accuracy:  0.770, Validation Accuracy:  0.770, Loss:  0.262
Epoch   1 Batch  278/538 - Train Accuracy:  0.800, Validation Accuracy:  0.775, Loss:  0.257
Epoch   1 Batch  279/538 - Train Accuracy:  0.782, Validation Accuracy:  0.784, Loss:  0.251
Epoch   1 Batch  280/538 - Train Accuracy:  0.801, Validation Accuracy:  0.777, Loss:  0.251
Epoch   1 Batch  281/538 - Train Accuracy:  0.788, Validation Accuracy:  0.778, Loss:  0.263
Epoch   1 Batch  282/538 - Train Accuracy:  0.791, Validation Accuracy:  0.777, Loss:  0.265
Epoch   1 Batch  283/538 - Train Accuracy:  0.797, Validation Accuracy:  0.767, Loss:  0.258
Epoch   1 Batch  284/538 - Train Accuracy:  0.782, Validation Accuracy:  0.770, Loss:  0.268
Epoch   1 Batch  285/538 - Train Accuracy:  0.780, Validation Accuracy:  0.774, Loss:  0.232
Epoch   1 Batch  286/538 - Train Accuracy:  0.788, Validation Accuracy:  0.775, Loss:  0.254
Epoch   1 Batch  287/538 - Train Accuracy:  0.788, Validation Accuracy:  0.782, Loss:  0.244
Epoch   1 Batch  288/538 - Train Accuracy:  0.791, Validation Accuracy:  0.778, Loss:  0.251
Epoch   1 Batch  289/538 - Train Accuracy:  0.804, Validation Accuracy:  0.772, Loss:  0.232
Epoch   1 Batch  290/538 - Train Accuracy:  0.791, Validation Accuracy:  0.782, Loss:  0.244
Epoch   1 Batch  291/538 - Train Accuracy:  0.783, Validation Accuracy:  0.782, Loss:  0.246
Epoch   1 Batch  292/538 - Train Accuracy:  0.776, Validation Accuracy:  0.766, Loss:  0.233
Epoch   1 Batch  293/538 - Train Accuracy:  0.803, Validation Accuracy:  0.776, Loss:  0.234
Epoch   1 Batch  294/538 - Train Accuracy:  0.766, Validation Accuracy:  0.778, Loss:  0.262
Epoch   1 Batch  295/538 - Train Accuracy:  0.810, Validation Accuracy:  0.775, Loss:  0.234
Epoch   1 Batch  296/538 - Train Accuracy:  0.785, Validation Accuracy:  0.781, Loss:  0.252
Epoch   1 Batch  297/538 - Train Accuracy:  0.781, Validation Accuracy:  0.776, Loss:  0.260
Epoch   1 Batch  298/538 - Train Accuracy:  0.786, Validation Accuracy:  0.776, Loss:  0.240
Epoch   1 Batch  299/538 - Train Accuracy:  0.775, Validation Accuracy:  0.776, Loss:  0.248
Epoch   1 Batch  300/538 - Train Accuracy:  0.774, Validation Accuracy:  0.779, Loss:  0.243
Epoch   1 Batch  301/538 - Train Accuracy:  0.776, Validation Accuracy:  0.782, Loss:  0.248
Epoch   1 Batch  302/538 - Train Accuracy:  0.802, Validation Accuracy:  0.777, Loss:  0.228
Epoch   1 Batch  303/538 - Train Accuracy:  0.805, Validation Accuracy:  0.776, Loss:  0.238
Epoch   1 Batch  304/538 - Train Accuracy:  0.765, Validation Accuracy:  0.787, Loss:  0.241
Epoch   1 Batch  305/538 - Train Accuracy:  0.807, Validation Accuracy:  0.788, Loss:  0.240
Epoch   1 Batch  306/538 - Train Accuracy:  0.791, Validation Accuracy:  0.798, Loss:  0.246
Epoch   1 Batch  307/538 - Train Accuracy:  0.795, Validation Accuracy:  0.799, Loss:  0.240
Epoch   1 Batch  308/538 - Train Accuracy:  0.793, Validation Accuracy:  0.781, Loss:  0.242
Epoch   1 Batch  309/538 - Train Accuracy:  0.789, Validation Accuracy:  0.776, Loss:  0.234
Epoch   1 Batch  310/538 - Train Accuracy:  0.824, Validation Accuracy:  0.771, Loss:  0.239
Epoch   1 Batch  311/538 - Train Accuracy:  0.788, Validation Accuracy:  0.779, Loss:  0.241
Epoch   1 Batch  312/538 - Train Accuracy:  0.794, Validation Accuracy:  0.782, Loss:  0.217
Epoch   1 Batch  313/538 - Train Accuracy:  0.780, Validation Accuracy:  0.780, Loss:  0.247
Epoch   1 Batch  314/538 - Train Accuracy:  0.793, Validation Accuracy:  0.778, Loss:  0.236
Epoch   1 Batch  315/538 - Train Accuracy:  0.793, Validation Accuracy:  0.786, Loss:  0.232
Epoch   1 Batch  316/538 - Train Accuracy:  0.800, Validation Accuracy:  0.791, Loss:  0.225
Epoch   1 Batch  317/538 - Train Accuracy:  0.799, Validation Accuracy:  0.783, Loss:  0.238
Epoch   1 Batch  318/538 - Train Accuracy:  0.809, Validation Accuracy:  0.789, Loss:  0.227
Epoch   1 Batch  319/538 - Train Accuracy:  0.802, Validation Accuracy:  0.780, Loss:  0.223
Epoch   1 Batch  320/538 - Train Accuracy:  0.808, Validation Accuracy:  0.788, Loss:  0.227
Epoch   1 Batch  321/538 - Train Accuracy:  0.809, Validation Accuracy:  0.783, Loss:  0.218
Epoch   1 Batch  322/538 - Train Accuracy:  0.801, Validation Accuracy:  0.789, Loss:  0.228
Epoch   1 Batch  323/538 - Train Accuracy:  0.803, Validation Accuracy:  0.780, Loss:  0.215
Epoch   1 Batch  324/538 - Train Accuracy:  0.785, Validation Accuracy:  0.790, Loss:  0.242
Epoch   1 Batch  325/538 - Train Accuracy:  0.798, Validation Accuracy:  0.794, Loss:  0.227
Epoch   1 Batch  326/538 - Train Accuracy:  0.811, Validation Accuracy:  0.778, Loss:  0.229
Epoch   1 Batch  327/538 - Train Accuracy:  0.779, Validation Accuracy:  0.787, Loss:  0.244
Epoch   1 Batch  328/538 - Train Accuracy:  0.807, Validation Accuracy:  0.792, Loss:  0.225
Epoch   1 Batch  329/538 - Train Accuracy:  0.796, Validation Accuracy:  0.791, Loss:  0.228
Epoch   1 Batch  330/538 - Train Accuracy:  0.825, Validation Accuracy:  0.786, Loss:  0.215
Epoch   1 Batch  331/538 - Train Accuracy:  0.784, Validation Accuracy:  0.782, Loss:  0.215
Epoch   1 Batch  332/538 - Train Accuracy:  0.782, Validation Accuracy:  0.779, Loss:  0.225
Epoch   1 Batch  333/538 - Train Accuracy:  0.805, Validation Accuracy:  0.789, Loss:  0.227
Epoch   1 Batch  334/538 - Train Accuracy:  0.819, Validation Accuracy:  0.787, Loss:  0.207
Epoch   1 Batch  335/538 - Train Accuracy:  0.804, Validation Accuracy:  0.782, Loss:  0.223
Epoch   1 Batch  336/538 - Train Accuracy:  0.815, Validation Accuracy:  0.787, Loss:  0.212
Epoch   1 Batch  337/538 - Train Accuracy:  0.825, Validation Accuracy:  0.788, Loss:  0.223
Epoch   1 Batch  338/538 - Train Accuracy:  0.780, Validation Accuracy:  0.784, Loss:  0.222
Epoch   1 Batch  339/538 - Train Accuracy:  0.788, Validation Accuracy:  0.789, Loss:  0.213
Epoch   1 Batch  340/538 - Train Accuracy:  0.792, Validation Accuracy:  0.790, Loss:  0.235
Epoch   1 Batch  341/538 - Train Accuracy:  0.803, Validation Accuracy:  0.794, Loss:  0.212
Epoch   1 Batch  342/538 - Train Accuracy:  0.800, Validation Accuracy:  0.788, Loss:  0.213
Epoch   1 Batch  343/538 - Train Accuracy:  0.812, Validation Accuracy:  0.791, Loss:  0.221
Epoch   1 Batch  344/538 - Train Accuracy:  0.830, Validation Accuracy:  0.791, Loss:  0.210
Epoch   1 Batch  345/538 - Train Accuracy:  0.815, Validation Accuracy:  0.792, Loss:  0.213
Epoch   1 Batch  346/538 - Train Accuracy:  0.821, Validation Accuracy:  0.799, Loss:  0.226
Epoch   1 Batch  347/538 - Train Accuracy:  0.806, Validation Accuracy:  0.791, Loss:  0.215
Epoch   1 Batch  348/538 - Train Accuracy:  0.825, Validation Accuracy:  0.785, Loss:  0.206
Epoch   1 Batch  349/538 - Train Accuracy:  0.812, Validation Accuracy:  0.779, Loss:  0.203
Epoch   1 Batch  350/538 - Train Accuracy:  0.825, Validation Accuracy:  0.788, Loss:  0.218
Epoch   1 Batch  351/538 - Train Accuracy:  0.799, Validation Accuracy:  0.794, Loss:  0.228
Epoch   1 Batch  352/538 - Train Accuracy:  0.818, Validation Accuracy:  0.793, Loss:  0.225
Epoch   1 Batch  353/538 - Train Accuracy:  0.809, Validation Accuracy:  0.792, Loss:  0.219
Epoch   1 Batch  354/538 - Train Accuracy:  0.777, Validation Accuracy:  0.794, Loss:  0.223
Epoch   1 Batch  355/538 - Train Accuracy:  0.816, Validation Accuracy:  0.798, Loss:  0.223
Epoch   1 Batch  356/538 - Train Accuracy:  0.817, Validation Accuracy:  0.795, Loss:  0.192
Epoch   1 Batch  357/538 - Train Accuracy:  0.824, Validation Accuracy:  0.815, Loss:  0.199
Epoch   1 Batch  358/538 - Train Accuracy:  0.818, Validation Accuracy:  0.815, Loss:  0.214
Epoch   1 Batch  359/538 - Train Accuracy:  0.807, Validation Accuracy:  0.807, Loss:  0.215
Epoch   1 Batch  360/538 - Train Accuracy:  0.791, Validation Accuracy:  0.796, Loss:  0.221
Epoch   1 Batch  361/538 - Train Accuracy:  0.826, Validation Accuracy:  0.794, Loss:  0.211
Epoch   1 Batch  362/538 - Train Accuracy:  0.834, Validation Accuracy:  0.805, Loss:  0.193
Epoch   1 Batch  363/538 - Train Accuracy:  0.810, Validation Accuracy:  0.806, Loss:  0.195
Epoch   1 Batch  364/538 - Train Accuracy:  0.796, Validation Accuracy:  0.803, Loss:  0.234
Epoch   1 Batch  365/538 - Train Accuracy:  0.802, Validation Accuracy:  0.812, Loss:  0.217
Epoch   1 Batch  366/538 - Train Accuracy:  0.827, Validation Accuracy:  0.805, Loss:  0.210
Epoch   1 Batch  367/538 - Train Accuracy:  0.830, Validation Accuracy:  0.802, Loss:  0.195
Epoch   1 Batch  368/538 - Train Accuracy:  0.830, Validation Accuracy:  0.804, Loss:  0.189
Epoch   1 Batch  369/538 - Train Accuracy:  0.812, Validation Accuracy:  0.799, Loss:  0.198
Epoch   1 Batch  370/538 - Train Accuracy:  0.804, Validation Accuracy:  0.805, Loss:  0.227
Epoch   1 Batch  371/538 - Train Accuracy:  0.840, Validation Accuracy:  0.799, Loss:  0.198
Epoch   1 Batch  372/538 - Train Accuracy:  0.833, Validation Accuracy:  0.811, Loss:  0.204
Epoch   1 Batch  373/538 - Train Accuracy:  0.812, Validation Accuracy:  0.812, Loss:  0.194
Epoch   1 Batch  374/538 - Train Accuracy:  0.805, Validation Accuracy:  0.814, Loss:  0.213
Epoch   1 Batch  375/538 - Train Accuracy:  0.821, Validation Accuracy:  0.810, Loss:  0.191
Epoch   1 Batch  376/538 - Train Accuracy:  0.831, Validation Accuracy:  0.812, Loss:  0.211
Epoch   1 Batch  377/538 - Train Accuracy:  0.819, Validation Accuracy:  0.812, Loss:  0.208
Epoch   1 Batch  378/538 - Train Accuracy:  0.859, Validation Accuracy:  0.815, Loss:  0.194
Epoch   1 Batch  379/538 - Train Accuracy:  0.832, Validation Accuracy:  0.816, Loss:  0.194
Epoch   1 Batch  380/538 - Train Accuracy:  0.818, Validation Accuracy:  0.822, Loss:  0.192
Epoch   1 Batch  381/538 - Train Accuracy:  0.846, Validation Accuracy:  0.822, Loss:  0.182
Epoch   1 Batch  382/538 - Train Accuracy:  0.819, Validation Accuracy:  0.821, Loss:  0.203
Epoch   1 Batch  383/538 - Train Accuracy:  0.821, Validation Accuracy:  0.827, Loss:  0.204
Epoch   1 Batch  384/538 - Train Accuracy:  0.826, Validation Accuracy:  0.830, Loss:  0.200
Epoch   1 Batch  385/538 - Train Accuracy:  0.848, Validation Accuracy:  0.817, Loss:  0.189
Epoch   1 Batch  386/538 - Train Accuracy:  0.835, Validation Accuracy:  0.817, Loss:  0.206
Epoch   1 Batch  387/538 - Train Accuracy:  0.824, Validation Accuracy:  0.818, Loss:  0.199
Epoch   1 Batch  388/538 - Train Accuracy:  0.831, Validation Accuracy:  0.810, Loss:  0.199
Epoch   1 Batch  389/538 - Train Accuracy:  0.804, Validation Accuracy:  0.817, Loss:  0.211
Epoch   1 Batch  390/538 - Train Accuracy:  0.843, Validation Accuracy:  0.812, Loss:  0.192
Epoch   1 Batch  391/538 - Train Accuracy:  0.831, Validation Accuracy:  0.820, Loss:  0.188
Epoch   1 Batch  392/538 - Train Accuracy:  0.822, Validation Accuracy:  0.816, Loss:  0.194
Epoch   1 Batch  393/538 - Train Accuracy:  0.843, Validation Accuracy:  0.819, Loss:  0.187
Epoch   1 Batch  394/538 - Train Accuracy:  0.800, Validation Accuracy:  0.816, Loss:  0.208
Epoch   1 Batch  395/538 - Train Accuracy:  0.811, Validation Accuracy:  0.816, Loss:  0.207
Epoch   1 Batch  396/538 - Train Accuracy:  0.831, Validation Accuracy:  0.809, Loss:  0.195
Epoch   1 Batch  397/538 - Train Accuracy:  0.827, Validation Accuracy:  0.805, Loss:  0.215
Epoch   1 Batch  398/538 - Train Accuracy:  0.833, Validation Accuracy:  0.818, Loss:  0.201
Epoch   1 Batch  399/538 - Train Accuracy:  0.816, Validation Accuracy:  0.812, Loss:  0.203
Epoch   1 Batch  400/538 - Train Accuracy:  0.825, Validation Accuracy:  0.806, Loss:  0.196
Epoch   1 Batch  401/538 - Train Accuracy:  0.836, Validation Accuracy:  0.801, Loss:  0.199
Epoch   1 Batch  402/538 - Train Accuracy:  0.836, Validation Accuracy:  0.815, Loss:  0.191
Epoch   1 Batch  403/538 - Train Accuracy:  0.834, Validation Accuracy:  0.809, Loss:  0.195
Epoch   1 Batch  404/538 - Train Accuracy:  0.835, Validation Accuracy:  0.817, Loss:  0.187
Epoch   1 Batch  405/538 - Train Accuracy:  0.828, Validation Accuracy:  0.818, Loss:  0.186
Epoch   1 Batch  406/538 - Train Accuracy:  0.829, Validation Accuracy:  0.814, Loss:  0.182
Epoch   1 Batch  407/538 - Train Accuracy:  0.856, Validation Accuracy:  0.806, Loss:  0.197
Epoch   1 Batch  408/538 - Train Accuracy:  0.829, Validation Accuracy:  0.823, Loss:  0.208
Epoch   1 Batch  409/538 - Train Accuracy:  0.795, Validation Accuracy:  0.804, Loss:  0.199
Epoch   1 Batch  410/538 - Train Accuracy:  0.853, Validation Accuracy:  0.823, Loss:  0.198
Epoch   1 Batch  411/538 - Train Accuracy:  0.842, Validation Accuracy:  0.817, Loss:  0.184
Epoch   1 Batch  412/538 - Train Accuracy:  0.833, Validation Accuracy:  0.823, Loss:  0.185
Epoch   1 Batch  413/538 - Train Accuracy:  0.833, Validation Accuracy:  0.821, Loss:  0.188
Epoch   1 Batch  414/538 - Train Accuracy:  0.821, Validation Accuracy:  0.825, Loss:  0.200
Epoch   1 Batch  415/538 - Train Accuracy:  0.823, Validation Accuracy:  0.834, Loss:  0.201
Epoch   1 Batch  416/538 - Train Accuracy:  0.840, Validation Accuracy:  0.829, Loss:  0.184
Epoch   1 Batch  417/538 - Train Accuracy:  0.835, Validation Accuracy:  0.821, Loss:  0.179
Epoch   1 Batch  418/538 - Train Accuracy:  0.842, Validation Accuracy:  0.835, Loss:  0.201
Epoch   1 Batch  419/538 - Train Accuracy:  0.852, Validation Accuracy:  0.834, Loss:  0.170
Epoch   1 Batch  420/538 - Train Accuracy:  0.850, Validation Accuracy:  0.829, Loss:  0.186
Epoch   1 Batch  421/538 - Train Accuracy:  0.858, Validation Accuracy:  0.831, Loss:  0.174
Epoch   1 Batch  422/538 - Train Accuracy:  0.842, Validation Accuracy:  0.830, Loss:  0.184
Epoch   1 Batch  423/538 - Train Accuracy:  0.847, Validation Accuracy:  0.837, Loss:  0.188
Epoch   1 Batch  424/538 - Train Accuracy:  0.834, Validation Accuracy:  0.827, Loss:  0.187
Epoch   1 Batch  425/538 - Train Accuracy:  0.844, Validation Accuracy:  0.832, Loss:  0.195
Epoch   1 Batch  426/538 - Train Accuracy:  0.836, Validation Accuracy:  0.836, Loss:  0.189
Epoch   1 Batch  427/538 - Train Accuracy:  0.816, Validation Accuracy:  0.833, Loss:  0.190
Epoch   1 Batch  428/538 - Train Accuracy:  0.868, Validation Accuracy:  0.827, Loss:  0.175
Epoch   1 Batch  429/538 - Train Accuracy:  0.844, Validation Accuracy:  0.825, Loss:  0.186
Epoch   1 Batch  430/538 - Train Accuracy:  0.842, Validation Accuracy:  0.816, Loss:  0.180
Epoch   1 Batch  431/538 - Train Accuracy:  0.859, Validation Accuracy:  0.828, Loss:  0.182
Epoch   1 Batch  432/538 - Train Accuracy:  0.850, Validation Accuracy:  0.823, Loss:  0.172
Epoch   1 Batch  433/538 - Train Accuracy:  0.827, Validation Accuracy:  0.830, Loss:  0.211
Epoch   1 Batch  434/538 - Train Accuracy:  0.804, Validation Accuracy:  0.835, Loss:  0.198
Epoch   1 Batch  435/538 - Train Accuracy:  0.840, Validation Accuracy:  0.827, Loss:  0.176
Epoch   1 Batch  436/538 - Train Accuracy:  0.825, Validation Accuracy:  0.849, Loss:  0.197
Epoch   1 Batch  437/538 - Train Accuracy:  0.846, Validation Accuracy:  0.843, Loss:  0.178
Epoch   1 Batch  438/538 - Train Accuracy:  0.860, Validation Accuracy:  0.848, Loss:  0.177
Epoch   1 Batch  439/538 - Train Accuracy:  0.862, Validation Accuracy:  0.843, Loss:  0.178
Epoch   1 Batch  440/538 - Train Accuracy:  0.842, Validation Accuracy:  0.845, Loss:  0.192
Epoch   1 Batch  441/538 - Train Accuracy:  0.842, Validation Accuracy:  0.844, Loss:  0.190
Epoch   1 Batch  442/538 - Train Accuracy:  0.850, Validation Accuracy:  0.836, Loss:  0.158
Epoch   1 Batch  443/538 - Train Accuracy:  0.850, Validation Accuracy:  0.836, Loss:  0.178
Epoch   1 Batch  444/538 - Train Accuracy:  0.870, Validation Accuracy:  0.843, Loss:  0.175
Epoch   1 Batch  445/538 - Train Accuracy:  0.863, Validation Accuracy:  0.830, Loss:  0.160
Epoch   1 Batch  446/538 - Train Accuracy:  0.869, Validation Accuracy:  0.833, Loss:  0.165
Epoch   1 Batch  447/538 - Train Accuracy:  0.843, Validation Accuracy:  0.840, Loss:  0.179
Epoch   1 Batch  448/538 - Train Accuracy:  0.849, Validation Accuracy:  0.841, Loss:  0.159
Epoch   1 Batch  449/538 - Train Accuracy:  0.863, Validation Accuracy:  0.835, Loss:  0.184
Epoch   1 Batch  450/538 - Train Accuracy:  0.844, Validation Accuracy:  0.833, Loss:  0.188
Epoch   1 Batch  451/538 - Train Accuracy:  0.841, Validation Accuracy:  0.835, Loss:  0.175
Epoch   1 Batch  452/538 - Train Accuracy:  0.851, Validation Accuracy:  0.841, Loss:  0.159
Epoch   1 Batch  453/538 - Train Accuracy:  0.852, Validation Accuracy:  0.832, Loss:  0.181
Epoch   1 Batch  454/538 - Train Accuracy:  0.853, Validation Accuracy:  0.837, Loss:  0.175
Epoch   1 Batch  455/538 - Train Accuracy:  0.858, Validation Accuracy:  0.842, Loss:  0.159
Epoch   1 Batch  456/538 - Train Accuracy:  0.886, Validation Accuracy:  0.852, Loss:  0.166
Epoch   1 Batch  457/538 - Train Accuracy:  0.857, Validation Accuracy:  0.859, Loss:  0.178
Epoch   1 Batch  458/538 - Train Accuracy:  0.852, Validation Accuracy:  0.855, Loss:  0.162
Epoch   1 Batch  459/538 - Train Accuracy:  0.860, Validation Accuracy:  0.855, Loss:  0.164
Epoch   1 Batch  460/538 - Train Accuracy:  0.838, Validation Accuracy:  0.847, Loss:  0.168
Epoch   1 Batch  461/538 - Train Accuracy:  0.870, Validation Accuracy:  0.859, Loss:  0.178
Epoch   1 Batch  462/538 - Train Accuracy:  0.868, Validation Accuracy:  0.861, Loss:  0.164
Epoch   1 Batch  463/538 - Train Accuracy:  0.838, Validation Accuracy:  0.858, Loss:  0.179
Epoch   1 Batch  464/538 - Train Accuracy:  0.863, Validation Accuracy:  0.859, Loss:  0.165
Epoch   1 Batch  465/538 - Train Accuracy:  0.821, Validation Accuracy:  0.835, Loss:  0.169
Epoch   1 Batch  466/538 - Train Accuracy:  0.861, Validation Accuracy:  0.853, Loss:  0.167
Epoch   1 Batch  467/538 - Train Accuracy:  0.869, Validation Accuracy:  0.843, Loss:  0.168
Epoch   1 Batch  468/538 - Train Accuracy:  0.874, Validation Accuracy:  0.844, Loss:  0.178
Epoch   1 Batch  469/538 - Train Accuracy:  0.836, Validation Accuracy:  0.835, Loss:  0.166
Epoch   1 Batch  470/538 - Train Accuracy:  0.849, Validation Accuracy:  0.833, Loss:  0.162
Epoch   1 Batch  471/538 - Train Accuracy:  0.852, Validation Accuracy:  0.841, Loss:  0.158
Epoch   1 Batch  472/538 - Train Accuracy:  0.883, Validation Accuracy:  0.846, Loss:  0.155
Epoch   1 Batch  473/538 - Train Accuracy:  0.828, Validation Accuracy:  0.832, Loss:  0.175
Epoch   1 Batch  474/538 - Train Accuracy:  0.881, Validation Accuracy:  0.835, Loss:  0.150
Epoch   1 Batch  475/538 - Train Accuracy:  0.854, Validation Accuracy:  0.837, Loss:  0.163
Epoch   1 Batch  476/538 - Train Accuracy:  0.844, Validation Accuracy:  0.827, Loss:  0.169
Epoch   1 Batch  477/538 - Train Accuracy:  0.861, Validation Accuracy:  0.846, Loss:  0.169
Epoch   1 Batch  478/538 - Train Accuracy:  0.846, Validation Accuracy:  0.846, Loss:  0.158
Epoch   1 Batch  479/538 - Train Accuracy:  0.866, Validation Accuracy:  0.846, Loss:  0.160
Epoch   1 Batch  480/538 - Train Accuracy:  0.873, Validation Accuracy:  0.846, Loss:  0.159
Epoch   1 Batch  481/538 - Train Accuracy:  0.896, Validation Accuracy:  0.870, Loss:  0.157
Epoch   1 Batch  482/538 - Train Accuracy:  0.868, Validation Accuracy:  0.861, Loss:  0.137
Epoch   1 Batch  483/538 - Train Accuracy:  0.850, Validation Accuracy:  0.861, Loss:  0.173
Epoch   1 Batch  484/538 - Train Accuracy:  0.872, Validation Accuracy:  0.839, Loss:  0.165
Epoch   1 Batch  485/538 - Train Accuracy:  0.867, Validation Accuracy:  0.850, Loss:  0.165
Epoch   1 Batch  486/538 - Train Accuracy:  0.884, Validation Accuracy:  0.863, Loss:  0.150
Epoch   1 Batch  487/538 - Train Accuracy:  0.877, Validation Accuracy:  0.866, Loss:  0.147
Epoch   1 Batch  488/538 - Train Accuracy:  0.879, Validation Accuracy:  0.861, Loss:  0.153
Epoch   1 Batch  489/538 - Train Accuracy:  0.852, Validation Accuracy:  0.872, Loss:  0.168
Epoch   1 Batch  490/538 - Train Accuracy:  0.877, Validation Accuracy:  0.871, Loss:  0.155
Epoch   1 Batch  491/538 - Train Accuracy:  0.845, Validation Accuracy:  0.875, Loss:  0.175
Epoch   1 Batch  492/538 - Train Accuracy:  0.860, Validation Accuracy:  0.862, Loss:  0.157
Epoch   1 Batch  493/538 - Train Accuracy:  0.861, Validation Accuracy:  0.863, Loss:  0.151
Epoch   1 Batch  494/538 - Train Accuracy:  0.863, Validation Accuracy:  0.864, Loss:  0.163
Epoch   1 Batch  495/538 - Train Accuracy:  0.882, Validation Accuracy:  0.864, Loss:  0.156
Epoch   1 Batch  496/538 - Train Accuracy:  0.874, Validation Accuracy:  0.867, Loss:  0.148
Epoch   1 Batch  497/538 - Train Accuracy:  0.876, Validation Accuracy:  0.855, Loss:  0.144
Epoch   1 Batch  498/538 - Train Accuracy:  0.866, Validation Accuracy:  0.860, Loss:  0.153
Epoch   1 Batch  499/538 - Train Accuracy:  0.872, Validation Accuracy:  0.863, Loss:  0.145
Epoch   1 Batch  500/538 - Train Accuracy:  0.887, Validation Accuracy:  0.857, Loss:  0.132
Epoch   1 Batch  501/538 - Train Accuracy:  0.890, Validation Accuracy:  0.861, Loss:  0.147
Epoch   1 Batch  502/538 - Train Accuracy:  0.872, Validation Accuracy:  0.866, Loss:  0.143
Epoch   1 Batch  503/538 - Train Accuracy:  0.896, Validation Accuracy:  0.874, Loss:  0.145
Epoch   1 Batch  504/538 - Train Accuracy:  0.899, Validation Accuracy:  0.877, Loss:  0.143
Epoch   1 Batch  505/538 - Train Accuracy:  0.871, Validation Accuracy:  0.876, Loss:  0.142
Epoch   1 Batch  506/538 - Train Accuracy:  0.877, Validation Accuracy:  0.884, Loss:  0.142
Epoch   1 Batch  507/538 - Train Accuracy:  0.839, Validation Accuracy:  0.884, Loss:  0.162
Epoch   1 Batch  508/538 - Train Accuracy:  0.879, Validation Accuracy:  0.877, Loss:  0.142
Epoch   1 Batch  509/538 - Train Accuracy:  0.877, Validation Accuracy:  0.862, Loss:  0.150
Epoch   1 Batch  510/538 - Train Accuracy:  0.881, Validation Accuracy:  0.873, Loss:  0.143
Epoch   1 Batch  511/538 - Train Accuracy:  0.867, Validation Accuracy:  0.876, Loss:  0.137
Epoch   1 Batch  512/538 - Train Accuracy:  0.891, Validation Accuracy:  0.870, Loss:  0.148
Epoch   1 Batch  513/538 - Train Accuracy:  0.849, Validation Accuracy:  0.870, Loss:  0.148
Epoch   1 Batch  514/538 - Train Accuracy:  0.881, Validation Accuracy:  0.874, Loss:  0.144
Epoch   1 Batch  515/538 - Train Accuracy:  0.884, Validation Accuracy:  0.880, Loss:  0.148
Epoch   1 Batch  516/538 - Train Accuracy:  0.836, Validation Accuracy:  0.870, Loss:  0.155
Epoch   1 Batch  517/538 - Train Accuracy:  0.883, Validation Accuracy:  0.850, Loss:  0.135
Epoch   1 Batch  518/538 - Train Accuracy:  0.876, Validation Accuracy:  0.859, Loss:  0.151
Epoch   1 Batch  519/538 - Train Accuracy:  0.877, Validation Accuracy:  0.864, Loss:  0.144
Epoch   1 Batch  520/538 - Train Accuracy:  0.874, Validation Accuracy:  0.874, Loss:  0.151
Epoch   1 Batch  521/538 - Train Accuracy:  0.844, Validation Accuracy:  0.879, Loss:  0.158
Epoch   1 Batch  522/538 - Train Accuracy:  0.865, Validation Accuracy:  0.868, Loss:  0.139
Epoch   1 Batch  523/538 - Train Accuracy:  0.866, Validation Accuracy:  0.870, Loss:  0.140
Epoch   1 Batch  524/538 - Train Accuracy:  0.865, Validation Accuracy:  0.871, Loss:  0.149
Epoch   1 Batch  525/538 - Train Accuracy:  0.885, Validation Accuracy:  0.864, Loss:  0.138
Epoch   1 Batch  526/538 - Train Accuracy:  0.891, Validation Accuracy:  0.866, Loss:  0.139
Epoch   1 Batch  527/538 - Train Accuracy:  0.894, Validation Accuracy:  0.878, Loss:  0.150
Epoch   1 Batch  528/538 - Train Accuracy:  0.871, Validation Accuracy:  0.883, Loss:  0.156
Epoch   1 Batch  529/538 - Train Accuracy:  0.862, Validation Accuracy:  0.874, Loss:  0.135
Epoch   1 Batch  530/538 - Train Accuracy:  0.869, Validation Accuracy:  0.882, Loss:  0.153
Epoch   1 Batch  531/538 - Train Accuracy:  0.900, Validation Accuracy:  0.882, Loss:  0.142
Epoch   1 Batch  532/538 - Train Accuracy:  0.877, Validation Accuracy:  0.884, Loss:  0.134
Epoch   1 Batch  533/538 - Train Accuracy:  0.908, Validation Accuracy:  0.883, Loss:  0.136
Epoch   1 Batch  534/538 - Train Accuracy:  0.884, Validation Accuracy:  0.882, Loss:  0.130
Epoch   1 Batch  535/538 - Train Accuracy:  0.886, Validation Accuracy:  0.871, Loss:  0.140
Epoch   1 Batch  536/538 - Train Accuracy:  0.887, Validation Accuracy:  0.871, Loss:  0.147
Epoch   2 Batch    0/538 - Train Accuracy:  0.891, Validation Accuracy:  0.872, Loss:  0.133
Epoch   2 Batch    1/538 - Train Accuracy:  0.897, Validation Accuracy:  0.878, Loss:  0.140
Epoch   2 Batch    2/538 - Train Accuracy:  0.864, Validation Accuracy:  0.879, Loss:  0.151
Epoch   2 Batch    3/538 - Train Accuracy:  0.887, Validation Accuracy:  0.875, Loss:  0.128
Epoch   2 Batch    4/538 - Train Accuracy:  0.882, Validation Accuracy:  0.860, Loss:  0.132
Epoch   2 Batch    5/538 - Train Accuracy:  0.887, Validation Accuracy:  0.870, Loss:  0.142
Epoch   2 Batch    6/538 - Train Accuracy:  0.887, Validation Accuracy:  0.878, Loss:  0.124
Epoch   2 Batch    7/538 - Train Accuracy:  0.893, Validation Accuracy:  0.872, Loss:  0.133
Epoch   2 Batch    8/538 - Train Accuracy:  0.881, Validation Accuracy:  0.865, Loss:  0.133
Epoch   2 Batch    9/538 - Train Accuracy:  0.877, Validation Accuracy:  0.861, Loss:  0.127
Epoch   2 Batch   10/538 - Train Accuracy:  0.887, Validation Accuracy:  0.865, Loss:  0.141
Epoch   2 Batch   11/538 - Train Accuracy:  0.884, Validation Accuracy:  0.864, Loss:  0.137
Epoch   2 Batch   12/538 - Train Accuracy:  0.866, Validation Accuracy:  0.872, Loss:  0.138
Epoch   2 Batch   13/538 - Train Accuracy:  0.897, Validation Accuracy:  0.870, Loss:  0.126
Epoch   2 Batch   14/538 - Train Accuracy:  0.891, Validation Accuracy:  0.876, Loss:  0.136
Epoch   2 Batch   15/538 - Train Accuracy:  0.895, Validation Accuracy:  0.868, Loss:  0.120
Epoch   2 Batch   16/538 - Train Accuracy:  0.865, Validation Accuracy:  0.868, Loss:  0.128
Epoch   2 Batch   17/538 - Train Accuracy:  0.874, Validation Accuracy:  0.882, Loss:  0.131
Epoch   2 Batch   18/538 - Train Accuracy:  0.906, Validation Accuracy:  0.881, Loss:  0.136
Epoch   2 Batch   19/538 - Train Accuracy:  0.880, Validation Accuracy:  0.880, Loss:  0.140
Epoch   2 Batch   20/538 - Train Accuracy:  0.876, Validation Accuracy:  0.896, Loss:  0.141
Epoch   2 Batch   21/538 - Train Accuracy:  0.919, Validation Accuracy:  0.893, Loss:  0.119
Epoch   2 Batch   22/538 - Train Accuracy:  0.884, Validation Accuracy:  0.887, Loss:  0.135
Epoch   2 Batch   23/538 - Train Accuracy:  0.893, Validation Accuracy:  0.883, Loss:  0.142
Epoch   2 Batch   24/538 - Train Accuracy:  0.887, Validation Accuracy:  0.885, Loss:  0.133
Epoch   2 Batch   25/538 - Train Accuracy:  0.892, Validation Accuracy:  0.881, Loss:  0.132
Epoch   2 Batch   26/538 - Train Accuracy:  0.865, Validation Accuracy:  0.884, Loss:  0.143
Epoch   2 Batch   27/538 - Train Accuracy:  0.883, Validation Accuracy:  0.872, Loss:  0.121
Epoch   2 Batch   28/538 - Train Accuracy:  0.875, Validation Accuracy:  0.873, Loss:  0.119
Epoch   2 Batch   29/538 - Train Accuracy:  0.897, Validation Accuracy:  0.876, Loss:  0.119
Epoch   2 Batch   30/538 - Train Accuracy:  0.872, Validation Accuracy:  0.876, Loss:  0.143
Epoch   2 Batch   31/538 - Train Accuracy:  0.901, Validation Accuracy:  0.889, Loss:  0.114
Epoch   2 Batch   32/538 - Train Accuracy:  0.890, Validation Accuracy:  0.886, Loss:  0.106
Epoch   2 Batch   33/538 - Train Accuracy:  0.894, Validation Accuracy:  0.884, Loss:  0.129
Epoch   2 Batch   34/538 - Train Accuracy:  0.870, Validation Accuracy:  0.878, Loss:  0.136
Epoch   2 Batch   35/538 - Train Accuracy:  0.895, Validation Accuracy:  0.883, Loss:  0.116
Epoch   2 Batch   36/538 - Train Accuracy:  0.899, Validation Accuracy:  0.879, Loss:  0.117
Epoch   2 Batch   37/538 - Train Accuracy:  0.895, Validation Accuracy:  0.894, Loss:  0.134
Epoch   2 Batch   38/538 - Train Accuracy:  0.887, Validation Accuracy:  0.891, Loss:  0.122
Epoch   2 Batch   39/538 - Train Accuracy:  0.904, Validation Accuracy:  0.897, Loss:  0.134
Epoch   2 Batch   40/538 - Train Accuracy:  0.894, Validation Accuracy:  0.883, Loss:  0.107
Epoch   2 Batch   41/538 - Train Accuracy:  0.887, Validation Accuracy:  0.873, Loss:  0.128
Epoch   2 Batch   42/538 - Train Accuracy:  0.871, Validation Accuracy:  0.900, Loss:  0.126
Epoch   2 Batch   43/538 - Train Accuracy:  0.872, Validation Accuracy:  0.891, Loss:  0.141
Epoch   2 Batch   44/538 - Train Accuracy:  0.865, Validation Accuracy:  0.888, Loss:  0.136
Epoch   2 Batch   45/538 - Train Accuracy:  0.900, Validation Accuracy:  0.894, Loss:  0.124
Epoch   2 Batch   46/538 - Train Accuracy:  0.913, Validation Accuracy:  0.881, Loss:  0.116
Epoch   2 Batch   47/538 - Train Accuracy:  0.892, Validation Accuracy:  0.878, Loss:  0.126
Epoch   2 Batch   48/538 - Train Accuracy:  0.888, Validation Accuracy:  0.879, Loss:  0.119
Epoch   2 Batch   49/538 - Train Accuracy:  0.893, Validation Accuracy:  0.879, Loss:  0.122
Epoch   2 Batch   50/538 - Train Accuracy:  0.884, Validation Accuracy:  0.876, Loss:  0.121
Epoch   2 Batch   51/538 - Train Accuracy:  0.882, Validation Accuracy:  0.863, Loss:  0.134
Epoch   2 Batch   52/538 - Train Accuracy:  0.878, Validation Accuracy:  0.874, Loss:  0.133
Epoch   2 Batch   53/538 - Train Accuracy:  0.890, Validation Accuracy:  0.879, Loss:  0.118
Epoch   2 Batch   54/538 - Train Accuracy:  0.891, Validation Accuracy:  0.878, Loss:  0.117
Epoch   2 Batch   55/538 - Train Accuracy:  0.885, Validation Accuracy:  0.886, Loss:  0.120
Epoch   2 Batch   56/538 - Train Accuracy:  0.893, Validation Accuracy:  0.881, Loss:  0.112
Epoch   2 Batch   57/538 - Train Accuracy:  0.868, Validation Accuracy:  0.888, Loss:  0.140
Epoch   2 Batch   58/538 - Train Accuracy:  0.871, Validation Accuracy:  0.891, Loss:  0.125
Epoch   2 Batch   59/538 - Train Accuracy:  0.894, Validation Accuracy:  0.882, Loss:  0.120
Epoch   2 Batch   60/538 - Train Accuracy:  0.903, Validation Accuracy:  0.879, Loss:  0.116
Epoch   2 Batch   61/538 - Train Accuracy:  0.907, Validation Accuracy:  0.891, Loss:  0.114
Epoch   2 Batch   62/538 - Train Accuracy:  0.894, Validation Accuracy:  0.894, Loss:  0.111
Epoch   2 Batch   63/538 - Train Accuracy:  0.902, Validation Accuracy:  0.896, Loss:  0.104
Epoch   2 Batch   64/538 - Train Accuracy:  0.892, Validation Accuracy:  0.883, Loss:  0.113
Epoch   2 Batch   65/538 - Train Accuracy:  0.861, Validation Accuracy:  0.872, Loss:  0.113
Epoch   2 Batch   66/538 - Train Accuracy:  0.890, Validation Accuracy:  0.869, Loss:  0.101
Epoch   2 Batch   67/538 - Train Accuracy:  0.918, Validation Accuracy:  0.872, Loss:  0.107
Epoch   2 Batch   68/538 - Train Accuracy:  0.885, Validation Accuracy:  0.878, Loss:  0.105
Epoch   2 Batch   69/538 - Train Accuracy:  0.899, Validation Accuracy:  0.881, Loss:  0.112
Epoch   2 Batch   70/538 - Train Accuracy:  0.885, Validation Accuracy:  0.886, Loss:  0.111
Epoch   2 Batch   71/538 - Train Accuracy:  0.877, Validation Accuracy:  0.893, Loss:  0.125
Epoch   2 Batch   72/538 - Train Accuracy:  0.910, Validation Accuracy:  0.893, Loss:  0.118
Epoch   2 Batch   73/538 - Train Accuracy:  0.867, Validation Accuracy:  0.889, Loss:  0.115
Epoch   2 Batch   74/538 - Train Accuracy:  0.898, Validation Accuracy:  0.886, Loss:  0.111
Epoch   2 Batch   75/538 - Train Accuracy:  0.891, Validation Accuracy:  0.891, Loss:  0.108
Epoch   2 Batch   76/538 - Train Accuracy:  0.895, Validation Accuracy:  0.897, Loss:  0.112
Epoch   2 Batch   77/538 - Train Accuracy:  0.881, Validation Accuracy:  0.902, Loss:  0.103
Epoch   2 Batch   78/538 - Train Accuracy:  0.889, Validation Accuracy:  0.894, Loss:  0.112
Epoch   2 Batch   79/538 - Train Accuracy:  0.916, Validation Accuracy:  0.888, Loss:  0.102
Epoch   2 Batch   80/538 - Train Accuracy:  0.881, Validation Accuracy:  0.890, Loss:  0.111
Epoch   2 Batch   81/538 - Train Accuracy:  0.878, Validation Accuracy:  0.895, Loss:  0.115
Epoch   2 Batch   82/538 - Train Accuracy:  0.875, Validation Accuracy:  0.895, Loss:  0.112
Epoch   2 Batch   83/538 - Train Accuracy:  0.902, Validation Accuracy:  0.890, Loss:  0.116
Epoch   2 Batch   84/538 - Train Accuracy:  0.891, Validation Accuracy:  0.891, Loss:  0.110
Epoch   2 Batch   85/538 - Train Accuracy:  0.916, Validation Accuracy:  0.894, Loss:  0.093
Epoch   2 Batch   86/538 - Train Accuracy:  0.892, Validation Accuracy:  0.900, Loss:  0.110
Epoch   2 Batch   87/538 - Train Accuracy:  0.891, Validation Accuracy:  0.889, Loss:  0.106
Epoch   2 Batch   88/538 - Train Accuracy:  0.903, Validation Accuracy:  0.900, Loss:  0.110
Epoch   2 Batch   89/538 - Train Accuracy:  0.905, Validation Accuracy:  0.900, Loss:  0.102
Epoch   2 Batch   90/538 - Train Accuracy:  0.891, Validation Accuracy:  0.895, Loss:  0.114
Epoch   2 Batch   91/538 - Train Accuracy:  0.902, Validation Accuracy:  0.896, Loss:  0.103
Epoch   2 Batch   92/538 - Train Accuracy:  0.893, Validation Accuracy:  0.895, Loss:  0.114
Epoch   2 Batch   93/538 - Train Accuracy:  0.903, Validation Accuracy:  0.906, Loss:  0.099
Epoch   2 Batch   94/538 - Train Accuracy:  0.914, Validation Accuracy:  0.899, Loss:  0.103
Epoch   2 Batch   95/538 - Train Accuracy:  0.888, Validation Accuracy:  0.894, Loss:  0.101
Epoch   2 Batch   96/538 - Train Accuracy:  0.910, Validation Accuracy:  0.895, Loss:  0.092
Epoch   2 Batch   97/538 - Train Accuracy:  0.904, Validation Accuracy:  0.893, Loss:  0.097
Epoch   2 Batch   98/538 - Train Accuracy:  0.906, Validation Accuracy:  0.889, Loss:  0.103
Epoch   2 Batch   99/538 - Train Accuracy:  0.897, Validation Accuracy:  0.896, Loss:  0.104
Epoch   2 Batch  100/538 - Train Accuracy:  0.912, Validation Accuracy:  0.895, Loss:  0.094
Epoch   2 Batch  101/538 - Train Accuracy:  0.867, Validation Accuracy:  0.898, Loss:  0.117
Epoch   2 Batch  102/538 - Train Accuracy:  0.897, Validation Accuracy:  0.890, Loss:  0.108
Epoch   2 Batch  103/538 - Train Accuracy:  0.910, Validation Accuracy:  0.891, Loss:  0.099
Epoch   2 Batch  104/538 - Train Accuracy:  0.896, Validation Accuracy:  0.890, Loss:  0.099
Epoch   2 Batch  105/538 - Train Accuracy:  0.906, Validation Accuracy:  0.898, Loss:  0.094
Epoch   2 Batch  106/538 - Train Accuracy:  0.886, Validation Accuracy:  0.893, Loss:  0.093
Epoch   2 Batch  107/538 - Train Accuracy:  0.866, Validation Accuracy:  0.893, Loss:  0.112
Epoch   2 Batch  108/538 - Train Accuracy:  0.896, Validation Accuracy:  0.891, Loss:  0.105
Epoch   2 Batch  109/538 - Train Accuracy:  0.921, Validation Accuracy:  0.894, Loss:  0.092
Epoch   2 Batch  110/538 - Train Accuracy:  0.902, Validation Accuracy:  0.905, Loss:  0.098
Epoch   2 Batch  111/538 - Train Accuracy:  0.897, Validation Accuracy:  0.894, Loss:  0.093
Epoch   2 Batch  112/538 - Train Accuracy:  0.900, Validation Accuracy:  0.901, Loss:  0.101
Epoch   2 Batch  113/538 - Train Accuracy:  0.886, Validation Accuracy:  0.900, Loss:  0.104
Epoch   2 Batch  114/538 - Train Accuracy:  0.897, Validation Accuracy:  0.898, Loss:  0.096
Epoch   2 Batch  115/538 - Train Accuracy:  0.912, Validation Accuracy:  0.907, Loss:  0.096
Epoch   2 Batch  116/538 - Train Accuracy:  0.895, Validation Accuracy:  0.902, Loss:  0.112
Epoch   2 Batch  117/538 - Train Accuracy:  0.890, Validation Accuracy:  0.894, Loss:  0.105
Epoch   2 Batch  118/538 - Train Accuracy:  0.913, Validation Accuracy:  0.900, Loss:  0.086
Epoch   2 Batch  119/538 - Train Accuracy:  0.923, Validation Accuracy:  0.902, Loss:  0.083
Epoch   2 Batch  120/538 - Train Accuracy:  0.911, Validation Accuracy:  0.896, Loss:  0.085
Epoch   2 Batch  121/538 - Train Accuracy:  0.900, Validation Accuracy:  0.904, Loss:  0.092
Epoch   2 Batch  122/538 - Train Accuracy:  0.892, Validation Accuracy:  0.903, Loss:  0.088
Epoch   2 Batch  123/538 - Train Accuracy:  0.899, Validation Accuracy:  0.900, Loss:  0.085
Epoch   2 Batch  124/538 - Train Accuracy:  0.910, Validation Accuracy:  0.898, Loss:  0.086
Epoch   2 Batch  125/538 - Train Accuracy:  0.903, Validation Accuracy:  0.906, Loss:  0.099
Epoch   2 Batch  126/538 - Train Accuracy:  0.896, Validation Accuracy:  0.899, Loss:  0.095
Epoch   2 Batch  127/538 - Train Accuracy:  0.886, Validation Accuracy:  0.895, Loss:  0.111
Epoch   2 Batch  128/538 - Train Accuracy:  0.902, Validation Accuracy:  0.908, Loss:  0.095
Epoch   2 Batch  129/538 - Train Accuracy:  0.903, Validation Accuracy:  0.908, Loss:  0.084
Epoch   2 Batch  130/538 - Train Accuracy:  0.910, Validation Accuracy:  0.898, Loss:  0.086
Epoch   2 Batch  131/538 - Train Accuracy:  0.928, Validation Accuracy:  0.900, Loss:  0.085
Epoch   2 Batch  132/538 - Train Accuracy:  0.871, Validation Accuracy:  0.905, Loss:  0.095
Epoch   2 Batch  133/538 - Train Accuracy:  0.896, Validation Accuracy:  0.906, Loss:  0.089
Epoch   2 Batch  134/538 - Train Accuracy:  0.882, Validation Accuracy:  0.903, Loss:  0.105
Epoch   2 Batch  135/538 - Train Accuracy:  0.906, Validation Accuracy:  0.904, Loss:  0.101
Epoch   2 Batch  136/538 - Train Accuracy:  0.906, Validation Accuracy:  0.904, Loss:  0.087
Epoch   2 Batch  137/538 - Train Accuracy:  0.882, Validation Accuracy:  0.907, Loss:  0.097
Epoch   2 Batch  138/538 - Train Accuracy:  0.895, Validation Accuracy:  0.911, Loss:  0.097
Epoch   2 Batch  139/538 - Train Accuracy:  0.884, Validation Accuracy:  0.911, Loss:  0.104
Epoch   2 Batch  140/538 - Train Accuracy:  0.883, Validation Accuracy:  0.901, Loss:  0.109
Epoch   2 Batch  141/538 - Train Accuracy:  0.899, Validation Accuracy:  0.903, Loss:  0.097
Epoch   2 Batch  142/538 - Train Accuracy:  0.905, Validation Accuracy:  0.900, Loss:  0.093
Epoch   2 Batch  143/538 - Train Accuracy:  0.900, Validation Accuracy:  0.905, Loss:  0.096
Epoch   2 Batch  144/538 - Train Accuracy:  0.912, Validation Accuracy:  0.909, Loss:  0.100
Epoch   2 Batch  145/538 - Train Accuracy:  0.887, Validation Accuracy:  0.895, Loss:  0.104
Epoch   2 Batch  146/538 - Train Accuracy:  0.910, Validation Accuracy:  0.899, Loss:  0.098
Epoch   2 Batch  147/538 - Train Accuracy:  0.915, Validation Accuracy:  0.914, Loss:  0.097
Epoch   2 Batch  148/538 - Train Accuracy:  0.875, Validation Accuracy:  0.915, Loss:  0.099
Epoch   2 Batch  149/538 - Train Accuracy:  0.914, Validation Accuracy:  0.912, Loss:  0.086
Epoch   2 Batch  150/538 - Train Accuracy:  0.915, Validation Accuracy:  0.913, Loss:  0.090
Epoch   2 Batch  151/538 - Train Accuracy:  0.914, Validation Accuracy:  0.917, Loss:  0.091
Epoch   2 Batch  152/538 - Train Accuracy:  0.908, Validation Accuracy:  0.912, Loss:  0.090
Epoch   2 Batch  153/538 - Train Accuracy:  0.873, Validation Accuracy:  0.916, Loss:  0.093
Epoch   2 Batch  154/538 - Train Accuracy:  0.900, Validation Accuracy:  0.911, Loss:  0.084
Epoch   2 Batch  155/538 - Train Accuracy:  0.899, Validation Accuracy:  0.901, Loss:  0.094
Epoch   2 Batch  156/538 - Train Accuracy:  0.921, Validation Accuracy:  0.902, Loss:  0.077
Epoch   2 Batch  157/538 - Train Accuracy:  0.924, Validation Accuracy:  0.905, Loss:  0.084
Epoch   2 Batch  158/538 - Train Accuracy:  0.904, Validation Accuracy:  0.902, Loss:  0.101
Epoch   2 Batch  159/538 - Train Accuracy:  0.913, Validation Accuracy:  0.905, Loss:  0.095
Epoch   2 Batch  160/538 - Train Accuracy:  0.894, Validation Accuracy:  0.893, Loss:  0.080
Epoch   2 Batch  161/538 - Train Accuracy:  0.902, Validation Accuracy:  0.894, Loss:  0.087
Epoch   2 Batch  162/538 - Train Accuracy:  0.903, Validation Accuracy:  0.898, Loss:  0.089
Epoch   2 Batch  163/538 - Train Accuracy:  0.885, Validation Accuracy:  0.902, Loss:  0.098
Epoch   2 Batch  164/538 - Train Accuracy:  0.892, Validation Accuracy:  0.905, Loss:  0.095
Epoch   2 Batch  165/538 - Train Accuracy:  0.895, Validation Accuracy:  0.906, Loss:  0.079
Epoch   2 Batch  166/538 - Train Accuracy:  0.929, Validation Accuracy:  0.908, Loss:  0.081
Epoch   2 Batch  167/538 - Train Accuracy:  0.900, Validation Accuracy:  0.902, Loss:  0.092
Epoch   2 Batch  168/538 - Train Accuracy:  0.874, Validation Accuracy:  0.899, Loss:  0.101
Epoch   2 Batch  169/538 - Train Accuracy:  0.913, Validation Accuracy:  0.903, Loss:  0.085
Epoch   2 Batch  170/538 - Train Accuracy:  0.911, Validation Accuracy:  0.914, Loss:  0.086
Epoch   2 Batch  171/538 - Train Accuracy:  0.916, Validation Accuracy:  0.915, Loss:  0.090
Epoch   2 Batch  172/538 - Train Accuracy:  0.910, Validation Accuracy:  0.909, Loss:  0.081
Epoch   2 Batch  173/538 - Train Accuracy:  0.907, Validation Accuracy:  0.903, Loss:  0.075
Epoch   2 Batch  174/538 - Train Accuracy:  0.909, Validation Accuracy:  0.905, Loss:  0.089
Epoch   2 Batch  175/538 - Train Accuracy:  0.903, Validation Accuracy:  0.899, Loss:  0.077
Epoch   2 Batch  176/538 - Train Accuracy:  0.867, Validation Accuracy:  0.901, Loss:  0.090
Epoch   2 Batch  177/538 - Train Accuracy:  0.897, Validation Accuracy:  0.900, Loss:  0.085
Epoch   2 Batch  178/538 - Train Accuracy:  0.887, Validation Accuracy:  0.910, Loss:  0.088
Epoch   2 Batch  179/538 - Train Accuracy:  0.915, Validation Accuracy:  0.914, Loss:  0.081
Epoch   2 Batch  180/538 - Train Accuracy:  0.920, Validation Accuracy:  0.916, Loss:  0.088
Epoch   2 Batch  181/538 - Train Accuracy:  0.883, Validation Accuracy:  0.912, Loss:  0.095
Epoch   2 Batch  182/538 - Train Accuracy:  0.900, Validation Accuracy:  0.906, Loss:  0.077
Epoch   2 Batch  183/538 - Train Accuracy:  0.932, Validation Accuracy:  0.919, Loss:  0.074
Epoch   2 Batch  184/538 - Train Accuracy:  0.939, Validation Accuracy:  0.922, Loss:  0.073
Epoch   2 Batch  185/538 - Train Accuracy:  0.928, Validation Accuracy:  0.923, Loss:  0.070
Epoch   2 Batch  186/538 - Train Accuracy:  0.922, Validation Accuracy:  0.917, Loss:  0.080
Epoch   2 Batch  187/538 - Train Accuracy:  0.907, Validation Accuracy:  0.917, Loss:  0.085
Epoch   2 Batch  188/538 - Train Accuracy:  0.909, Validation Accuracy:  0.913, Loss:  0.074
Epoch   2 Batch  189/538 - Train Accuracy:  0.926, Validation Accuracy:  0.905, Loss:  0.085
Epoch   2 Batch  190/538 - Train Accuracy:  0.883, Validation Accuracy:  0.907, Loss:  0.108
Epoch   2 Batch  191/538 - Train Accuracy:  0.920, Validation Accuracy:  0.906, Loss:  0.078
Epoch   2 Batch  192/538 - Train Accuracy:  0.913, Validation Accuracy:  0.910, Loss:  0.076
Epoch   2 Batch  193/538 - Train Accuracy:  0.887, Validation Accuracy:  0.908, Loss:  0.083
Epoch   2 Batch  194/538 - Train Accuracy:  0.890, Validation Accuracy:  0.904, Loss:  0.091
Epoch   2 Batch  195/538 - Train Accuracy:  0.915, Validation Accuracy:  0.905, Loss:  0.081
Epoch   2 Batch  196/538 - Train Accuracy:  0.902, Validation Accuracy:  0.912, Loss:  0.081
Epoch   2 Batch  197/538 - Train Accuracy:  0.915, Validation Accuracy:  0.917, Loss:  0.082
Epoch   2 Batch  198/538 - Train Accuracy:  0.905, Validation Accuracy:  0.924, Loss:  0.076
Epoch   2 Batch  199/538 - Train Accuracy:  0.888, Validation Accuracy:  0.921, Loss:  0.087
Epoch   2 Batch  200/538 - Train Accuracy:  0.908, Validation Accuracy:  0.912, Loss:  0.071
Epoch   2 Batch  201/538 - Train Accuracy:  0.900, Validation Accuracy:  0.910, Loss:  0.089
Epoch   2 Batch  202/538 - Train Accuracy:  0.930, Validation Accuracy:  0.913, Loss:  0.076
Epoch   2 Batch  203/538 - Train Accuracy:  0.911, Validation Accuracy:  0.911, Loss:  0.086
Epoch   2 Batch  204/538 - Train Accuracy:  0.887, Validation Accuracy:  0.912, Loss:  0.084
Epoch   2 Batch  205/538 - Train Accuracy:  0.922, Validation Accuracy:  0.915, Loss:  0.075
Epoch   2 Batch  206/538 - Train Accuracy:  0.896, Validation Accuracy:  0.912, Loss:  0.082
Epoch   2 Batch  207/538 - Train Accuracy:  0.918, Validation Accuracy:  0.918, Loss:  0.076
Epoch   2 Batch  208/538 - Train Accuracy:  0.906, Validation Accuracy:  0.922, Loss:  0.098
Epoch   2 Batch  209/538 - Train Accuracy:  0.922, Validation Accuracy:  0.923, Loss:  0.072
Epoch   2 Batch  210/538 - Train Accuracy:  0.888, Validation Accuracy:  0.917, Loss:  0.081
Epoch   2 Batch  211/538 - Train Accuracy:  0.913, Validation Accuracy:  0.920, Loss:  0.084
Epoch   2 Batch  212/538 - Train Accuracy:  0.897, Validation Accuracy:  0.926, Loss:  0.075
Epoch   2 Batch  213/538 - Train Accuracy:  0.915, Validation Accuracy:  0.933, Loss:  0.074
Epoch   2 Batch  214/538 - Train Accuracy:  0.906, Validation Accuracy:  0.937, Loss:  0.070
Epoch   2 Batch  215/538 - Train Accuracy:  0.909, Validation Accuracy:  0.924, Loss:  0.073
Epoch   2 Batch  216/538 - Train Accuracy:  0.915, Validation Accuracy:  0.917, Loss:  0.085
Epoch   2 Batch  217/538 - Train Accuracy:  0.918, Validation Accuracy:  0.910, Loss:  0.078
Epoch   2 Batch  218/538 - Train Accuracy:  0.911, Validation Accuracy:  0.912, Loss:  0.071
Epoch   2 Batch  219/538 - Train Accuracy:  0.876, Validation Accuracy:  0.911, Loss:  0.098
Epoch   2 Batch  220/538 - Train Accuracy:  0.894, Validation Accuracy:  0.906, Loss:  0.077
Epoch   2 Batch  221/538 - Train Accuracy:  0.926, Validation Accuracy:  0.898, Loss:  0.069
Epoch   2 Batch  222/538 - Train Accuracy:  0.885, Validation Accuracy:  0.895, Loss:  0.073
Epoch   2 Batch  223/538 - Train Accuracy:  0.899, Validation Accuracy:  0.910, Loss:  0.087
Epoch   2 Batch  224/538 - Train Accuracy:  0.908, Validation Accuracy:  0.913, Loss:  0.084
Epoch   2 Batch  225/538 - Train Accuracy:  0.920, Validation Accuracy:  0.912, Loss:  0.077
Epoch   2 Batch  226/538 - Train Accuracy:  0.909, Validation Accuracy:  0.911, Loss:  0.076
Epoch   2 Batch  227/538 - Train Accuracy:  0.920, Validation Accuracy:  0.910, Loss:  0.078
Epoch   2 Batch  228/538 - Train Accuracy:  0.885, Validation Accuracy:  0.906, Loss:  0.077
Epoch   2 Batch  229/538 - Train Accuracy:  0.925, Validation Accuracy:  0.909, Loss:  0.078
Epoch   2 Batch  230/538 - Train Accuracy:  0.899, Validation Accuracy:  0.916, Loss:  0.079
Epoch   2 Batch  231/538 - Train Accuracy:  0.899, Validation Accuracy:  0.913, Loss:  0.076
Epoch   2 Batch  232/538 - Train Accuracy:  0.910, Validation Accuracy:  0.907, Loss:  0.073
Epoch   2 Batch  233/538 - Train Accuracy:  0.911, Validation Accuracy:  0.907, Loss:  0.084
Epoch   2 Batch  234/538 - Train Accuracy:  0.906, Validation Accuracy:  0.900, Loss:  0.079
Epoch   2 Batch  235/538 - Train Accuracy:  0.917, Validation Accuracy:  0.901, Loss:  0.067
Epoch   2 Batch  236/538 - Train Accuracy:  0.905, Validation Accuracy:  0.912, Loss:  0.082
Epoch   2 Batch  237/538 - Train Accuracy:  0.917, Validation Accuracy:  0.913, Loss:  0.069
Epoch   2 Batch  238/538 - Train Accuracy:  0.940, Validation Accuracy:  0.910, Loss:  0.071
Epoch   2 Batch  239/538 - Train Accuracy:  0.899, Validation Accuracy:  0.913, Loss:  0.075
Epoch   2 Batch  240/538 - Train Accuracy:  0.913, Validation Accuracy:  0.923, Loss:  0.086
Epoch   2 Batch  241/538 - Train Accuracy:  0.911, Validation Accuracy:  0.919, Loss:  0.079
Epoch   2 Batch  242/538 - Train Accuracy:  0.913, Validation Accuracy:  0.916, Loss:  0.078
Epoch   2 Batch  243/538 - Train Accuracy:  0.897, Validation Accuracy:  0.913, Loss:  0.075
Epoch   2 Batch  244/538 - Train Accuracy:  0.895, Validation Accuracy:  0.916, Loss:  0.073
Epoch   2 Batch  245/538 - Train Accuracy:  0.903, Validation Accuracy:  0.919, Loss:  0.084
Epoch   2 Batch  246/538 - Train Accuracy:  0.932, Validation Accuracy:  0.911, Loss:  0.062
Epoch   2 Batch  247/538 - Train Accuracy:  0.907, Validation Accuracy:  0.911, Loss:  0.075
Epoch   2 Batch  248/538 - Train Accuracy:  0.916, Validation Accuracy:  0.911, Loss:  0.077
Epoch   2 Batch  249/538 - Train Accuracy:  0.908, Validation Accuracy:  0.915, Loss:  0.065
Epoch   2 Batch  250/538 - Train Accuracy:  0.913, Validation Accuracy:  0.917, Loss:  0.076
Epoch   2 Batch  251/538 - Train Accuracy:  0.928, Validation Accuracy:  0.910, Loss:  0.073
Epoch   2 Batch  252/538 - Train Accuracy:  0.919, Validation Accuracy:  0.912, Loss:  0.069
Epoch   2 Batch  253/538 - Train Accuracy:  0.883, Validation Accuracy:  0.915, Loss:  0.070
Epoch   2 Batch  254/538 - Train Accuracy:  0.900, Validation Accuracy:  0.913, Loss:  0.078
Epoch   2 Batch  255/538 - Train Accuracy:  0.916, Validation Accuracy:  0.910, Loss:  0.073
Epoch   2 Batch  256/538 - Train Accuracy:  0.900, Validation Accuracy:  0.905, Loss:  0.080
Epoch   2 Batch  257/538 - Train Accuracy:  0.904, Validation Accuracy:  0.905, Loss:  0.073
Epoch   2 Batch  258/538 - Train Accuracy:  0.913, Validation Accuracy:  0.907, Loss:  0.073
Epoch   2 Batch  259/538 - Train Accuracy:  0.927, Validation Accuracy:  0.910, Loss:  0.068
Epoch   2 Batch  260/538 - Train Accuracy:  0.878, Validation Accuracy:  0.914, Loss:  0.084
Epoch   2 Batch  261/538 - Train Accuracy:  0.907, Validation Accuracy:  0.915, Loss:  0.074
Epoch   2 Batch  262/538 - Train Accuracy:  0.914, Validation Accuracy:  0.921, Loss:  0.067
Epoch   2 Batch  263/538 - Train Accuracy:  0.904, Validation Accuracy:  0.925, Loss:  0.073
Epoch   2 Batch  264/538 - Train Accuracy:  0.901, Validation Accuracy:  0.924, Loss:  0.077
Epoch   2 Batch  265/538 - Train Accuracy:  0.893, Validation Accuracy:  0.919, Loss:  0.083
Epoch   2 Batch  266/538 - Train Accuracy:  0.880, Validation Accuracy:  0.923, Loss:  0.075
Epoch   2 Batch  267/538 - Train Accuracy:  0.903, Validation Accuracy:  0.912, Loss:  0.078
Epoch   2 Batch  268/538 - Train Accuracy:  0.907, Validation Accuracy:  0.905, Loss:  0.061
Epoch   2 Batch  269/538 - Train Accuracy:  0.893, Validation Accuracy:  0.900, Loss:  0.072
Epoch   2 Batch  270/538 - Train Accuracy:  0.918, Validation Accuracy:  0.907, Loss:  0.067
Epoch   2 Batch  271/538 - Train Accuracy:  0.915, Validation Accuracy:  0.907, Loss:  0.065
Epoch   2 Batch  272/538 - Train Accuracy:  0.899, Validation Accuracy:  0.911, Loss:  0.082
Epoch   2 Batch  273/538 - Train Accuracy:  0.915, Validation Accuracy:  0.920, Loss:  0.076
Epoch   2 Batch  274/538 - Train Accuracy:  0.862, Validation Accuracy:  0.913, Loss:  0.079
Epoch   2 Batch  275/538 - Train Accuracy:  0.912, Validation Accuracy:  0.915, Loss:  0.080
Epoch   2 Batch  276/538 - Train Accuracy:  0.904, Validation Accuracy:  0.918, Loss:  0.076
Epoch   2 Batch  277/538 - Train Accuracy:  0.908, Validation Accuracy:  0.922, Loss:  0.067
Epoch   2 Batch  278/538 - Train Accuracy:  0.911, Validation Accuracy:  0.917, Loss:  0.068
Epoch   2 Batch  279/538 - Train Accuracy:  0.912, Validation Accuracy:  0.909, Loss:  0.068
Epoch   2 Batch  280/538 - Train Accuracy:  0.921, Validation Accuracy:  0.911, Loss:  0.066
Epoch   2 Batch  281/538 - Train Accuracy:  0.913, Validation Accuracy:  0.914, Loss:  0.074
Epoch   2 Batch  282/538 - Train Accuracy:  0.917, Validation Accuracy:  0.914, Loss:  0.082
Epoch   2 Batch  283/538 - Train Accuracy:  0.916, Validation Accuracy:  0.911, Loss:  0.072
Epoch   2 Batch  284/538 - Train Accuracy:  0.920, Validation Accuracy:  0.915, Loss:  0.077
Epoch   2 Batch  285/538 - Train Accuracy:  0.927, Validation Accuracy:  0.912, Loss:  0.062
Epoch   2 Batch  286/538 - Train Accuracy:  0.899, Validation Accuracy:  0.917, Loss:  0.075
Epoch   2 Batch  287/538 - Train Accuracy:  0.918, Validation Accuracy:  0.911, Loss:  0.062
Epoch   2 Batch  288/538 - Train Accuracy:  0.924, Validation Accuracy:  0.911, Loss:  0.066
Epoch   2 Batch  289/538 - Train Accuracy:  0.919, Validation Accuracy:  0.923, Loss:  0.058
Epoch   2 Batch  290/538 - Train Accuracy:  0.932, Validation Accuracy:  0.922, Loss:  0.064
Epoch   2 Batch  291/538 - Train Accuracy:  0.916, Validation Accuracy:  0.920, Loss:  0.073
Epoch   2 Batch  292/538 - Train Accuracy:  0.911, Validation Accuracy:  0.925, Loss:  0.059
Epoch   2 Batch  293/538 - Train Accuracy:  0.916, Validation Accuracy:  0.922, Loss:  0.068
Epoch   2 Batch  294/538 - Train Accuracy:  0.907, Validation Accuracy:  0.923, Loss:  0.076
Epoch   2 Batch  295/538 - Train Accuracy:  0.925, Validation Accuracy:  0.927, Loss:  0.070
Epoch   2 Batch  296/538 - Train Accuracy:  0.909, Validation Accuracy:  0.922, Loss:  0.077
Epoch   2 Batch  297/538 - Train Accuracy:  0.920, Validation Accuracy:  0.931, Loss:  0.071
Epoch   2 Batch  298/538 - Train Accuracy:  0.898, Validation Accuracy:  0.924, Loss:  0.067
Epoch   2 Batch  299/538 - Train Accuracy:  0.899, Validation Accuracy:  0.920, Loss:  0.080
Epoch   2 Batch  300/538 - Train Accuracy:  0.918, Validation Accuracy:  0.910, Loss:  0.072
Epoch   2 Batch  301/538 - Train Accuracy:  0.897, Validation Accuracy:  0.917, Loss:  0.071
Epoch   2 Batch  302/538 - Train Accuracy:  0.935, Validation Accuracy:  0.922, Loss:  0.067
Epoch   2 Batch  303/538 - Train Accuracy:  0.927, Validation Accuracy:  0.922, Loss:  0.069
Epoch   2 Batch  304/538 - Train Accuracy:  0.907, Validation Accuracy:  0.926, Loss:  0.070
Epoch   2 Batch  305/538 - Train Accuracy:  0.914, Validation Accuracy:  0.919, Loss:  0.063
Epoch   2 Batch  306/538 - Train Accuracy:  0.896, Validation Accuracy:  0.922, Loss:  0.079
Epoch   2 Batch  307/538 - Train Accuracy:  0.931, Validation Accuracy:  0.926, Loss:  0.070
Epoch   2 Batch  308/538 - Train Accuracy:  0.918, Validation Accuracy:  0.937, Loss:  0.067
Epoch   2 Batch  309/538 - Train Accuracy:  0.913, Validation Accuracy:  0.928, Loss:  0.058
Epoch   2 Batch  310/538 - Train Accuracy:  0.938, Validation Accuracy:  0.922, Loss:  0.066
Epoch   2 Batch  311/538 - Train Accuracy:  0.899, Validation Accuracy:  0.919, Loss:  0.074
Epoch   2 Batch  312/538 - Train Accuracy:  0.915, Validation Accuracy:  0.914, Loss:  0.061
Epoch   2 Batch  313/538 - Train Accuracy:  0.908, Validation Accuracy:  0.921, Loss:  0.075
Epoch   2 Batch  314/538 - Train Accuracy:  0.920, Validation Accuracy:  0.925, Loss:  0.071
Epoch   2 Batch  315/538 - Train Accuracy:  0.907, Validation Accuracy:  0.928, Loss:  0.068
Epoch   2 Batch  316/538 - Train Accuracy:  0.915, Validation Accuracy:  0.925, Loss:  0.054
Epoch   2 Batch  317/538 - Train Accuracy:  0.930, Validation Accuracy:  0.920, Loss:  0.064
Epoch   2 Batch  318/538 - Train Accuracy:  0.901, Validation Accuracy:  0.922, Loss:  0.062
Epoch   2 Batch  319/538 - Train Accuracy:  0.906, Validation Accuracy:  0.927, Loss:  0.073
Epoch   2 Batch  320/538 - Train Accuracy:  0.914, Validation Accuracy:  0.919, Loss:  0.064
Epoch   2 Batch  321/538 - Train Accuracy:  0.911, Validation Accuracy:  0.920, Loss:  0.063
Epoch   2 Batch  322/538 - Train Accuracy:  0.914, Validation Accuracy:  0.925, Loss:  0.074
Epoch   2 Batch  323/538 - Train Accuracy:  0.923, Validation Accuracy:  0.929, Loss:  0.060
Epoch   2 Batch  324/538 - Train Accuracy:  0.903, Validation Accuracy:  0.926, Loss:  0.072
Epoch   2 Batch  325/538 - Train Accuracy:  0.925, Validation Accuracy:  0.930, Loss:  0.064
Epoch   2 Batch  326/538 - Train Accuracy:  0.921, Validation Accuracy:  0.929, Loss:  0.067
Epoch   2 Batch  327/538 - Train Accuracy:  0.905, Validation Accuracy:  0.936, Loss:  0.077
Epoch   2 Batch  328/538 - Train Accuracy:  0.929, Validation Accuracy:  0.932, Loss:  0.058
Epoch   2 Batch  329/538 - Train Accuracy:  0.915, Validation Accuracy:  0.920, Loss:  0.064
Epoch   2 Batch  330/538 - Train Accuracy:  0.925, Validation Accuracy:  0.918, Loss:  0.063
Epoch   2 Batch  331/538 - Train Accuracy:  0.909, Validation Accuracy:  0.911, Loss:  0.061
Epoch   2 Batch  332/538 - Train Accuracy:  0.916, Validation Accuracy:  0.918, Loss:  0.061
Epoch   2 Batch  333/538 - Train Accuracy:  0.926, Validation Accuracy:  0.919, Loss:  0.068
Epoch   2 Batch  334/538 - Train Accuracy:  0.921, Validation Accuracy:  0.925, Loss:  0.062
Epoch   2 Batch  335/538 - Train Accuracy:  0.917, Validation Accuracy:  0.932, Loss:  0.066
Epoch   2 Batch  336/538 - Train Accuracy:  0.912, Validation Accuracy:  0.928, Loss:  0.060
Epoch   2 Batch  337/538 - Train Accuracy:  0.923, Validation Accuracy:  0.916, Loss:  0.062
Epoch   2 Batch  338/538 - Train Accuracy:  0.916, Validation Accuracy:  0.916, Loss:  0.065
Epoch   2 Batch  339/538 - Train Accuracy:  0.908, Validation Accuracy:  0.914, Loss:  0.063
Epoch   2 Batch  340/538 - Train Accuracy:  0.905, Validation Accuracy:  0.927, Loss:  0.065
Epoch   2 Batch  341/538 - Train Accuracy:  0.923, Validation Accuracy:  0.928, Loss:  0.061
Epoch   2 Batch  342/538 - Train Accuracy:  0.908, Validation Accuracy:  0.920, Loss:  0.065
Epoch   2 Batch  343/538 - Train Accuracy:  0.928, Validation Accuracy:  0.924, Loss:  0.065
Epoch   2 Batch  344/538 - Train Accuracy:  0.935, Validation Accuracy:  0.928, Loss:  0.060
Epoch   2 Batch  345/538 - Train Accuracy:  0.919, Validation Accuracy:  0.931, Loss:  0.064
Epoch   2 Batch  346/538 - Train Accuracy:  0.894, Validation Accuracy:  0.928, Loss:  0.080
Epoch   2 Batch  347/538 - Train Accuracy:  0.919, Validation Accuracy:  0.930, Loss:  0.063
Epoch   2 Batch  348/538 - Train Accuracy:  0.914, Validation Accuracy:  0.928, Loss:  0.058
Epoch   2 Batch  349/538 - Train Accuracy:  0.927, Validation Accuracy:  0.927, Loss:  0.056
Epoch   2 Batch  350/538 - Train Accuracy:  0.927, Validation Accuracy:  0.927, Loss:  0.070
Epoch   2 Batch  351/538 - Train Accuracy:  0.901, Validation Accuracy:  0.924, Loss:  0.078
Epoch   2 Batch  352/538 - Train Accuracy:  0.890, Validation Accuracy:  0.922, Loss:  0.082
Epoch   2 Batch  353/538 - Train Accuracy:  0.906, Validation Accuracy:  0.914, Loss:  0.070
Epoch   2 Batch  354/538 - Train Accuracy:  0.887, Validation Accuracy:  0.919, Loss:  0.073
Epoch   2 Batch  355/538 - Train Accuracy:  0.920, Validation Accuracy:  0.930, Loss:  0.068
Epoch   2 Batch  356/538 - Train Accuracy:  0.919, Validation Accuracy:  0.937, Loss:  0.059
Epoch   2 Batch  357/538 - Train Accuracy:  0.912, Validation Accuracy:  0.930, Loss:  0.064
Epoch   2 Batch  358/538 - Train Accuracy:  0.928, Validation Accuracy:  0.928, Loss:  0.057
Epoch   2 Batch  359/538 - Train Accuracy:  0.905, Validation Accuracy:  0.926, Loss:  0.069
Epoch   2 Batch  360/538 - Train Accuracy:  0.911, Validation Accuracy:  0.924, Loss:  0.066
Epoch   2 Batch  361/538 - Train Accuracy:  0.926, Validation Accuracy:  0.930, Loss:  0.065
Epoch   2 Batch  362/538 - Train Accuracy:  0.932, Validation Accuracy:  0.929, Loss:  0.054
Epoch   2 Batch  363/538 - Train Accuracy:  0.906, Validation Accuracy:  0.931, Loss:  0.065
Epoch   2 Batch  364/538 - Train Accuracy:  0.913, Validation Accuracy:  0.927, Loss:  0.085
Epoch   2 Batch  365/538 - Train Accuracy:  0.911, Validation Accuracy:  0.931, Loss:  0.064
Epoch   2 Batch  366/538 - Train Accuracy:  0.925, Validation Accuracy:  0.933, Loss:  0.063
Epoch   2 Batch  367/538 - Train Accuracy:  0.926, Validation Accuracy:  0.926, Loss:  0.056
Epoch   2 Batch  368/538 - Train Accuracy:  0.928, Validation Accuracy:  0.928, Loss:  0.054
Epoch   2 Batch  369/538 - Train Accuracy:  0.928, Validation Accuracy:  0.926, Loss:  0.057
Epoch   2 Batch  370/538 - Train Accuracy:  0.921, Validation Accuracy:  0.928, Loss:  0.071
Epoch   2 Batch  371/538 - Train Accuracy:  0.919, Validation Accuracy:  0.931, Loss:  0.061
Epoch   2 Batch  372/538 - Train Accuracy:  0.943, Validation Accuracy:  0.924, Loss:  0.060
Epoch   2 Batch  373/538 - Train Accuracy:  0.935, Validation Accuracy:  0.913, Loss:  0.053
Epoch   2 Batch  374/538 - Train Accuracy:  0.905, Validation Accuracy:  0.907, Loss:  0.063
Epoch   2 Batch  375/538 - Train Accuracy:  0.921, Validation Accuracy:  0.919, Loss:  0.056
Epoch   2 Batch  376/538 - Train Accuracy:  0.907, Validation Accuracy:  0.922, Loss:  0.066
Epoch   2 Batch  377/538 - Train Accuracy:  0.932, Validation Accuracy:  0.927, Loss:  0.064
Epoch   2 Batch  378/538 - Train Accuracy:  0.929, Validation Accuracy:  0.927, Loss:  0.057
Epoch   2 Batch  379/538 - Train Accuracy:  0.920, Validation Accuracy:  0.921, Loss:  0.062
Epoch   2 Batch  380/538 - Train Accuracy:  0.921, Validation Accuracy:  0.923, Loss:  0.057
Epoch   2 Batch  381/538 - Train Accuracy:  0.931, Validation Accuracy:  0.920, Loss:  0.059
Epoch   2 Batch  382/538 - Train Accuracy:  0.907, Validation Accuracy:  0.920, Loss:  0.061
Epoch   2 Batch  383/538 - Train Accuracy:  0.916, Validation Accuracy:  0.931, Loss:  0.068
Epoch   2 Batch  384/538 - Train Accuracy:  0.905, Validation Accuracy:  0.925, Loss:  0.062
Epoch   2 Batch  385/538 - Train Accuracy:  0.938, Validation Accuracy:  0.923, Loss:  0.056
Epoch   2 Batch  386/538 - Train Accuracy:  0.919, Validation Accuracy:  0.922, Loss:  0.063
Epoch   2 Batch  387/538 - Train Accuracy:  0.916, Validation Accuracy:  0.925, Loss:  0.062
Epoch   2 Batch  388/538 - Train Accuracy:  0.923, Validation Accuracy:  0.926, Loss:  0.068
Epoch   2 Batch  389/538 - Train Accuracy:  0.901, Validation Accuracy:  0.925, Loss:  0.074
Epoch   2 Batch  390/538 - Train Accuracy:  0.935, Validation Accuracy:  0.926, Loss:  0.059
Epoch   2 Batch  391/538 - Train Accuracy:  0.916, Validation Accuracy:  0.928, Loss:  0.057
Epoch   2 Batch  392/538 - Train Accuracy:  0.912, Validation Accuracy:  0.931, Loss:  0.063
Epoch   2 Batch  393/538 - Train Accuracy:  0.940, Validation Accuracy:  0.926, Loss:  0.061
Epoch   2 Batch  394/538 - Train Accuracy:  0.881, Validation Accuracy:  0.929, Loss:  0.068
Epoch   2 Batch  395/538 - Train Accuracy:  0.908, Validation Accuracy:  0.934, Loss:  0.068
Epoch   2 Batch  396/538 - Train Accuracy:  0.917, Validation Accuracy:  0.939, Loss:  0.056
Epoch   2 Batch  397/538 - Train Accuracy:  0.924, Validation Accuracy:  0.944, Loss:  0.067
Epoch   2 Batch  398/538 - Train Accuracy:  0.938, Validation Accuracy:  0.942, Loss:  0.057
Epoch   2 Batch  399/538 - Train Accuracy:  0.907, Validation Accuracy:  0.944, Loss:  0.076
Epoch   2 Batch  400/538 - Train Accuracy:  0.920, Validation Accuracy:  0.936, Loss:  0.065
Epoch   2 Batch  401/538 - Train Accuracy:  0.936, Validation Accuracy:  0.935, Loss:  0.060
Epoch   2 Batch  402/538 - Train Accuracy:  0.928, Validation Accuracy:  0.940, Loss:  0.060
Epoch   2 Batch  403/538 - Train Accuracy:  0.919, Validation Accuracy:  0.935, Loss:  0.070
Epoch   2 Batch  404/538 - Train Accuracy:  0.918, Validation Accuracy:  0.935, Loss:  0.062
Epoch   2 Batch  405/538 - Train Accuracy:  0.927, Validation Accuracy:  0.931, Loss:  0.059
Epoch   2 Batch  406/538 - Train Accuracy:  0.921, Validation Accuracy:  0.920, Loss:  0.061
Epoch   2 Batch  407/538 - Train Accuracy:  0.926, Validation Accuracy:  0.928, Loss:  0.063
Epoch   2 Batch  408/538 - Train Accuracy:  0.922, Validation Accuracy:  0.918, Loss:  0.066
Epoch   2 Batch  409/538 - Train Accuracy:  0.913, Validation Accuracy:  0.923, Loss:  0.066
Epoch   2 Batch  410/538 - Train Accuracy:  0.931, Validation Accuracy:  0.922, Loss:  0.063
Epoch   2 Batch  411/538 - Train Accuracy:  0.942, Validation Accuracy:  0.925, Loss:  0.061
Epoch   2 Batch  412/538 - Train Accuracy:  0.900, Validation Accuracy:  0.923, Loss:  0.052
Epoch   2 Batch  413/538 - Train Accuracy:  0.929, Validation Accuracy:  0.928, Loss:  0.060
Epoch   2 Batch  414/538 - Train Accuracy:  0.881, Validation Accuracy:  0.931, Loss:  0.069
Epoch   2 Batch  415/538 - Train Accuracy:  0.897, Validation Accuracy:  0.937, Loss:  0.064
Epoch   2 Batch  416/538 - Train Accuracy:  0.920, Validation Accuracy:  0.935, Loss:  0.064
Epoch   2 Batch  417/538 - Train Accuracy:  0.921, Validation Accuracy:  0.936, Loss:  0.053
Epoch   2 Batch  418/538 - Train Accuracy:  0.925, Validation Accuracy:  0.935, Loss:  0.064
Epoch   2 Batch  419/538 - Train Accuracy:  0.935, Validation Accuracy:  0.928, Loss:  0.048
Epoch   2 Batch  420/538 - Train Accuracy:  0.928, Validation Accuracy:  0.935, Loss:  0.060
Epoch   2 Batch  421/538 - Train Accuracy:  0.924, Validation Accuracy:  0.938, Loss:  0.054
Epoch   2 Batch  422/538 - Train Accuracy:  0.923, Validation Accuracy:  0.937, Loss:  0.061
Epoch   2 Batch  423/538 - Train Accuracy:  0.922, Validation Accuracy:  0.938, Loss:  0.067
Epoch   2 Batch  424/538 - Train Accuracy:  0.914, Validation Accuracy:  0.927, Loss:  0.069
Epoch   2 Batch  425/538 - Train Accuracy:  0.902, Validation Accuracy:  0.925, Loss:  0.076
Epoch   2 Batch  426/538 - Train Accuracy:  0.927, Validation Accuracy:  0.923, Loss:  0.058
Epoch   2 Batch  427/538 - Train Accuracy:  0.891, Validation Accuracy:  0.924, Loss:  0.066
Epoch   2 Batch  428/538 - Train Accuracy:  0.936, Validation Accuracy:  0.931, Loss:  0.059
Epoch   2 Batch  429/538 - Train Accuracy:  0.929, Validation Accuracy:  0.932, Loss:  0.064
Epoch   2 Batch  430/538 - Train Accuracy:  0.918, Validation Accuracy:  0.931, Loss:  0.054
Epoch   2 Batch  431/538 - Train Accuracy:  0.915, Validation Accuracy:  0.911, Loss:  0.055
Epoch   2 Batch  432/538 - Train Accuracy:  0.924, Validation Accuracy:  0.906, Loss:  0.061
Epoch   2 Batch  433/538 - Train Accuracy:  0.914, Validation Accuracy:  0.920, Loss:  0.089
Epoch   2 Batch  434/538 - Train Accuracy:  0.910, Validation Accuracy:  0.918, Loss:  0.060
Epoch   2 Batch  435/538 - Train Accuracy:  0.917, Validation Accuracy:  0.930, Loss:  0.060
Epoch   2 Batch  436/538 - Train Accuracy:  0.902, Validation Accuracy:  0.928, Loss:  0.069
Epoch   2 Batch  437/538 - Train Accuracy:  0.932, Validation Accuracy:  0.924, Loss:  0.058
Epoch   2 Batch  438/538 - Train Accuracy:  0.935, Validation Accuracy:  0.919, Loss:  0.054
Epoch   2 Batch  439/538 - Train Accuracy:  0.942, Validation Accuracy:  0.927, Loss:  0.057
Epoch   2 Batch  440/538 - Train Accuracy:  0.914, Validation Accuracy:  0.928, Loss:  0.061
Epoch   2 Batch  441/538 - Train Accuracy:  0.909, Validation Accuracy:  0.930, Loss:  0.071
Epoch   2 Batch  442/538 - Train Accuracy:  0.937, Validation Accuracy:  0.926, Loss:  0.051
Epoch   2 Batch  443/538 - Train Accuracy:  0.920, Validation Accuracy:  0.925, Loss:  0.063
Epoch   2 Batch  444/538 - Train Accuracy:  0.921, Validation Accuracy:  0.918, Loss:  0.061
Epoch   2 Batch  445/538 - Train Accuracy:  0.933, Validation Accuracy:  0.919, Loss:  0.050
Epoch   2 Batch  446/538 - Train Accuracy:  0.932, Validation Accuracy:  0.933, Loss:  0.060
Epoch   2 Batch  447/538 - Train Accuracy:  0.924, Validation Accuracy:  0.932, Loss:  0.062
Epoch   2 Batch  448/538 - Train Accuracy:  0.924, Validation Accuracy:  0.931, Loss:  0.051
Epoch   2 Batch  449/538 - Train Accuracy:  0.927, Validation Accuracy:  0.915, Loss:  0.061
Epoch   2 Batch  450/538 - Train Accuracy:  0.905, Validation Accuracy:  0.917, Loss:  0.073
Epoch   2 Batch  451/538 - Train Accuracy:  0.901, Validation Accuracy:  0.914, Loss:  0.060
Epoch   2 Batch  452/538 - Train Accuracy:  0.932, Validation Accuracy:  0.924, Loss:  0.051
Epoch   2 Batch  453/538 - Train Accuracy:  0.928, Validation Accuracy:  0.922, Loss:  0.064
Epoch   2 Batch  454/538 - Train Accuracy:  0.920, Validation Accuracy:  0.926, Loss:  0.062
Epoch   2 Batch  455/538 - Train Accuracy:  0.930, Validation Accuracy:  0.926, Loss:  0.059
Epoch   2 Batch  456/538 - Train Accuracy:  0.934, Validation Accuracy:  0.927, Loss:  0.074
Epoch   2 Batch  457/538 - Train Accuracy:  0.924, Validation Accuracy:  0.924, Loss:  0.056
Epoch   2 Batch  458/538 - Train Accuracy:  0.925, Validation Accuracy:  0.925, Loss:  0.054
Epoch   2 Batch  459/538 - Train Accuracy:  0.930, Validation Accuracy:  0.923, Loss:  0.053
Epoch   2 Batch  460/538 - Train Accuracy:  0.903, Validation Accuracy:  0.927, Loss:  0.064
Epoch   2 Batch  461/538 - Train Accuracy:  0.939, Validation Accuracy:  0.930, Loss:  0.057
Epoch   2 Batch  462/538 - Train Accuracy:  0.911, Validation Accuracy:  0.930, Loss:  0.060
Epoch   2 Batch  463/538 - Train Accuracy:  0.899, Validation Accuracy:  0.930, Loss:  0.062
Epoch   2 Batch  464/538 - Train Accuracy:  0.936, Validation Accuracy:  0.932, Loss:  0.052
Epoch   2 Batch  465/538 - Train Accuracy:  0.925, Validation Accuracy:  0.935, Loss:  0.054
Epoch   2 Batch  466/538 - Train Accuracy:  0.915, Validation Accuracy:  0.932, Loss:  0.055
Epoch   2 Batch  467/538 - Train Accuracy:  0.938, Validation Accuracy:  0.933, Loss:  0.056
Epoch   2 Batch  468/538 - Train Accuracy:  0.928, Validation Accuracy:  0.933, Loss:  0.068
Epoch   2 Batch  469/538 - Train Accuracy:  0.929, Validation Accuracy:  0.930, Loss:  0.058
Epoch   2 Batch  470/538 - Train Accuracy:  0.933, Validation Accuracy:  0.928, Loss:  0.054
Epoch   2 Batch  471/538 - Train Accuracy:  0.939, Validation Accuracy:  0.927, Loss:  0.051
Epoch   2 Batch  472/538 - Train Accuracy:  0.956, Validation Accuracy:  0.928, Loss:  0.049
Epoch   2 Batch  473/538 - Train Accuracy:  0.901, Validation Accuracy:  0.930, Loss:  0.058
Epoch   2 Batch  474/538 - Train Accuracy:  0.933, Validation Accuracy:  0.925, Loss:  0.051
Epoch   2 Batch  475/538 - Train Accuracy:  0.944, Validation Accuracy:  0.930, Loss:  0.056
Epoch   2 Batch  476/538 - Train Accuracy:  0.912, Validation Accuracy:  0.929, Loss:  0.050
Epoch   2 Batch  477/538 - Train Accuracy:  0.922, Validation Accuracy:  0.923, Loss:  0.061
Epoch   2 Batch  478/538 - Train Accuracy:  0.940, Validation Accuracy:  0.930, Loss:  0.049
Epoch   2 Batch  479/538 - Train Accuracy:  0.924, Validation Accuracy:  0.932, Loss:  0.052
Epoch   2 Batch  480/538 - Train Accuracy:  0.937, Validation Accuracy:  0.920, Loss:  0.054
Epoch   2 Batch  481/538 - Train Accuracy:  0.946, Validation Accuracy:  0.918, Loss:  0.055
Epoch   2 Batch  482/538 - Train Accuracy:  0.932, Validation Accuracy:  0.912, Loss:  0.048
Epoch   2 Batch  483/538 - Train Accuracy:  0.896, Validation Accuracy:  0.921, Loss:  0.067
Epoch   2 Batch  484/538 - Train Accuracy:  0.928, Validation Accuracy:  0.924, Loss:  0.063
Epoch   2 Batch  485/538 - Train Accuracy:  0.928, Validation Accuracy:  0.922, Loss:  0.062
Epoch   2 Batch  486/538 - Train Accuracy:  0.933, Validation Accuracy:  0.924, Loss:  0.045
Epoch   2 Batch  487/538 - Train Accuracy:  0.922, Validation Accuracy:  0.914, Loss:  0.048
Epoch   2 Batch  488/538 - Train Accuracy:  0.951, Validation Accuracy:  0.917, Loss:  0.049
Epoch   2 Batch  489/538 - Train Accuracy:  0.909, Validation Accuracy:  0.915, Loss:  0.061
Epoch   2 Batch  490/538 - Train Accuracy:  0.928, Validation Accuracy:  0.926, Loss:  0.052
Epoch   2 Batch  491/538 - Train Accuracy:  0.898, Validation Accuracy:  0.925, Loss:  0.059
Epoch   2 Batch  492/538 - Train Accuracy:  0.918, Validation Accuracy:  0.926, Loss:  0.053
Epoch   2 Batch  493/538 - Train Accuracy:  0.917, Validation Accuracy:  0.930, Loss:  0.051
Epoch   2 Batch  494/538 - Train Accuracy:  0.931, Validation Accuracy:  0.931, Loss:  0.062
Epoch   2 Batch  495/538 - Train Accuracy:  0.938, Validation Accuracy:  0.930, Loss:  0.058
Epoch   2 Batch  496/538 - Train Accuracy:  0.938, Validation Accuracy:  0.933, Loss:  0.046
Epoch   2 Batch  497/538 - Train Accuracy:  0.922, Validation Accuracy:  0.935, Loss:  0.055
Epoch   2 Batch  498/538 - Train Accuracy:  0.926, Validation Accuracy:  0.931, Loss:  0.052
Epoch   2 Batch  499/538 - Train Accuracy:  0.919, Validation Accuracy:  0.926, Loss:  0.055
Epoch   2 Batch  500/538 - Train Accuracy:  0.943, Validation Accuracy:  0.923, Loss:  0.042
Epoch   2 Batch  501/538 - Train Accuracy:  0.940, Validation Accuracy:  0.927, Loss:  0.057
Epoch   2 Batch  502/538 - Train Accuracy:  0.924, Validation Accuracy:  0.930, Loss:  0.048
Epoch   2 Batch  503/538 - Train Accuracy:  0.941, Validation Accuracy:  0.937, Loss:  0.054
Epoch   2 Batch  504/538 - Train Accuracy:  0.944, Validation Accuracy:  0.937, Loss:  0.048
Epoch   2 Batch  505/538 - Train Accuracy:  0.937, Validation Accuracy:  0.939, Loss:  0.044
Epoch   2 Batch  506/538 - Train Accuracy:  0.940, Validation Accuracy:  0.937, Loss:  0.045
Epoch   2 Batch  507/538 - Train Accuracy:  0.898, Validation Accuracy:  0.933, Loss:  0.059
Epoch   2 Batch  508/538 - Train Accuracy:  0.929, Validation Accuracy:  0.934, Loss:  0.056
Epoch   2 Batch  509/538 - Train Accuracy:  0.931, Validation Accuracy:  0.931, Loss:  0.053
Epoch   2 Batch  510/538 - Train Accuracy:  0.924, Validation Accuracy:  0.931, Loss:  0.051
Epoch   2 Batch  511/538 - Train Accuracy:  0.924, Validation Accuracy:  0.934, Loss:  0.055
Epoch   2 Batch  512/538 - Train Accuracy:  0.932, Validation Accuracy:  0.935, Loss:  0.055
Epoch   2 Batch  513/538 - Train Accuracy:  0.898, Validation Accuracy:  0.931, Loss:  0.051
Epoch   2 Batch  514/538 - Train Accuracy:  0.932, Validation Accuracy:  0.932, Loss:  0.054
Epoch   2 Batch  515/538 - Train Accuracy:  0.916, Validation Accuracy:  0.938, Loss:  0.062
Epoch   2 Batch  516/538 - Train Accuracy:  0.897, Validation Accuracy:  0.931, Loss:  0.058
Epoch   2 Batch  517/538 - Train Accuracy:  0.941, Validation Accuracy:  0.934, Loss:  0.050
Epoch   2 Batch  518/538 - Train Accuracy:  0.908, Validation Accuracy:  0.939, Loss:  0.059
Epoch   2 Batch  519/538 - Train Accuracy:  0.919, Validation Accuracy:  0.939, Loss:  0.057
Epoch   2 Batch  520/538 - Train Accuracy:  0.925, Validation Accuracy:  0.935, Loss:  0.052
Epoch   2 Batch  521/538 - Train Accuracy:  0.920, Validation Accuracy:  0.936, Loss:  0.063
Epoch   2 Batch  522/538 - Train Accuracy:  0.932, Validation Accuracy:  0.932, Loss:  0.051
Epoch   2 Batch  523/538 - Train Accuracy:  0.938, Validation Accuracy:  0.935, Loss:  0.055
Epoch   2 Batch  524/538 - Train Accuracy:  0.933, Validation Accuracy:  0.933, Loss:  0.055
Epoch   2 Batch  525/538 - Train Accuracy:  0.926, Validation Accuracy:  0.936, Loss:  0.053
Epoch   2 Batch  526/538 - Train Accuracy:  0.933, Validation Accuracy:  0.938, Loss:  0.053
Epoch   2 Batch  527/538 - Train Accuracy:  0.935, Validation Accuracy:  0.935, Loss:  0.055
Epoch   2 Batch  528/538 - Train Accuracy:  0.933, Validation Accuracy:  0.943, Loss:  0.054
Epoch   2 Batch  529/538 - Train Accuracy:  0.916, Validation Accuracy:  0.942, Loss:  0.055
Epoch   2 Batch  530/538 - Train Accuracy:  0.903, Validation Accuracy:  0.943, Loss:  0.058
Epoch   2 Batch  531/538 - Train Accuracy:  0.934, Validation Accuracy:  0.934, Loss:  0.058
Epoch   2 Batch  532/538 - Train Accuracy:  0.914, Validation Accuracy:  0.923, Loss:  0.053
Epoch   2 Batch  533/538 - Train Accuracy:  0.944, Validation Accuracy:  0.936, Loss:  0.049
Epoch   2 Batch  534/538 - Train Accuracy:  0.929, Validation Accuracy:  0.936, Loss:  0.047
Epoch   2 Batch  535/538 - Train Accuracy:  0.940, Validation Accuracy:  0.940, Loss:  0.052
Epoch   2 Batch  536/538 - Train Accuracy:  0.929, Validation Accuracy:  0.942, Loss:  0.060
Epoch   3 Batch    0/538 - Train Accuracy:  0.950, Validation Accuracy:  0.930, Loss:  0.046
Epoch   3 Batch    1/538 - Train Accuracy:  0.928, Validation Accuracy:  0.934, Loss:  0.058
Epoch   3 Batch    2/538 - Train Accuracy:  0.934, Validation Accuracy:  0.944, Loss:  0.064
Epoch   3 Batch    3/538 - Train Accuracy:  0.949, Validation Accuracy:  0.939, Loss:  0.047
Epoch   3 Batch    4/538 - Train Accuracy:  0.913, Validation Accuracy:  0.942, Loss:  0.051
Epoch   3 Batch    5/538 - Train Accuracy:  0.919, Validation Accuracy:  0.940, Loss:  0.060
Epoch   3 Batch    6/538 - Train Accuracy:  0.931, Validation Accuracy:  0.922, Loss:  0.047
Epoch   3 Batch    7/538 - Train Accuracy:  0.938, Validation Accuracy:  0.927, Loss:  0.055
Epoch   3 Batch    8/538 - Train Accuracy:  0.922, Validation Accuracy:  0.929, Loss:  0.056
Epoch   3 Batch    9/538 - Train Accuracy:  0.910, Validation Accuracy:  0.924, Loss:  0.051
Epoch   3 Batch   10/538 - Train Accuracy:  0.918, Validation Accuracy:  0.923, Loss:  0.056
Epoch   3 Batch   11/538 - Train Accuracy:  0.929, Validation Accuracy:  0.927, Loss:  0.048
Epoch   3 Batch   12/538 - Train Accuracy:  0.919, Validation Accuracy:  0.935, Loss:  0.056
Epoch   3 Batch   13/538 - Train Accuracy:  0.949, Validation Accuracy:  0.938, Loss:  0.046
Epoch   3 Batch   14/538 - Train Accuracy:  0.926, Validation Accuracy:  0.936, Loss:  0.053
Epoch   3 Batch   15/538 - Train Accuracy:  0.938, Validation Accuracy:  0.938, Loss:  0.049
Epoch   3 Batch   16/538 - Train Accuracy:  0.910, Validation Accuracy:  0.940, Loss:  0.048
Epoch   3 Batch   17/538 - Train Accuracy:  0.924, Validation Accuracy:  0.941, Loss:  0.050
Epoch   3 Batch   18/538 - Train Accuracy:  0.924, Validation Accuracy:  0.941, Loss:  0.061
Epoch   3 Batch   19/538 - Train Accuracy:  0.919, Validation Accuracy:  0.935, Loss:  0.051
Epoch   3 Batch   20/538 - Train Accuracy:  0.928, Validation Accuracy:  0.931, Loss:  0.056
Epoch   3 Batch   21/538 - Train Accuracy:  0.948, Validation Accuracy:  0.932, Loss:  0.039
Epoch   3 Batch   22/538 - Train Accuracy:  0.905, Validation Accuracy:  0.930, Loss:  0.056
Epoch   3 Batch   23/538 - Train Accuracy:  0.916, Validation Accuracy:  0.927, Loss:  0.062
Epoch   3 Batch   24/538 - Train Accuracy:  0.937, Validation Accuracy:  0.931, Loss:  0.053
Epoch   3 Batch   25/538 - Train Accuracy:  0.923, Validation Accuracy:  0.936, Loss:  0.052
Epoch   3 Batch   26/538 - Train Accuracy:  0.914, Validation Accuracy:  0.938, Loss:  0.061
Epoch   3 Batch   27/538 - Train Accuracy:  0.946, Validation Accuracy:  0.943, Loss:  0.047
Epoch   3 Batch   28/538 - Train Accuracy:  0.924, Validation Accuracy:  0.944, Loss:  0.048
Epoch   3 Batch   29/538 - Train Accuracy:  0.934, Validation Accuracy:  0.944, Loss:  0.044
Epoch   3 Batch   30/538 - Train Accuracy:  0.920, Validation Accuracy:  0.938, Loss:  0.057
Epoch   3 Batch   31/538 - Train Accuracy:  0.950, Validation Accuracy:  0.926, Loss:  0.043
Epoch   3 Batch   32/538 - Train Accuracy:  0.934, Validation Accuracy:  0.926, Loss:  0.040
Epoch   3 Batch   33/538 - Train Accuracy:  0.932, Validation Accuracy:  0.931, Loss:  0.054
Epoch   3 Batch   34/538 - Train Accuracy:  0.918, Validation Accuracy:  0.934, Loss:  0.059
Epoch   3 Batch   35/538 - Train Accuracy:  0.925, Validation Accuracy:  0.935, Loss:  0.046
Epoch   3 Batch   36/538 - Train Accuracy:  0.929, Validation Accuracy:  0.942, Loss:  0.043
Epoch   3 Batch   37/538 - Train Accuracy:  0.929, Validation Accuracy:  0.941, Loss:  0.056
Epoch   3 Batch   38/538 - Train Accuracy:  0.923, Validation Accuracy:  0.937, Loss:  0.049
Epoch   3 Batch   39/538 - Train Accuracy:  0.933, Validation Accuracy:  0.936, Loss:  0.050
Epoch   3 Batch   40/538 - Train Accuracy:  0.929, Validation Accuracy:  0.940, Loss:  0.043
Epoch   3 Batch   41/538 - Train Accuracy:  0.939, Validation Accuracy:  0.938, Loss:  0.049
Epoch   3 Batch   42/538 - Train Accuracy:  0.926, Validation Accuracy:  0.933, Loss:  0.048
Epoch   3 Batch   43/538 - Train Accuracy:  0.912, Validation Accuracy:  0.936, Loss:  0.064
Epoch   3 Batch   44/538 - Train Accuracy:  0.912, Validation Accuracy:  0.931, Loss:  0.059
Epoch   3 Batch   45/538 - Train Accuracy:  0.927, Validation Accuracy:  0.925, Loss:  0.051
Epoch   3 Batch   46/538 - Train Accuracy:  0.944, Validation Accuracy:  0.930, Loss:  0.046
Epoch   3 Batch   47/538 - Train Accuracy:  0.931, Validation Accuracy:  0.927, Loss:  0.056
Epoch   3 Batch   48/538 - Train Accuracy:  0.920, Validation Accuracy:  0.929, Loss:  0.053
Epoch   3 Batch   49/538 - Train Accuracy:  0.932, Validation Accuracy:  0.938, Loss:  0.049
Epoch   3 Batch   50/538 - Train Accuracy:  0.918, Validation Accuracy:  0.942, Loss:  0.049
Epoch   3 Batch   51/538 - Train Accuracy:  0.936, Validation Accuracy:  0.936, Loss:  0.059
Epoch   3 Batch   52/538 - Train Accuracy:  0.940, Validation Accuracy:  0.924, Loss:  0.057
Epoch   3 Batch   53/538 - Train Accuracy:  0.912, Validation Accuracy:  0.924, Loss:  0.052
Epoch   3 Batch   54/538 - Train Accuracy:  0.926, Validation Accuracy:  0.926, Loss:  0.048
Epoch   3 Batch   55/538 - Train Accuracy:  0.919, Validation Accuracy:  0.930, Loss:  0.046
Epoch   3 Batch   56/538 - Train Accuracy:  0.930, Validation Accuracy:  0.931, Loss:  0.050
Epoch   3 Batch   57/538 - Train Accuracy:  0.910, Validation Accuracy:  0.931, Loss:  0.059
Epoch   3 Batch   58/538 - Train Accuracy:  0.922, Validation Accuracy:  0.919, Loss:  0.049
Epoch   3 Batch   59/538 - Train Accuracy:  0.909, Validation Accuracy:  0.923, Loss:  0.050
Epoch   3 Batch   60/538 - Train Accuracy:  0.930, Validation Accuracy:  0.924, Loss:  0.053
Epoch   3 Batch   61/538 - Train Accuracy:  0.936, Validation Accuracy:  0.927, Loss:  0.047
Epoch   3 Batch   62/538 - Train Accuracy:  0.935, Validation Accuracy:  0.928, Loss:  0.051
Epoch   3 Batch   63/538 - Train Accuracy:  0.949, Validation Accuracy:  0.924, Loss:  0.047
Epoch   3 Batch   64/538 - Train Accuracy:  0.928, Validation Accuracy:  0.926, Loss:  0.050
Epoch   3 Batch   65/538 - Train Accuracy:  0.917, Validation Accuracy:  0.917, Loss:  0.052
Epoch   3 Batch   66/538 - Train Accuracy:  0.942, Validation Accuracy:  0.911, Loss:  0.042
Epoch   3 Batch   67/538 - Train Accuracy:  0.947, Validation Accuracy:  0.926, Loss:  0.048
Epoch   3 Batch   68/538 - Train Accuracy:  0.929, Validation Accuracy:  0.932, Loss:  0.045
Epoch   3 Batch   69/538 - Train Accuracy:  0.922, Validation Accuracy:  0.931, Loss:  0.047
Epoch   3 Batch   70/538 - Train Accuracy:  0.921, Validation Accuracy:  0.925, Loss:  0.047
Epoch   3 Batch   71/538 - Train Accuracy:  0.914, Validation Accuracy:  0.934, Loss:  0.061
Epoch   3 Batch   72/538 - Train Accuracy:  0.935, Validation Accuracy:  0.939, Loss:  0.062
Epoch   3 Batch   73/538 - Train Accuracy:  0.922, Validation Accuracy:  0.931, Loss:  0.052
Epoch   3 Batch   74/538 - Train Accuracy:  0.929, Validation Accuracy:  0.926, Loss:  0.048
Epoch   3 Batch   75/538 - Train Accuracy:  0.931, Validation Accuracy:  0.922, Loss:  0.049
Epoch   3 Batch   76/538 - Train Accuracy:  0.930, Validation Accuracy:  0.922, Loss:  0.050
Epoch   3 Batch   77/538 - Train Accuracy:  0.924, Validation Accuracy:  0.920, Loss:  0.044
Epoch   3 Batch   78/538 - Train Accuracy:  0.933, Validation Accuracy:  0.927, Loss:  0.052
Epoch   3 Batch   79/538 - Train Accuracy:  0.927, Validation Accuracy:  0.935, Loss:  0.042
Epoch   3 Batch   80/538 - Train Accuracy:  0.924, Validation Accuracy:  0.932, Loss:  0.052
Epoch   3 Batch   81/538 - Train Accuracy:  0.912, Validation Accuracy:  0.934, Loss:  0.053
Epoch   3 Batch   82/538 - Train Accuracy:  0.904, Validation Accuracy:  0.927, Loss:  0.052
Epoch   3 Batch   83/538 - Train Accuracy:  0.923, Validation Accuracy:  0.924, Loss:  0.055
Epoch   3 Batch   84/538 - Train Accuracy:  0.917, Validation Accuracy:  0.930, Loss:  0.051
Epoch   3 Batch   85/538 - Train Accuracy:  0.952, Validation Accuracy:  0.937, Loss:  0.042
Epoch   3 Batch   86/538 - Train Accuracy:  0.934, Validation Accuracy:  0.940, Loss:  0.048
Epoch   3 Batch   87/538 - Train Accuracy:  0.934, Validation Accuracy:  0.932, Loss:  0.048
Epoch   3 Batch   88/538 - Train Accuracy:  0.938, Validation Accuracy:  0.939, Loss:  0.052
Epoch   3 Batch   89/538 - Train Accuracy:  0.946, Validation Accuracy:  0.936, Loss:  0.043
Epoch   3 Batch   90/538 - Train Accuracy:  0.921, Validation Accuracy:  0.941, Loss:  0.051
Epoch   3 Batch   91/538 - Train Accuracy:  0.945, Validation Accuracy:  0.944, Loss:  0.046
Epoch   3 Batch   92/538 - Train Accuracy:  0.935, Validation Accuracy:  0.943, Loss:  0.052
Epoch   3 Batch   93/538 - Train Accuracy:  0.932, Validation Accuracy:  0.935, Loss:  0.042
Epoch   3 Batch   94/538 - Train Accuracy:  0.947, Validation Accuracy:  0.929, Loss:  0.041
Epoch   3 Batch   95/538 - Train Accuracy:  0.926, Validation Accuracy:  0.931, Loss:  0.044
Epoch   3 Batch   96/538 - Train Accuracy:  0.940, Validation Accuracy:  0.939, Loss:  0.037
Epoch   3 Batch   97/538 - Train Accuracy:  0.931, Validation Accuracy:  0.937, Loss:  0.040
Epoch   3 Batch   98/538 - Train Accuracy:  0.937, Validation Accuracy:  0.933, Loss:  0.050
Epoch   3 Batch   99/538 - Train Accuracy:  0.933, Validation Accuracy:  0.933, Loss:  0.050
Epoch   3 Batch  100/538 - Train Accuracy:  0.944, Validation Accuracy:  0.933, Loss:  0.042
Epoch   3 Batch  101/538 - Train Accuracy:  0.916, Validation Accuracy:  0.931, Loss:  0.053
Epoch   3 Batch  102/538 - Train Accuracy:  0.926, Validation Accuracy:  0.933, Loss:  0.051
Epoch   3 Batch  103/538 - Train Accuracy:  0.925, Validation Accuracy:  0.939, Loss:  0.048
Epoch   3 Batch  104/538 - Train Accuracy:  0.930, Validation Accuracy:  0.937, Loss:  0.044
Epoch   3 Batch  105/538 - Train Accuracy:  0.936, Validation Accuracy:  0.934, Loss:  0.042
Epoch   3 Batch  106/538 - Train Accuracy:  0.922, Validation Accuracy:  0.923, Loss:  0.041
Epoch   3 Batch  107/538 - Train Accuracy:  0.904, Validation Accuracy:  0.921, Loss:  0.050
Epoch   3 Batch  108/538 - Train Accuracy:  0.926, Validation Accuracy:  0.917, Loss:  0.051
Epoch   3 Batch  109/538 - Train Accuracy:  0.935, Validation Accuracy:  0.918, Loss:  0.040
Epoch   3 Batch  110/538 - Train Accuracy:  0.930, Validation Accuracy:  0.922, Loss:  0.045
Epoch   3 Batch  111/538 - Train Accuracy:  0.931, Validation Accuracy:  0.937, Loss:  0.043
Epoch   3 Batch  112/538 - Train Accuracy:  0.932, Validation Accuracy:  0.935, Loss:  0.049
Epoch   3 Batch  113/538 - Train Accuracy:  0.921, Validation Accuracy:  0.931, Loss:  0.049
Epoch   3 Batch  114/538 - Train Accuracy:  0.939, Validation Accuracy:  0.934, Loss:  0.042
Epoch   3 Batch  115/538 - Train Accuracy:  0.932, Validation Accuracy:  0.940, Loss:  0.049
Epoch   3 Batch  116/538 - Train Accuracy:  0.929, Validation Accuracy:  0.954, Loss:  0.057
Epoch   3 Batch  117/538 - Train Accuracy:  0.927, Validation Accuracy:  0.950, Loss:  0.053
Epoch   3 Batch  118/538 - Train Accuracy:  0.937, Validation Accuracy:  0.946, Loss:  0.038
Epoch   3 Batch  119/538 - Train Accuracy:  0.949, Validation Accuracy:  0.950, Loss:  0.040
Epoch   3 Batch  120/538 - Train Accuracy:  0.946, Validation Accuracy:  0.953, Loss:  0.039
Epoch   3 Batch  121/538 - Train Accuracy:  0.939, Validation Accuracy:  0.945, Loss:  0.044
Epoch   3 Batch  122/538 - Train Accuracy:  0.926, Validation Accuracy:  0.941, Loss:  0.044
Epoch   3 Batch  123/538 - Train Accuracy:  0.916, Validation Accuracy:  0.939, Loss:  0.047
Epoch   3 Batch  124/538 - Train Accuracy:  0.939, Validation Accuracy:  0.937, Loss:  0.046
Epoch   3 Batch  125/538 - Train Accuracy:  0.924, Validation Accuracy:  0.936, Loss:  0.048
Epoch   3 Batch  126/538 - Train Accuracy:  0.925, Validation Accuracy:  0.931, Loss:  0.048
Epoch   3 Batch  127/538 - Train Accuracy:  0.922, Validation Accuracy:  0.936, Loss:  0.060
Epoch   3 Batch  128/538 - Train Accuracy:  0.932, Validation Accuracy:  0.941, Loss:  0.052
Epoch   3 Batch  129/538 - Train Accuracy:  0.940, Validation Accuracy:  0.935, Loss:  0.039
Epoch   3 Batch  130/538 - Train Accuracy:  0.933, Validation Accuracy:  0.937, Loss:  0.045
Epoch   3 Batch  131/538 - Train Accuracy:  0.945, Validation Accuracy:  0.946, Loss:  0.043
Epoch   3 Batch  132/538 - Train Accuracy:  0.922, Validation Accuracy:  0.948, Loss:  0.049
Epoch   3 Batch  133/538 - Train Accuracy:  0.934, Validation Accuracy:  0.945, Loss:  0.043
Epoch   3 Batch  134/538 - Train Accuracy:  0.911, Validation Accuracy:  0.936, Loss:  0.062
Epoch   3 Batch  135/538 - Train Accuracy:  0.933, Validation Accuracy:  0.917, Loss:  0.058
Epoch   3 Batch  136/538 - Train Accuracy:  0.928, Validation Accuracy:  0.907, Loss:  0.044
Epoch   3 Batch  137/538 - Train Accuracy:  0.925, Validation Accuracy:  0.911, Loss:  0.056
Epoch   3 Batch  138/538 - Train Accuracy:  0.931, Validation Accuracy:  0.919, Loss:  0.050
Epoch   3 Batch  139/538 - Train Accuracy:  0.932, Validation Accuracy:  0.932, Loss:  0.058
Epoch   3 Batch  140/538 - Train Accuracy:  0.904, Validation Accuracy:  0.942, Loss:  0.060
Epoch   3 Batch  141/538 - Train Accuracy:  0.929, Validation Accuracy:  0.929, Loss:  0.051
Epoch   3 Batch  142/538 - Train Accuracy:  0.938, Validation Accuracy:  0.914, Loss:  0.050
Epoch   3 Batch  143/538 - Train Accuracy:  0.933, Validation Accuracy:  0.917, Loss:  0.053
Epoch   3 Batch  144/538 - Train Accuracy:  0.929, Validation Accuracy:  0.917, Loss:  0.057
Epoch   3 Batch  145/538 - Train Accuracy:  0.907, Validation Accuracy:  0.930, Loss:  0.063
Epoch   3 Batch  146/538 - Train Accuracy:  0.936, Validation Accuracy:  0.910, Loss:  0.048
Epoch   3 Batch  147/538 - Train Accuracy:  0.932, Validation Accuracy:  0.907, Loss:  0.053
Epoch   3 Batch  148/538 - Train Accuracy:  0.913, Validation Accuracy:  0.909, Loss:  0.057
Epoch   3 Batch  149/538 - Train Accuracy:  0.927, Validation Accuracy:  0.914, Loss:  0.048
Epoch   3 Batch  150/538 - Train Accuracy:  0.939, Validation Accuracy:  0.931, Loss:  0.044
Epoch   3 Batch  151/538 - Train Accuracy:  0.931, Validation Accuracy:  0.923, Loss:  0.054
Epoch   3 Batch  152/538 - Train Accuracy:  0.923, Validation Accuracy:  0.917, Loss:  0.052
Epoch   3 Batch  153/538 - Train Accuracy:  0.906, Validation Accuracy:  0.911, Loss:  0.058
Epoch   3 Batch  154/538 - Train Accuracy:  0.938, Validation Accuracy:  0.924, Loss:  0.042
Epoch   3 Batch  155/538 - Train Accuracy:  0.922, Validation Accuracy:  0.923, Loss:  0.050
Epoch   3 Batch  156/538 - Train Accuracy:  0.943, Validation Accuracy:  0.932, Loss:  0.041
Epoch   3 Batch  157/538 - Train Accuracy:  0.940, Validation Accuracy:  0.932, Loss:  0.045
Epoch   3 Batch  158/538 - Train Accuracy:  0.933, Validation Accuracy:  0.934, Loss:  0.058
Epoch   3 Batch  159/538 - Train Accuracy:  0.948, Validation Accuracy:  0.914, Loss:  0.053
Epoch   3 Batch  160/538 - Train Accuracy:  0.908, Validation Accuracy:  0.905, Loss:  0.046
Epoch   3 Batch  161/538 - Train Accuracy:  0.936, Validation Accuracy:  0.917, Loss:  0.044
Epoch   3 Batch  162/538 - Train Accuracy:  0.921, Validation Accuracy:  0.918, Loss:  0.053
Epoch   3 Batch  163/538 - Train Accuracy:  0.929, Validation Accuracy:  0.929, Loss:  0.058
Epoch   3 Batch  164/538 - Train Accuracy:  0.920, Validation Accuracy:  0.936, Loss:  0.051
Epoch   3 Batch  165/538 - Train Accuracy:  0.921, Validation Accuracy:  0.933, Loss:  0.040
Epoch   3 Batch  166/538 - Train Accuracy:  0.958, Validation Accuracy:  0.928, Loss:  0.041
Epoch   3 Batch  167/538 - Train Accuracy:  0.926, Validation Accuracy:  0.933, Loss:  0.053
Epoch   3 Batch  168/538 - Train Accuracy:  0.906, Validation Accuracy:  0.928, Loss:  0.058
Epoch   3 Batch  169/538 - Train Accuracy:  0.938, Validation Accuracy:  0.930, Loss:  0.041
Epoch   3 Batch  170/538 - Train Accuracy:  0.917, Validation Accuracy:  0.932, Loss:  0.048
Epoch   3 Batch  171/538 - Train Accuracy:  0.928, Validation Accuracy:  0.933, Loss:  0.047
Epoch   3 Batch  172/538 - Train Accuracy:  0.927, Validation Accuracy:  0.927, Loss:  0.043
Epoch   3 Batch  173/538 - Train Accuracy:  0.948, Validation Accuracy:  0.923, Loss:  0.038
Epoch   3 Batch  174/538 - Train Accuracy:  0.930, Validation Accuracy:  0.910, Loss:  0.046
Epoch   3 Batch  175/538 - Train Accuracy:  0.937, Validation Accuracy:  0.915, Loss:  0.043
Epoch   3 Batch  176/538 - Train Accuracy:  0.922, Validation Accuracy:  0.923, Loss:  0.054
Epoch   3 Batch  177/538 - Train Accuracy:  0.943, Validation Accuracy:  0.932, Loss:  0.044
Epoch   3 Batch  178/538 - Train Accuracy:  0.921, Validation Accuracy:  0.929, Loss:  0.050
Epoch   3 Batch  179/538 - Train Accuracy:  0.940, Validation Accuracy:  0.932, Loss:  0.041
Epoch   3 Batch  180/538 - Train Accuracy:  0.935, Validation Accuracy:  0.927, Loss:  0.047
Epoch   3 Batch  181/538 - Train Accuracy:  0.915, Validation Accuracy:  0.931, Loss:  0.052
Epoch   3 Batch  182/538 - Train Accuracy:  0.940, Validation Accuracy:  0.937, Loss:  0.040
Epoch   3 Batch  183/538 - Train Accuracy:  0.954, Validation Accuracy:  0.942, Loss:  0.037
Epoch   3 Batch  184/538 - Train Accuracy:  0.950, Validation Accuracy:  0.945, Loss:  0.040
Epoch   3 Batch  185/538 - Train Accuracy:  0.953, Validation Accuracy:  0.947, Loss:  0.036
Epoch   3 Batch  186/538 - Train Accuracy:  0.931, Validation Accuracy:  0.942, Loss:  0.043
Epoch   3 Batch  187/538 - Train Accuracy:  0.930, Validation Accuracy:  0.928, Loss:  0.047
Epoch   3 Batch  188/538 - Train Accuracy:  0.938, Validation Accuracy:  0.926, Loss:  0.039
Epoch   3 Batch  189/538 - Train Accuracy:  0.947, Validation Accuracy:  0.931, Loss:  0.048
Epoch   3 Batch  190/538 - Train Accuracy:  0.929, Validation Accuracy:  0.931, Loss:  0.059
Epoch   3 Batch  191/538 - Train Accuracy:  0.954, Validation Accuracy:  0.939, Loss:  0.042
Epoch   3 Batch  192/538 - Train Accuracy:  0.938, Validation Accuracy:  0.941, Loss:  0.039
Epoch   3 Batch  193/538 - Train Accuracy:  0.924, Validation Accuracy:  0.944, Loss:  0.045
Epoch   3 Batch  194/538 - Train Accuracy:  0.918, Validation Accuracy:  0.938, Loss:  0.051
Epoch   3 Batch  195/538 - Train Accuracy:  0.935, Validation Accuracy:  0.937, Loss:  0.051
Epoch   3 Batch  196/538 - Train Accuracy:  0.933, Validation Accuracy:  0.934, Loss:  0.043
Epoch   3 Batch  197/538 - Train Accuracy:  0.946, Validation Accuracy:  0.934, Loss:  0.044
Epoch   3 Batch  198/538 - Train Accuracy:  0.943, Validation Accuracy:  0.930, Loss:  0.044
Epoch   3 Batch  199/538 - Train Accuracy:  0.920, Validation Accuracy:  0.938, Loss:  0.048
Epoch   3 Batch  200/538 - Train Accuracy:  0.936, Validation Accuracy:  0.936, Loss:  0.040
Epoch   3 Batch  201/538 - Train Accuracy:  0.934, Validation Accuracy:  0.939, Loss:  0.052
Epoch   3 Batch  202/538 - Train Accuracy:  0.940, Validation Accuracy:  0.930, Loss:  0.044
Epoch   3 Batch  203/538 - Train Accuracy:  0.927, Validation Accuracy:  0.929, Loss:  0.051
Epoch   3 Batch  204/538 - Train Accuracy:  0.923, Validation Accuracy:  0.931, Loss:  0.054
Epoch   3 Batch  205/538 - Train Accuracy:  0.937, Validation Accuracy:  0.939, Loss:  0.046
Epoch   3 Batch  206/538 - Train Accuracy:  0.923, Validation Accuracy:  0.946, Loss:  0.043
Epoch   3 Batch  207/538 - Train Accuracy:  0.943, Validation Accuracy:  0.943, Loss:  0.043
Epoch   3 Batch  208/538 - Train Accuracy:  0.933, Validation Accuracy:  0.941, Loss:  0.055
Epoch   3 Batch  209/538 - Train Accuracy:  0.950, Validation Accuracy:  0.932, Loss:  0.042
Epoch   3 Batch  210/538 - Train Accuracy:  0.931, Validation Accuracy:  0.927, Loss:  0.044
Epoch   3 Batch  211/538 - Train Accuracy:  0.931, Validation Accuracy:  0.934, Loss:  0.047
Epoch   3 Batch  212/538 - Train Accuracy:  0.936, Validation Accuracy:  0.936, Loss:  0.042
Epoch   3 Batch  213/538 - Train Accuracy:  0.940, Validation Accuracy:  0.946, Loss:  0.042
Epoch   3 Batch  214/538 - Train Accuracy:  0.936, Validation Accuracy:  0.950, Loss:  0.039
Epoch   3 Batch  215/538 - Train Accuracy:  0.943, Validation Accuracy:  0.949, Loss:  0.043
Epoch   3 Batch  216/538 - Train Accuracy:  0.942, Validation Accuracy:  0.939, Loss:  0.047
Epoch   3 Batch  217/538 - Train Accuracy:  0.941, Validation Accuracy:  0.932, Loss:  0.043
Epoch   3 Batch  218/538 - Train Accuracy:  0.938, Validation Accuracy:  0.930, Loss:  0.039
Epoch   3 Batch  219/538 - Train Accuracy:  0.927, Validation Accuracy:  0.932, Loss:  0.051
Epoch   3 Batch  220/538 - Train Accuracy:  0.917, Validation Accuracy:  0.928, Loss:  0.045
Epoch   3 Batch  221/538 - Train Accuracy:  0.943, Validation Accuracy:  0.933, Loss:  0.042
Epoch   3 Batch  222/538 - Train Accuracy:  0.916, Validation Accuracy:  0.930, Loss:  0.040
Epoch   3 Batch  223/538 - Train Accuracy:  0.928, Validation Accuracy:  0.925, Loss:  0.052
Epoch   3 Batch  224/538 - Train Accuracy:  0.931, Validation Accuracy:  0.922, Loss:  0.045
Epoch   3 Batch  225/538 - Train Accuracy:  0.942, Validation Accuracy:  0.922, Loss:  0.045
Epoch   3 Batch  226/538 - Train Accuracy:  0.932, Validation Accuracy:  0.930, Loss:  0.043
Epoch   3 Batch  227/538 - Train Accuracy:  0.945, Validation Accuracy:  0.943, Loss:  0.046
Epoch   3 Batch  228/538 - Train Accuracy:  0.924, Validation Accuracy:  0.942, Loss:  0.042
Epoch   3 Batch  229/538 - Train Accuracy:  0.935, Validation Accuracy:  0.942, Loss:  0.047
Epoch   3 Batch  230/538 - Train Accuracy:  0.927, Validation Accuracy:  0.939, Loss:  0.044
Epoch   3 Batch  231/538 - Train Accuracy:  0.937, Validation Accuracy:  0.931, Loss:  0.044
Epoch   3 Batch  232/538 - Train Accuracy:  0.928, Validation Accuracy:  0.928, Loss:  0.043
Epoch   3 Batch  233/538 - Train Accuracy:  0.940, Validation Accuracy:  0.927, Loss:  0.048
Epoch   3 Batch  234/538 - Train Accuracy:  0.937, Validation Accuracy:  0.925, Loss:  0.042
Epoch   3 Batch  235/538 - Train Accuracy:  0.942, Validation Accuracy:  0.924, Loss:  0.036
Epoch   3 Batch  236/538 - Train Accuracy:  0.921, Validation Accuracy:  0.933, Loss:  0.044
Epoch   3 Batch  237/538 - Train Accuracy:  0.942, Validation Accuracy:  0.937, Loss:  0.036
Epoch   3 Batch  238/538 - Train Accuracy:  0.962, Validation Accuracy:  0.938, Loss:  0.042
Epoch   3 Batch  239/538 - Train Accuracy:  0.928, Validation Accuracy:  0.940, Loss:  0.044
Epoch   3 Batch  240/538 - Train Accuracy:  0.938, Validation Accuracy:  0.943, Loss:  0.046
Epoch   3 Batch  241/538 - Train Accuracy:  0.930, Validation Accuracy:  0.943, Loss:  0.048
Epoch   3 Batch  242/538 - Train Accuracy:  0.941, Validation Accuracy:  0.942, Loss:  0.044
Epoch   3 Batch  243/538 - Train Accuracy:  0.943, Validation Accuracy:  0.941, Loss:  0.039
Epoch   3 Batch  244/538 - Train Accuracy:  0.922, Validation Accuracy:  0.937, Loss:  0.039
Epoch   3 Batch  245/538 - Train Accuracy:  0.931, Validation Accuracy:  0.923, Loss:  0.052
Epoch   3 Batch  246/538 - Train Accuracy:  0.947, Validation Accuracy:  0.915, Loss:  0.036
Epoch   3 Batch  247/538 - Train Accuracy:  0.936, Validation Accuracy:  0.915, Loss:  0.038
Epoch   3 Batch  248/538 - Train Accuracy:  0.933, Validation Accuracy:  0.922, Loss:  0.043
Epoch   3 Batch  249/538 - Train Accuracy:  0.925, Validation Accuracy:  0.930, Loss:  0.037
Epoch   3 Batch  250/538 - Train Accuracy:  0.944, Validation Accuracy:  0.932, Loss:  0.042
Epoch   3 Batch  251/538 - Train Accuracy:  0.938, Validation Accuracy:  0.938, Loss:  0.038
Epoch   3 Batch  252/538 - Train Accuracy:  0.937, Validation Accuracy:  0.940, Loss:  0.042
Epoch   3 Batch  253/538 - Train Accuracy:  0.909, Validation Accuracy:  0.945, Loss:  0.043
Epoch   3 Batch  254/538 - Train Accuracy:  0.923, Validation Accuracy:  0.946, Loss:  0.048
Epoch   3 Batch  255/538 - Train Accuracy:  0.950, Validation Accuracy:  0.951, Loss:  0.045
Epoch   3 Batch  256/538 - Train Accuracy:  0.931, Validation Accuracy:  0.952, Loss:  0.044
Epoch   3 Batch  257/538 - Train Accuracy:  0.942, Validation Accuracy:  0.940, Loss:  0.045
Epoch   3 Batch  258/538 - Train Accuracy:  0.938, Validation Accuracy:  0.941, Loss:  0.048
Epoch   3 Batch  259/538 - Train Accuracy:  0.951, Validation Accuracy:  0.936, Loss:  0.036
Epoch   3 Batch  260/538 - Train Accuracy:  0.907, Validation Accuracy:  0.935, Loss:  0.050
Epoch   3 Batch  261/538 - Train Accuracy:  0.940, Validation Accuracy:  0.930, Loss:  0.050
Epoch   3 Batch  262/538 - Train Accuracy:  0.941, Validation Accuracy:  0.936, Loss:  0.043
Epoch   3 Batch  263/538 - Train Accuracy:  0.925, Validation Accuracy:  0.943, Loss:  0.043
Epoch   3 Batch  264/538 - Train Accuracy:  0.924, Validation Accuracy:  0.944, Loss:  0.044
Epoch   3 Batch  265/538 - Train Accuracy:  0.920, Validation Accuracy:  0.944, Loss:  0.055
Epoch   3 Batch  266/538 - Train Accuracy:  0.925, Validation Accuracy:  0.944, Loss:  0.041
Epoch   3 Batch  267/538 - Train Accuracy:  0.926, Validation Accuracy:  0.945, Loss:  0.046
Epoch   3 Batch  268/538 - Train Accuracy:  0.942, Validation Accuracy:  0.942, Loss:  0.034
Epoch   3 Batch  269/538 - Train Accuracy:  0.934, Validation Accuracy:  0.930, Loss:  0.045
Epoch   3 Batch  270/538 - Train Accuracy:  0.948, Validation Accuracy:  0.931, Loss:  0.038
Epoch   3 Batch  271/538 - Train Accuracy:  0.942, Validation Accuracy:  0.934, Loss:  0.031
Epoch   3 Batch  272/538 - Train Accuracy:  0.925, Validation Accuracy:  0.933, Loss:  0.049
Epoch   3 Batch  273/538 - Train Accuracy:  0.942, Validation Accuracy:  0.944, Loss:  0.047
Epoch   3 Batch  274/538 - Train Accuracy:  0.905, Validation Accuracy:  0.941, Loss:  0.053
Epoch   3 Batch  275/538 - Train Accuracy:  0.938, Validation Accuracy:  0.941, Loss:  0.053
Epoch   3 Batch  276/538 - Train Accuracy:  0.925, Validation Accuracy:  0.938, Loss:  0.052
Epoch   3 Batch  277/538 - Train Accuracy:  0.934, Validation Accuracy:  0.937, Loss:  0.035
Epoch   3 Batch  278/538 - Train Accuracy:  0.929, Validation Accuracy:  0.936, Loss:  0.046
Epoch   3 Batch  279/538 - Train Accuracy:  0.929, Validation Accuracy:  0.941, Loss:  0.040
Epoch   3 Batch  280/538 - Train Accuracy:  0.939, Validation Accuracy:  0.942, Loss:  0.039
Epoch   3 Batch  281/538 - Train Accuracy:  0.928, Validation Accuracy:  0.945, Loss:  0.048
Epoch   3 Batch  282/538 - Train Accuracy:  0.935, Validation Accuracy:  0.945, Loss:  0.052
Epoch   3 Batch  283/538 - Train Accuracy:  0.938, Validation Accuracy:  0.944, Loss:  0.047
Epoch   3 Batch  284/538 - Train Accuracy:  0.937, Validation Accuracy:  0.946, Loss:  0.051
Epoch   3 Batch  285/538 - Train Accuracy:  0.935, Validation Accuracy:  0.946, Loss:  0.040
Epoch   3 Batch  286/538 - Train Accuracy:  0.925, Validation Accuracy:  0.949, Loss:  0.047
Epoch   3 Batch  287/538 - Train Accuracy:  0.952, Validation Accuracy:  0.949, Loss:  0.032
Epoch   3 Batch  288/538 - Train Accuracy:  0.949, Validation Accuracy:  0.942, Loss:  0.038
Epoch   3 Batch  289/538 - Train Accuracy:  0.942, Validation Accuracy:  0.938, Loss:  0.035
Epoch   3 Batch  290/538 - Train Accuracy:  0.955, Validation Accuracy:  0.928, Loss:  0.038
Epoch   3 Batch  291/538 - Train Accuracy:  0.938, Validation Accuracy:  0.936, Loss:  0.047
Epoch   3 Batch  292/538 - Train Accuracy:  0.951, Validation Accuracy:  0.937, Loss:  0.038
Epoch   3 Batch  293/538 - Train Accuracy:  0.926, Validation Accuracy:  0.938, Loss:  0.044
Epoch   3 Batch  294/538 - Train Accuracy:  0.934, Validation Accuracy:  0.945, Loss:  0.047
Epoch   3 Batch  295/538 - Train Accuracy:  0.941, Validation Accuracy:  0.942, Loss:  0.045
Epoch   3 Batch  296/538 - Train Accuracy:  0.929, Validation Accuracy:  0.944, Loss:  0.060
Epoch   3 Batch  297/538 - Train Accuracy:  0.944, Validation Accuracy:  0.940, Loss:  0.041
Epoch   3 Batch  298/538 - Train Accuracy:  0.932, Validation Accuracy:  0.928, Loss:  0.042
Epoch   3 Batch  299/538 - Train Accuracy:  0.928, Validation Accuracy:  0.933, Loss:  0.051
Epoch   3 Batch  300/538 - Train Accuracy:  0.933, Validation Accuracy:  0.942, Loss:  0.045
Epoch   3 Batch  301/538 - Train Accuracy:  0.913, Validation Accuracy:  0.956, Loss:  0.048
Epoch   3 Batch  302/538 - Train Accuracy:  0.946, Validation Accuracy:  0.955, Loss:  0.042
Epoch   3 Batch  303/538 - Train Accuracy:  0.949, Validation Accuracy:  0.949, Loss:  0.043
Epoch   3 Batch  304/538 - Train Accuracy:  0.944, Validation Accuracy:  0.939, Loss:  0.047
Epoch   3 Batch  305/538 - Train Accuracy:  0.944, Validation Accuracy:  0.928, Loss:  0.040
Epoch   3 Batch  306/538 - Train Accuracy:  0.924, Validation Accuracy:  0.915, Loss:  0.048
Epoch   3 Batch  307/538 - Train Accuracy:  0.952, Validation Accuracy:  0.938, Loss:  0.043
Epoch   3 Batch  308/538 - Train Accuracy:  0.935, Validation Accuracy:  0.946, Loss:  0.044
Epoch   3 Batch  309/538 - Train Accuracy:  0.928, Validation Accuracy:  0.949, Loss:  0.039
Epoch   3 Batch  310/538 - Train Accuracy:  0.950, Validation Accuracy:  0.953, Loss:  0.045
Epoch   3 Batch  311/538 - Train Accuracy:  0.920, Validation Accuracy:  0.952, Loss:  0.045
Epoch   3 Batch  312/538 - Train Accuracy:  0.937, Validation Accuracy:  0.944, Loss:  0.039
Epoch   3 Batch  313/538 - Train Accuracy:  0.936, Validation Accuracy:  0.939, Loss:  0.043
Epoch   3 Batch  314/538 - Train Accuracy:  0.939, Validation Accuracy:  0.949, Loss:  0.045
Epoch   3 Batch  315/538 - Train Accuracy:  0.930, Validation Accuracy:  0.951, Loss:  0.039
Epoch   3 Batch  316/538 - Train Accuracy:  0.938, Validation Accuracy:  0.951, Loss:  0.034
Epoch   3 Batch  317/538 - Train Accuracy:  0.938, Validation Accuracy:  0.947, Loss:  0.042
Epoch   3 Batch  318/538 - Train Accuracy:  0.925, Validation Accuracy:  0.945, Loss:  0.037
Epoch   3 Batch  319/538 - Train Accuracy:  0.926, Validation Accuracy:  0.929, Loss:  0.047
Epoch   3 Batch  320/538 - Train Accuracy:  0.935, Validation Accuracy:  0.933, Loss:  0.039
Epoch   3 Batch  321/538 - Train Accuracy:  0.929, Validation Accuracy:  0.929, Loss:  0.036
Epoch   3 Batch  322/538 - Train Accuracy:  0.945, Validation Accuracy:  0.936, Loss:  0.043
Epoch   3 Batch  323/538 - Train Accuracy:  0.941, Validation Accuracy:  0.946, Loss:  0.037
Epoch   3 Batch  324/538 - Train Accuracy:  0.940, Validation Accuracy:  0.944, Loss:  0.039
Epoch   3 Batch  325/538 - Train Accuracy:  0.946, Validation Accuracy:  0.951, Loss:  0.040
Epoch   3 Batch  326/538 - Train Accuracy:  0.946, Validation Accuracy:  0.951, Loss:  0.039
Epoch   3 Batch  327/538 - Train Accuracy:  0.936, Validation Accuracy:  0.952, Loss:  0.049
Epoch   3 Batch  328/538 - Train Accuracy:  0.954, Validation Accuracy:  0.950, Loss:  0.031
Epoch   3 Batch  329/538 - Train Accuracy:  0.940, Validation Accuracy:  0.955, Loss:  0.040
Epoch   3 Batch  330/538 - Train Accuracy:  0.950, Validation Accuracy:  0.958, Loss:  0.037
Epoch   3 Batch  331/538 - Train Accuracy:  0.929, Validation Accuracy:  0.959, Loss:  0.042
Epoch   3 Batch  332/538 - Train Accuracy:  0.956, Validation Accuracy:  0.955, Loss:  0.038
Epoch   3 Batch  333/538 - Train Accuracy:  0.945, Validation Accuracy:  0.951, Loss:  0.042
Epoch   3 Batch  334/538 - Train Accuracy:  0.943, Validation Accuracy:  0.949, Loss:  0.036
Epoch   3 Batch  335/538 - Train Accuracy:  0.937, Validation Accuracy:  0.949, Loss:  0.038
Epoch   3 Batch  336/538 - Train Accuracy:  0.938, Validation Accuracy:  0.948, Loss:  0.039
Epoch   3 Batch  337/538 - Train Accuracy:  0.941, Validation Accuracy:  0.951, Loss:  0.043
Epoch   3 Batch  338/538 - Train Accuracy:  0.937, Validation Accuracy:  0.942, Loss:  0.038
Epoch   3 Batch  339/538 - Train Accuracy:  0.943, Validation Accuracy:  0.941, Loss:  0.039
Epoch   3 Batch  340/538 - Train Accuracy:  0.926, Validation Accuracy:  0.943, Loss:  0.043
Epoch   3 Batch  341/538 - Train Accuracy:  0.939, Validation Accuracy:  0.950, Loss:  0.040
Epoch   3 Batch  342/538 - Train Accuracy:  0.945, Validation Accuracy:  0.952, Loss:  0.038
Epoch   3 Batch  343/538 - Train Accuracy:  0.952, Validation Accuracy:  0.951, Loss:  0.039
Epoch   3 Batch  344/538 - Train Accuracy:  0.950, Validation Accuracy:  0.953, Loss:  0.039
Epoch   3 Batch  345/538 - Train Accuracy:  0.947, Validation Accuracy:  0.941, Loss:  0.041
Epoch   3 Batch  346/538 - Train Accuracy:  0.921, Validation Accuracy:  0.929, Loss:  0.051
Epoch   3 Batch  347/538 - Train Accuracy:  0.937, Validation Accuracy:  0.931, Loss:  0.037
Epoch   3 Batch  348/538 - Train Accuracy:  0.930, Validation Accuracy:  0.937, Loss:  0.034
Epoch   3 Batch  349/538 - Train Accuracy:  0.949, Validation Accuracy:  0.941, Loss:  0.036
Epoch   3 Batch  350/538 - Train Accuracy:  0.946, Validation Accuracy:  0.946, Loss:  0.043
Epoch   3 Batch  351/538 - Train Accuracy:  0.935, Validation Accuracy:  0.948, Loss:  0.049
Epoch   3 Batch  352/538 - Train Accuracy:  0.911, Validation Accuracy:  0.941, Loss:  0.057
Epoch   3 Batch  353/538 - Train Accuracy:  0.939, Validation Accuracy:  0.940, Loss:  0.045
Epoch   3 Batch  354/538 - Train Accuracy:  0.933, Validation Accuracy:  0.934, Loss:  0.042
Epoch   3 Batch  355/538 - Train Accuracy:  0.938, Validation Accuracy:  0.945, Loss:  0.039
Epoch   3 Batch  356/538 - Train Accuracy:  0.934, Validation Accuracy:  0.950, Loss:  0.034
Epoch   3 Batch  357/538 - Train Accuracy:  0.939, Validation Accuracy:  0.952, Loss:  0.040
Epoch   3 Batch  358/538 - Train Accuracy:  0.941, Validation Accuracy:  0.954, Loss:  0.034
Epoch   3 Batch  359/538 - Train Accuracy:  0.933, Validation Accuracy:  0.948, Loss:  0.045
Epoch   3 Batch  360/538 - Train Accuracy:  0.945, Validation Accuracy:  0.952, Loss:  0.040
Epoch   3 Batch  361/538 - Train Accuracy:  0.942, Validation Accuracy:  0.943, Loss:  0.043
Epoch   3 Batch  362/538 - Train Accuracy:  0.946, Validation Accuracy:  0.944, Loss:  0.034
Epoch   3 Batch  363/538 - Train Accuracy:  0.939, Validation Accuracy:  0.949, Loss:  0.040
Epoch   3 Batch  364/538 - Train Accuracy:  0.931, Validation Accuracy:  0.953, Loss:  0.050
Epoch   3 Batch  365/538 - Train Accuracy:  0.928, Validation Accuracy:  0.952, Loss:  0.042
Epoch   3 Batch  366/538 - Train Accuracy:  0.949, Validation Accuracy:  0.948, Loss:  0.039
Epoch   3 Batch  367/538 - Train Accuracy:  0.946, Validation Accuracy:  0.942, Loss:  0.031
Epoch   3 Batch  368/538 - Train Accuracy:  0.938, Validation Accuracy:  0.944, Loss:  0.035
Epoch   3 Batch  369/538 - Train Accuracy:  0.943, Validation Accuracy:  0.945, Loss:  0.035
Epoch   3 Batch  370/538 - Train Accuracy:  0.943, Validation Accuracy:  0.949, Loss:  0.043
Epoch   3 Batch  371/538 - Train Accuracy:  0.942, Validation Accuracy:  0.942, Loss:  0.039
Epoch   3 Batch  372/538 - Train Accuracy:  0.946, Validation Accuracy:  0.932, Loss:  0.037
Epoch   3 Batch  373/538 - Train Accuracy:  0.937, Validation Accuracy:  0.932, Loss:  0.033
Epoch   3 Batch  374/538 - Train Accuracy:  0.947, Validation Accuracy:  0.941, Loss:  0.038
Epoch   3 Batch  375/538 - Train Accuracy:  0.948, Validation Accuracy:  0.949, Loss:  0.037
Epoch   3 Batch  376/538 - Train Accuracy:  0.933, Validation Accuracy:  0.947, Loss:  0.038
Epoch   3 Batch  377/538 - Train Accuracy:  0.946, Validation Accuracy:  0.949, Loss:  0.038
Epoch   3 Batch  378/538 - Train Accuracy:  0.941, Validation Accuracy:  0.939, Loss:  0.036
Epoch   3 Batch  379/538 - Train Accuracy:  0.936, Validation Accuracy:  0.934, Loss:  0.039
Epoch   3 Batch  380/538 - Train Accuracy:  0.949, Validation Accuracy:  0.931, Loss:  0.036
Epoch   3 Batch  381/538 - Train Accuracy:  0.947, Validation Accuracy:  0.934, Loss:  0.039
Epoch   3 Batch  382/538 - Train Accuracy:  0.922, Validation Accuracy:  0.940, Loss:  0.045
Epoch   3 Batch  383/538 - Train Accuracy:  0.933, Validation Accuracy:  0.949, Loss:  0.044
Epoch   3 Batch  384/538 - Train Accuracy:  0.932, Validation Accuracy:  0.950, Loss:  0.039
Epoch   3 Batch  385/538 - Train Accuracy:  0.953, Validation Accuracy:  0.955, Loss:  0.041
Epoch   3 Batch  386/538 - Train Accuracy:  0.947, Validation Accuracy:  0.947, Loss:  0.041
Epoch   3 Batch  387/538 - Train Accuracy:  0.941, Validation Accuracy:  0.931, Loss:  0.037
Epoch   3 Batch  388/538 - Train Accuracy:  0.940, Validation Accuracy:  0.934, Loss:  0.041
Epoch   3 Batch  389/538 - Train Accuracy:  0.924, Validation Accuracy:  0.949, Loss:  0.048
Epoch   3 Batch  390/538 - Train Accuracy:  0.952, Validation Accuracy:  0.953, Loss:  0.035
Epoch   3 Batch  391/538 - Train Accuracy:  0.938, Validation Accuracy:  0.952, Loss:  0.034
Epoch   3 Batch  392/538 - Train Accuracy:  0.928, Validation Accuracy:  0.950, Loss:  0.036
Epoch   3 Batch  393/538 - Train Accuracy:  0.953, Validation Accuracy:  0.957, Loss:  0.039
Epoch   3 Batch  394/538 - Train Accuracy:  0.913, Validation Accuracy:  0.944, Loss:  0.042
Epoch   3 Batch  395/538 - Train Accuracy:  0.932, Validation Accuracy:  0.947, Loss:  0.048
Epoch   3 Batch  396/538 - Train Accuracy:  0.945, Validation Accuracy:  0.956, Loss:  0.033
Epoch   3 Batch  397/538 - Train Accuracy:  0.940, Validation Accuracy:  0.950, Loss:  0.042
Epoch   3 Batch  398/538 - Train Accuracy:  0.945, Validation Accuracy:  0.944, Loss:  0.036
Epoch   3 Batch  399/538 - Train Accuracy:  0.925, Validation Accuracy:  0.946, Loss:  0.045
Epoch   3 Batch  400/538 - Train Accuracy:  0.956, Validation Accuracy:  0.949, Loss:  0.042
Epoch   3 Batch  401/538 - Train Accuracy:  0.954, Validation Accuracy:  0.955, Loss:  0.035
Epoch   3 Batch  402/538 - Train Accuracy:  0.959, Validation Accuracy:  0.946, Loss:  0.037
Epoch   3 Batch  403/538 - Train Accuracy:  0.938, Validation Accuracy:  0.941, Loss:  0.042
Epoch   3 Batch  404/538 - Train Accuracy:  0.925, Validation Accuracy:  0.945, Loss:  0.044
Epoch   3 Batch  405/538 - Train Accuracy:  0.948, Validation Accuracy:  0.943, Loss:  0.032
Epoch   3 Batch  406/538 - Train Accuracy:  0.939, Validation Accuracy:  0.943, Loss:  0.041
Epoch   3 Batch  407/538 - Train Accuracy:  0.963, Validation Accuracy:  0.946, Loss:  0.040
Epoch   3 Batch  408/538 - Train Accuracy:  0.936, Validation Accuracy:  0.944, Loss:  0.043
Epoch   3 Batch  409/538 - Train Accuracy:  0.930, Validation Accuracy:  0.940, Loss:  0.042
Epoch   3 Batch  410/538 - Train Accuracy:  0.940, Validation Accuracy:  0.930, Loss:  0.042
Epoch   3 Batch  411/538 - Train Accuracy:  0.947, Validation Accuracy:  0.931, Loss:  0.042
Epoch   3 Batch  412/538 - Train Accuracy:  0.938, Validation Accuracy:  0.938, Loss:  0.035
Epoch   3 Batch  413/538 - Train Accuracy:  0.945, Validation Accuracy:  0.952, Loss:  0.035
Epoch   3 Batch  414/538 - Train Accuracy:  0.915, Validation Accuracy:  0.939, Loss:  0.050
Epoch   3 Batch  415/538 - Train Accuracy:  0.919, Validation Accuracy:  0.939, Loss:  0.044
Epoch   3 Batch  416/538 - Train Accuracy:  0.937, Validation Accuracy:  0.946, Loss:  0.043
Epoch   3 Batch  417/538 - Train Accuracy:  0.950, Validation Accuracy:  0.943, Loss:  0.036
Epoch   3 Batch  418/538 - Train Accuracy:  0.942, Validation Accuracy:  0.938, Loss:  0.045
Epoch   3 Batch  419/538 - Train Accuracy:  0.950, Validation Accuracy:  0.930, Loss:  0.032
Epoch   3 Batch  420/538 - Train Accuracy:  0.942, Validation Accuracy:  0.935, Loss:  0.040
Epoch   3 Batch  421/538 - Train Accuracy:  0.949, Validation Accuracy:  0.947, Loss:  0.039
Epoch   3 Batch  422/538 - Train Accuracy:  0.945, Validation Accuracy:  0.949, Loss:  0.037
Epoch   3 Batch  423/538 - Train Accuracy:  0.941, Validation Accuracy:  0.956, Loss:  0.042
Epoch   3 Batch  424/538 - Train Accuracy:  0.928, Validation Accuracy:  0.954, Loss:  0.044
Epoch   3 Batch  425/538 - Train Accuracy:  0.928, Validation Accuracy:  0.947, Loss:  0.051
Epoch   3 Batch  426/538 - Train Accuracy:  0.940, Validation Accuracy:  0.944, Loss:  0.039
Epoch   3 Batch  427/538 - Train Accuracy:  0.929, Validation Accuracy:  0.944, Loss:  0.045
Epoch   3 Batch  428/538 - Train Accuracy:  0.936, Validation Accuracy:  0.939, Loss:  0.036
Epoch   3 Batch  429/538 - Train Accuracy:  0.943, Validation Accuracy:  0.939, Loss:  0.040
Epoch   3 Batch  430/538 - Train Accuracy:  0.934, Validation Accuracy:  0.951, Loss:  0.036
Epoch   3 Batch  431/538 - Train Accuracy:  0.921, Validation Accuracy:  0.951, Loss:  0.036
Epoch   3 Batch  432/538 - Train Accuracy:  0.921, Validation Accuracy:  0.949, Loss:  0.041
Epoch   3 Batch  433/538 - Train Accuracy:  0.924, Validation Accuracy:  0.947, Loss:  0.063
Epoch   3 Batch  434/538 - Train Accuracy:  0.928, Validation Accuracy:  0.941, Loss:  0.037
Epoch   3 Batch  435/538 - Train Accuracy:  0.938, Validation Accuracy:  0.949, Loss:  0.039
Epoch   3 Batch  436/538 - Train Accuracy:  0.920, Validation Accuracy:  0.953, Loss:  0.041
Epoch   3 Batch  437/538 - Train Accuracy:  0.951, Validation Accuracy:  0.956, Loss:  0.039
Epoch   3 Batch  438/538 - Train Accuracy:  0.941, Validation Accuracy:  0.960, Loss:  0.036
Epoch   3 Batch  439/538 - Train Accuracy:  0.959, Validation Accuracy:  0.962, Loss:  0.038
Epoch   3 Batch  440/538 - Train Accuracy:  0.943, Validation Accuracy:  0.960, Loss:  0.040
Epoch   3 Batch  441/538 - Train Accuracy:  0.925, Validation Accuracy:  0.956, Loss:  0.049
Epoch   3 Batch  442/538 - Train Accuracy:  0.950, Validation Accuracy:  0.952, Loss:  0.032
Epoch   3 Batch  443/538 - Train Accuracy:  0.931, Validation Accuracy:  0.950, Loss:  0.040
Epoch   3 Batch  444/538 - Train Accuracy:  0.945, Validation Accuracy:  0.949, Loss:  0.037
Epoch   3 Batch  445/538 - Train Accuracy:  0.952, Validation Accuracy:  0.949, Loss:  0.033
Epoch   3 Batch  446/538 - Train Accuracy:  0.950, Validation Accuracy:  0.947, Loss:  0.037
Epoch   3 Batch  447/538 - Train Accuracy:  0.929, Validation Accuracy:  0.952, Loss:  0.038
Epoch   3 Batch  448/538 - Train Accuracy:  0.937, Validation Accuracy:  0.950, Loss:  0.035
Epoch   3 Batch  449/538 - Train Accuracy:  0.950, Validation Accuracy:  0.954, Loss:  0.043
Epoch   3 Batch  450/538 - Train Accuracy:  0.931, Validation Accuracy:  0.958, Loss:  0.050
Epoch   3 Batch  451/538 - Train Accuracy:  0.926, Validation Accuracy:  0.958, Loss:  0.036
Epoch   3 Batch  452/538 - Train Accuracy:  0.949, Validation Accuracy:  0.951, Loss:  0.038
Epoch   3 Batch  453/538 - Train Accuracy:  0.948, Validation Accuracy:  0.946, Loss:  0.042
Epoch   3 Batch  454/538 - Train Accuracy:  0.935, Validation Accuracy:  0.947, Loss:  0.041
Epoch   3 Batch  455/538 - Train Accuracy:  0.953, Validation Accuracy:  0.945, Loss:  0.041
Epoch   3 Batch  456/538 - Train Accuracy:  0.942, Validation Accuracy:  0.946, Loss:  0.051
Epoch   3 Batch  457/538 - Train Accuracy:  0.945, Validation Accuracy:  0.945, Loss:  0.033
Epoch   3 Batch  458/538 - Train Accuracy:  0.953, Validation Accuracy:  0.946, Loss:  0.038
Epoch   3 Batch  459/538 - Train Accuracy:  0.944, Validation Accuracy:  0.950, Loss:  0.033
Epoch   3 Batch  460/538 - Train Accuracy:  0.937, Validation Accuracy:  0.951, Loss:  0.040
Epoch   3 Batch  461/538 - Train Accuracy:  0.955, Validation Accuracy:  0.951, Loss:  0.040
Epoch   3 Batch  462/538 - Train Accuracy:  0.937, Validation Accuracy:  0.949, Loss:  0.038
Epoch   3 Batch  463/538 - Train Accuracy:  0.924, Validation Accuracy:  0.946, Loss:  0.042
Epoch   3 Batch  464/538 - Train Accuracy:  0.951, Validation Accuracy:  0.943, Loss:  0.033
Epoch   3 Batch  465/538 - Train Accuracy:  0.942, Validation Accuracy:  0.939, Loss:  0.037
Epoch   3 Batch  466/538 - Train Accuracy:  0.932, Validation Accuracy:  0.936, Loss:  0.034
Epoch   3 Batch  467/538 - Train Accuracy:  0.945, Validation Accuracy:  0.940, Loss:  0.040
Epoch   3 Batch  468/538 - Train Accuracy:  0.944, Validation Accuracy:  0.941, Loss:  0.045
Epoch   3 Batch  469/538 - Train Accuracy:  0.937, Validation Accuracy:  0.942, Loss:  0.039
Epoch   3 Batch  470/538 - Train Accuracy:  0.941, Validation Accuracy:  0.943, Loss:  0.038
Epoch   3 Batch  471/538 - Train Accuracy:  0.953, Validation Accuracy:  0.944, Loss:  0.031
Epoch   3 Batch  472/538 - Train Accuracy:  0.973, Validation Accuracy:  0.945, Loss:  0.028
Epoch   3 Batch  473/538 - Train Accuracy:  0.931, Validation Accuracy:  0.939, Loss:  0.038
Epoch   3 Batch  474/538 - Train Accuracy:  0.954, Validation Accuracy:  0.940, Loss:  0.033
Epoch   3 Batch  475/538 - Train Accuracy:  0.945, Validation Accuracy:  0.945, Loss:  0.037
Epoch   3 Batch  476/538 - Train Accuracy:  0.950, Validation Accuracy:  0.948, Loss:  0.031
Epoch   3 Batch  477/538 - Train Accuracy:  0.938, Validation Accuracy:  0.943, Loss:  0.043
Epoch   3 Batch  478/538 - Train Accuracy:  0.955, Validation Accuracy:  0.942, Loss:  0.030
Epoch   3 Batch  479/538 - Train Accuracy:  0.948, Validation Accuracy:  0.952, Loss:  0.035
Epoch   3 Batch  480/538 - Train Accuracy:  0.956, Validation Accuracy:  0.951, Loss:  0.034
Epoch   3 Batch  481/538 - Train Accuracy:  0.952, Validation Accuracy:  0.950, Loss:  0.037
Epoch   3 Batch  482/538 - Train Accuracy:  0.948, Validation Accuracy:  0.951, Loss:  0.031
Epoch   3 Batch  483/538 - Train Accuracy:  0.921, Validation Accuracy:  0.951, Loss:  0.043
Epoch   3 Batch  484/538 - Train Accuracy:  0.937, Validation Accuracy:  0.949, Loss:  0.039
Epoch   3 Batch  485/538 - Train Accuracy:  0.951, Validation Accuracy:  0.952, Loss:  0.038
Epoch   3 Batch  486/538 - Train Accuracy:  0.951, Validation Accuracy:  0.945, Loss:  0.031
Epoch   3 Batch  487/538 - Train Accuracy:  0.943, Validation Accuracy:  0.941, Loss:  0.031
Epoch   3 Batch  488/538 - Train Accuracy:  0.954, Validation Accuracy:  0.940, Loss:  0.028
Epoch   3 Batch  489/538 - Train Accuracy:  0.944, Validation Accuracy:  0.942, Loss:  0.038
Epoch   3 Batch  490/538 - Train Accuracy:  0.944, Validation Accuracy:  0.935, Loss:  0.034
Epoch   3 Batch  491/538 - Train Accuracy:  0.915, Validation Accuracy:  0.939, Loss:  0.039
Epoch   3 Batch  492/538 - Train Accuracy:  0.946, Validation Accuracy:  0.937, Loss:  0.034
Epoch   3 Batch  493/538 - Train Accuracy:  0.940, Validation Accuracy:  0.943, Loss:  0.038
Epoch   3 Batch  494/538 - Train Accuracy:  0.945, Validation Accuracy:  0.941, Loss:  0.041
Epoch   3 Batch  495/538 - Train Accuracy:  0.952, Validation Accuracy:  0.948, Loss:  0.038
Epoch   3 Batch  496/538 - Train Accuracy:  0.962, Validation Accuracy:  0.947, Loss:  0.030
Epoch   3 Batch  497/538 - Train Accuracy:  0.956, Validation Accuracy:  0.946, Loss:  0.033
Epoch   3 Batch  498/538 - Train Accuracy:  0.945, Validation Accuracy:  0.941, Loss:  0.033
Epoch   3 Batch  499/538 - Train Accuracy:  0.929, Validation Accuracy:  0.950, Loss:  0.038
Epoch   3 Batch  500/538 - Train Accuracy:  0.960, Validation Accuracy:  0.945, Loss:  0.028
Epoch   3 Batch  501/538 - Train Accuracy:  0.949, Validation Accuracy:  0.942, Loss:  0.038
Epoch   3 Batch  502/538 - Train Accuracy:  0.936, Validation Accuracy:  0.942, Loss:  0.030
Epoch   3 Batch  503/538 - Train Accuracy:  0.955, Validation Accuracy:  0.944, Loss:  0.040
Epoch   3 Batch  504/538 - Train Accuracy:  0.956, Validation Accuracy:  0.949, Loss:  0.027
Epoch   3 Batch  505/538 - Train Accuracy:  0.941, Validation Accuracy:  0.952, Loss:  0.029
Epoch   3 Batch  506/538 - Train Accuracy:  0.955, Validation Accuracy:  0.955, Loss:  0.027
Epoch   3 Batch  507/538 - Train Accuracy:  0.937, Validation Accuracy:  0.955, Loss:  0.038
Epoch   3 Batch  508/538 - Train Accuracy:  0.936, Validation Accuracy:  0.953, Loss:  0.037
Epoch   3 Batch  509/538 - Train Accuracy:  0.938, Validation Accuracy:  0.947, Loss:  0.033
Epoch   3 Batch  510/538 - Train Accuracy:  0.941, Validation Accuracy:  0.946, Loss:  0.034
Epoch   3 Batch  511/538 - Train Accuracy:  0.928, Validation Accuracy:  0.948, Loss:  0.038
Epoch   3 Batch  512/538 - Train Accuracy:  0.941, Validation Accuracy:  0.956, Loss:  0.036
Epoch   3 Batch  513/538 - Train Accuracy:  0.921, Validation Accuracy:  0.958, Loss:  0.034
Epoch   3 Batch  514/538 - Train Accuracy:  0.952, Validation Accuracy:  0.958, Loss:  0.033
Epoch   3 Batch  515/538 - Train Accuracy:  0.932, Validation Accuracy:  0.962, Loss:  0.038
Epoch   3 Batch  516/538 - Train Accuracy:  0.936, Validation Accuracy:  0.947, Loss:  0.038
Epoch   3 Batch  517/538 - Train Accuracy:  0.948, Validation Accuracy:  0.940, Loss:  0.029
Epoch   3 Batch  518/538 - Train Accuracy:  0.934, Validation Accuracy:  0.938, Loss:  0.040
Epoch   3 Batch  519/538 - Train Accuracy:  0.938, Validation Accuracy:  0.942, Loss:  0.036
Epoch   3 Batch  520/538 - Train Accuracy:  0.933, Validation Accuracy:  0.950, Loss:  0.034
Epoch   3 Batch  521/538 - Train Accuracy:  0.943, Validation Accuracy:  0.952, Loss:  0.042
Epoch   3 Batch  522/538 - Train Accuracy:  0.937, Validation Accuracy:  0.959, Loss:  0.034
Epoch   3 Batch  523/538 - Train Accuracy:  0.954, Validation Accuracy:  0.952, Loss:  0.034
Epoch   3 Batch  524/538 - Train Accuracy:  0.950, Validation Accuracy:  0.945, Loss:  0.034
Epoch   3 Batch  525/538 - Train Accuracy:  0.951, Validation Accuracy:  0.947, Loss:  0.038
Epoch   3 Batch  526/538 - Train Accuracy:  0.940, Validation Accuracy:  0.933, Loss:  0.035
Epoch   3 Batch  527/538 - Train Accuracy:  0.957, Validation Accuracy:  0.941, Loss:  0.033
Epoch   3 Batch  528/538 - Train Accuracy:  0.949, Validation Accuracy:  0.952, Loss:  0.039
Epoch   3 Batch  529/538 - Train Accuracy:  0.925, Validation Accuracy:  0.953, Loss:  0.036
Epoch   3 Batch  530/538 - Train Accuracy:  0.931, Validation Accuracy:  0.950, Loss:  0.043
Epoch   3 Batch  531/538 - Train Accuracy:  0.948, Validation Accuracy:  0.953, Loss:  0.042
Epoch   3 Batch  532/538 - Train Accuracy:  0.933, Validation Accuracy:  0.955, Loss:  0.031
Epoch   3 Batch  533/538 - Train Accuracy:  0.958, Validation Accuracy:  0.953, Loss:  0.034
Epoch   3 Batch  534/538 - Train Accuracy:  0.950, Validation Accuracy:  0.951, Loss:  0.028
Epoch   3 Batch  535/538 - Train Accuracy:  0.951, Validation Accuracy:  0.951, Loss:  0.036
Epoch   3 Batch  536/538 - Train Accuracy:  0.953, Validation Accuracy:  0.952, Loss:  0.040
Model Trained and Saved
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Save-Parameters">Save Parameters<a class="anchor-link" href="#Save-Parameters">&#182;</a></h1><p>Save the <code>batch_size</code> and <code>save_path</code> parameters for inference.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[78]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="c1"># Save parameters for checkpoint</span>
<span class="n">helper</span><span class="o">.</span><span class="n">save_params</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Checkpoint">Checkpoint<a class="anchor-link" href="#Checkpoint">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[79]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>

<span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">),</span> <span class="p">(</span><span class="n">source_int_to_vocab</span><span class="p">,</span> <span class="n">target_int_to_vocab</span><span class="p">)</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
<span class="n">load_path</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_params</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Sentence-to-Sequence">Sentence to Sequence<a class="anchor-link" href="#Sentence-to-Sequence">&#182;</a></h2><p>To feed a sentence into the model for translation, you first need to preprocess it.  Implement the function <code>sentence_to_seq()</code> to preprocess new sentences.</p>
<ul>
<li>Convert the sentence to lowercase</li>
<li>Convert words into ids using <code>vocab_to_int</code><ul>
<li>Convert words not in the vocabulary, to the <code>&lt;UNK&gt;</code> word id.</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[80]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">sentence_to_seq</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">vocab_to_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert a sentence to a sequence of ids</span>
<span class="sd">    :param sentence: String</span>
<span class="sd">    :param vocab_to_int: Dictionary to go from the words to an id</span>
<span class="sd">    :return: List of word ids</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="c1">#Convert the sentence to lowercase</span>
    <span class="n">sentence</span> <span class="o">=</span> <span class="n">sentence</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    
    <span class="c1">#Convert to numeric IDs</span>
    
    <span class="c1">#Convert words into ids using vocab_to_int</span>
    <span class="c1">#Convert words not in the vocabulary, to the &lt;UNK&gt; word id.</span>
    
    <span class="n">id_sentence</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># list of word id integers in one sentence, e.g. 1, 2, 3</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">():</span>
        <span class="c1"># catch KeyError and put &lt;UNK&gt; </span>
        <span class="n">id_sentence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vocab_to_int</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;UNK&gt;&#39;</span><span class="p">]))</span>
        
    <span class="k">return</span> <span class="n">id_sentence</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_sentence_to_seq</span><span class="p">(</span><span class="n">sentence_to_seq</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Translate">Translate<a class="anchor-link" href="#Translate">&#182;</a></h2><p>This will translate <code>translate_sentence</code> from English to French.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[81]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">translate_sentence</span> <span class="o">=</span> <span class="s1">&#39;he saw a old yellow truck .&#39;</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">translate_sentence</span> <span class="o">=</span> <span class="n">sentence_to_seq</span><span class="p">(</span><span class="n">translate_sentence</span><span class="p">,</span> <span class="n">source_vocab_to_int</span><span class="p">)</span>

<span class="n">loaded_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">loaded_graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="c1"># Load saved model</span>
    <span class="n">loader</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">import_meta_graph</span><span class="p">(</span><span class="n">load_path</span> <span class="o">+</span> <span class="s1">&#39;.meta&#39;</span><span class="p">)</span>
    <span class="n">loader</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">load_path</span><span class="p">)</span>

    <span class="n">input_data</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;input:0&#39;</span><span class="p">)</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;logits:0&#39;</span><span class="p">)</span>
    <span class="n">keep_prob</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;keep_prob:0&#39;</span><span class="p">)</span>

    <span class="n">translate_logits</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="p">[</span><span class="n">translate_sentence</span><span class="p">],</span> <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})[</span><span class="mi">0</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Input&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  Word Ids:      </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_sentence</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  English Words: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">source_int_to_vocab</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_sentence</span><span class="p">]))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Prediction&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  Word Ids:      </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">translate_logits</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  French Words: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">target_int_to_vocab</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">translate_logits</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Input
  Word Ids:      [203, 180, 55, 117, 193, 130, 200]
  English Words: [&#39;he&#39;, &#39;saw&#39;, &#39;a&#39;, &#39;old&#39;, &#39;yellow&#39;, &#39;truck&#39;, &#39;.&#39;]

Prediction
  Word Ids:      [199, 127, 105, 323, 43, 266, 243, 174, 1]
  French Words: [&#39;il&#39;, &#39;a&#39;, &#39;vu&#39;, &#39;un&#39;, &#39;vieux&#39;, &#39;camion&#39;, &#39;jaune&#39;, &#39;.&#39;, &#39;&lt;EOS&gt;&#39;]
</pre>
</div>
</div>

</div>
</div>

</div>Hmmmm.... translation of what we got is "il a vu un vieux camion jaune" 
which means "He saw an old yellow truck" (according to the Google translate :)
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Imperfect-Translation">Imperfect Translation<a class="anchor-link" href="#Imperfect-Translation">&#182;</a></h2><p>You might notice that some sentences translate better than others.  Since the dataset you're using only has a vocabulary of 227 English words of the thousands that you use, you're only going to see good results using these words.  For this project, you don't need a perfect translation. However, if you want to create a better translation model, you'll need better data.</p>
<p>You can train on the <a href="http://www.statmt.org/wmt10/training-giga-fren.tar">WMT10 French-English corpus</a>.  This dataset has more vocabulary and richer in topics discussed.  However, this will take you days to train, so make sure you've a GPU and the neural network is performing well on dataset we provided.  Just make sure you play with the WMT10 corpus after you've submitted this project.</p>
<h2 id="Submitting-This-Project">Submitting This Project<a class="anchor-link" href="#Submitting-This-Project">&#182;</a></h2><p>When submitting this project, make sure to run all the cells before saving the notebook. Save the notebook file as "dlnd_language_translation.ipynb" and save it as a HTML file under "File" -&gt; "Download as". Include the "helper.py" and "problem_unittests.py" files in your submission.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Visualize-loss-&amp;-accuracy">Visualize loss &amp; accuracy<a class="anchor-link" href="#Visualize-loss-&amp;-accuracy">&#182;</a></h1><p>Adding a graph to see effect of epoch iterations.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[83]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Run the process again, we could have done this before, but didn&#39;t want to interfere with the </span>
<span class="c1"># notebooks &quot;protected&quot; code.</span>

<span class="c1"># It would be even better with a graph:</span>
<span class="c1"># Visualize the loss and accuracy</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Graph it...!</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">import</span> <span class="nn">time</span>


<span class="n">save_path</span> <span class="o">=</span> <span class="s1">&#39;checkpoints/dev&#39;</span>
<span class="p">(</span><span class="n">source_int_text</span><span class="p">,</span> <span class="n">target_int_text</span><span class="p">),</span> <span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">),</span> <span class="n">_</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
<span class="n">max_source_sentence_length</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">source_int_text</span><span class="p">])</span>

<span class="n">train_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">train_graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
    <span class="n">input_data</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">keep_prob</span> <span class="o">=</span> <span class="n">model_inputs</span><span class="p">()</span>
    <span class="n">sequence_length</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder_with_default</span><span class="p">(</span><span class="n">max_source_sentence_length</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;sequence_length&#39;</span><span class="p">)</span>
    <span class="n">input_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>
    
    <span class="n">train_logits</span><span class="p">,</span> <span class="n">inference_logits</span> <span class="o">=</span> <span class="n">seq2seq_model</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">reverse</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">targets</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">target_vocab_to_int</span><span class="p">),</span>
        <span class="n">encoding_embedding_size</span><span class="p">,</span> <span class="n">decoding_embedding_size</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">)</span>

    <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">inference_logits</span><span class="p">,</span> <span class="s1">&#39;logits&#39;</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s2">&quot;optimization&quot;</span><span class="p">):</span>
        <span class="c1"># Loss function</span>
        <span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">sequence_loss</span><span class="p">(</span>
            <span class="n">train_logits</span><span class="p">,</span>
            <span class="n">targets</span><span class="p">,</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">input_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">sequence_length</span><span class="p">]))</span>

        <span class="c1"># Optimizer</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>

        <span class="c1"># Gradient Clipping</span>
        <span class="n">gradients</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">compute_gradients</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
        <span class="n">capped_gradients</span> <span class="o">=</span> <span class="p">[(</span><span class="n">tf</span><span class="o">.</span><span class="n">clip_by_value</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">),</span> <span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">grad</span><span class="p">,</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">gradients</span> <span class="k">if</span> <span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">]</span>
        <span class="n">train_op</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="n">capped_gradients</span><span class="p">)</span>



<span class="k">def</span> <span class="nf">get_accuracy</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">logits</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate accuracy</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">max_seq</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">max_seq</span> <span class="o">-</span> <span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
            <span class="n">target</span><span class="p">,</span>
            <span class="p">[(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="n">max_seq</span> <span class="o">-</span> <span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])],</span>
            <span class="s1">&#39;constant&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">max_seq</span> <span class="o">-</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
            <span class="n">logits</span><span class="p">,</span>
            <span class="p">[(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="n">max_seq</span> <span class="o">-</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">)],</span>
            <span class="s1">&#39;constant&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>

<span class="n">train_source</span> <span class="o">=</span> <span class="n">source_int_text</span><span class="p">[</span><span class="n">batch_size</span><span class="p">:]</span>
<span class="n">train_target</span> <span class="o">=</span> <span class="n">target_int_text</span><span class="p">[</span><span class="n">batch_size</span><span class="p">:]</span>

<span class="n">valid_source</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">pad_sentence_batch</span><span class="p">(</span><span class="n">source_int_text</span><span class="p">[:</span><span class="n">batch_size</span><span class="p">])</span>
<span class="n">valid_target</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">pad_sentence_batch</span><span class="p">(</span><span class="n">target_int_text</span><span class="p">[:</span><span class="n">batch_size</span><span class="p">])</span>

<span class="c1">#plotting info.....to graph</span>
<span class="n">loss_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">valid_acc_list</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">train_graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>

    <span class="k">for</span> <span class="n">epoch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">batch_i</span><span class="p">,</span> <span class="p">(</span><span class="n">source_batch</span><span class="p">,</span> <span class="n">target_batch</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
                <span class="n">helper</span><span class="o">.</span><span class="n">batch_data</span><span class="p">(</span><span class="n">train_source</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)):</span>
            <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            
            <span class="n">_</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                <span class="p">[</span><span class="n">train_op</span><span class="p">,</span> <span class="n">cost</span><span class="p">],</span>
                <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">source_batch</span><span class="p">,</span>
                 <span class="n">targets</span><span class="p">:</span> <span class="n">target_batch</span><span class="p">,</span>
                 <span class="n">lr</span><span class="p">:</span> <span class="n">learning_rate</span><span class="p">,</span>
                 <span class="n">sequence_length</span><span class="p">:</span> <span class="n">target_batch</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                 <span class="n">keep_prob</span><span class="p">:</span> <span class="n">keep_probability</span><span class="p">})</span>
            
            <span class="n">batch_train_logits</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                <span class="n">inference_logits</span><span class="p">,</span>
                <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">source_batch</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>
            <span class="n">batch_valid_logits</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                <span class="n">inference_logits</span><span class="p">,</span>
                <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">valid_source</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>
                
            <span class="n">train_acc</span> <span class="o">=</span> <span class="n">get_accuracy</span><span class="p">(</span><span class="n">target_batch</span><span class="p">,</span> <span class="n">batch_train_logits</span><span class="p">)</span>
            <span class="n">valid_acc</span> <span class="o">=</span> <span class="n">get_accuracy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">valid_target</span><span class="p">),</span> <span class="n">batch_valid_logits</span><span class="p">)</span>
            <span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

            <span class="c1"># store our progress</span>
            <span class="n">loss_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span> 
            <span class="n">valid_acc_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">valid_acc</span><span class="p">)</span>
            
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Model Trained and Saved&#39;</span><span class="p">)</span>
    <span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">loss_list</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Traning Loss&#39;</span><span class="p">)</span>

    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Loss value&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">valid_acc_list</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Iterations&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Validation Accuracy&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model Trained and Saved
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABBkAAAGDCAYAAABuushwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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=
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
    </div>
  </div>
</body>

 


</html>
